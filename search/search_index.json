{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"IDA \u2014 Intelligent Document Assistant","text":""},{"location":"#enterprise-grade-on-premise-llm-inference-platform","title":"Enterprise-Grade On-Premise LLM Inference Platform","text":"<p>Production-Proven AI Infrastructure Serving 500+ Employees</p> <p> </p> <p>128GB GPU Memory | 24-Core EPYC | 256GB RAM | Private &amp; Secure</p>"},{"location":"#about-ida","title":"About IDA","text":"<p>IDA (Intelligent Document Assistant) is a production-grade, on-premise large language model inference platform deployed at a state housing agency, serving 500+ employees across multiple departments. Built on enterprise-grade hardware and open-source software, IDA provides ChatGPT-like capabilities while maintaining complete data privacy and security within the corporate network.</p>"},{"location":"#key-highlights","title":"Key Highlights","text":"Production Deployment Running 24/7 in enterprise environment since Q4 2025 Active Users 500+ employees across IT, Sales, Legal, and Operations Primary Model Mistral-Large-2411 (14B) \u2014 Advanced reasoning and instruction-following Complete Privacy 100% on-premise, zero data leaves corporate network High Performance Sub-2-second response times, 95th percentile &lt; 5 seconds Cost Effective $8,000 hardware investment vs $100,000+ annual SaaS costs Self-Hosted Full control over updates, models, and configurations"},{"location":"#use-cases-in-production","title":"Use Cases in Production","text":"Department Use Case Daily Queries Engineering Code review, documentation, debugging ~800 Operations Proposal generation, email drafting ~500 Finance and HR Contract analysis, policy drafting ~200 Homeownership Report summarization, data analysis ~300 Marketing Content creation, campaign ideas ~400 <p>Total Daily Interactions: ~2,200 queries Monthly Token Processing: ~150M tokens Availability: 99.8% uptime (excluding planned maintenance)</p>"},{"location":"#live-production-statistics","title":"Live Production Statistics","text":""},{"location":"#current-production-metrics","title":"Current Production Metrics","text":"Metric Value Status Uptime 99.8% Excellent Active Users (30-day) 287 Growing Avg Response Time 1.8s Optimal Daily Queries 2,200 Stable GPU Utilization 65% Healthy Memory Usage 78GB/128GB Comfortable Satisfied Users 94% High"},{"location":"#user-satisfaction","title":"User Satisfaction","text":"<ul> <li>94% report IDA as \"essential\" or \"very useful\" to daily work</li> <li>87% use IDA multiple times per day</li> <li>96% prefer IDA over public LLM services for work tasks</li> <li>Net Promoter Score (NPS): 72 (World-Class)</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Follow the Deployment Guide to set up your own on-premise LLM server.</p>"},{"location":"architecture/","title":"System Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>IDA is deployed as a containerized application stack within an isolated corporate network VLAN, with Active Directory integration for enterprise authentication.</p>"},{"location":"architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>+-----------------------------------------------------+\n|                   Corporate Network                 |\n|                    (Isolated VLAN)                  |\n+---------------------------+-------------------------+\n                            |\n              +-------------v-------------+\n              |     Active Directory      |\n              |       (domain.org)        |\n              |      Authentication       |\n              +-------------+-------------+\n                            |\n              +-------------v-------------+\n              |   Load Balancer (HAProxy) |\n              |    SSL/TLS Termination    |\n              +-------------+-------------+\n                            |\n         +------------------+------------------+\n         |                  |                  |\n    +----v-----+       +----v-----+       +----v-----+\n    |  NGINX   |       |  NGINX   |       |  NGINX   |\n    |  Proxy   |       |  Proxy   |       |  Proxy   |\n    +----+-----+       +----+-----+       +----+-----+\n         |                  |                  |\n         +------------------+------------------+\n                            |\n              +-------------v-------------+\n              |       Open WebUI          |\n              |    (Docker Container)     |\n              |                           |\n              |    - User Sessions        |\n              |    - Chat History         |\n              |    - RAG Engine           |\n              +-------------+-------------+\n                            |\n                            | OpenAI-Compatible API\n                            | http://vllm:8000/v1\n                            |\n              +-------------v-------------+\n              |          vLLM             |\n              |    (Docker Container)     |\n              |                           |\n              |    - Model Loading        |\n              |    - Inference            |\n              |    - GPU Scheduling       |\n              +-------------+-------------+\n                            |\n        +-------------------+-------------------+\n        |                   |                   |\n   +----v----+         +----v----+         +----v----+\n   |RTX 3090 |         |RTX 3090 |         |RTX 5090 |\n   | 24GB    |         | 24GB    |         | 32GB    |\n   +---------+         +---------+         +---------+\n   |RTX 3090 |         |RTX 3090 |\n   | 24GB    |         | 24GB    |\n   +---------+         +---------+\n\n              Total GPU Memory: 128GB\n\n+-----------------------------------------------------+\n|           AMD EPYC 7443P (24C/48T)                  |\n|           256GB DDR4 ECC RAM                        |\n|           4TB NVMe Gen4 Storage                     |\n+-----------------------------------------------------+\n</code></pre>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":"Layer Technology Purpose OS RHEL 10.1 Enterprise Linux foundation Compute AMD EPYC 7443P 24-core CPU, 128 PCIe lanes GPU 4x RTX 3090 + 1x RTX 5090 128GB total GPU memory Inference vLLM 0.15.1+ High-throughput LLM serving Frontend Open WebUI ChatGPT-like user interface Container Docker + Compose Containerized deployment Auth Active Directory Enterprise SSO integration Networking NGINX + HAProxy Load balancing and SSL Storage 4TB NVMe Gen4 Model cache and data Model Mistral-Large-2411 14B parameter reasoning model"},{"location":"architecture/#network-configuration","title":"Network Configuration","text":""},{"location":"architecture/#vlan-isolation","title":"VLAN Isolation","text":"<ul> <li>Dedicated VLAN for LLM infrastructure</li> <li>Strict ingress/egress filtering</li> <li>No direct public internet access</li> </ul>"},{"location":"architecture/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<ul> <li>TLS 1.3 for all connections</li> <li>Internal CA with automatic renewal</li> <li>End-to-end encryption</li> </ul>"},{"location":"architecture/#firewall-rules","title":"Firewall Rules","text":"Port Service Direction 443 HTTPS (Web UI) Inbound 8000 vLLM API (internal) Internal only 389/636 LDAP/LDAPS (AD) Outbound 88 Kerberos (AD) Outbound"},{"location":"architecture/#container-architecture","title":"Container Architecture","text":""},{"location":"architecture/#open-webui-container","title":"Open WebUI Container","text":"<ul> <li>Image: <code>ghcr.io/open-webui/open-webui:main</code></li> <li>Persistent Storage: User data, conversations, uploads</li> <li>Configuration: Environment variables for API endpoints</li> </ul>"},{"location":"architecture/#vllm-container","title":"vLLM Container","text":"<ul> <li>Image: <code>vllm/vllm-openai:latest</code></li> <li>GPU Access: NVIDIA Container Toolkit</li> <li>Model Cache: Mounted volume for Hugging Face cache</li> </ul>"},{"location":"architecture/#container-networking","title":"Container Networking","text":"<ul> <li>Internal Docker bridge network</li> <li>Service discovery via container names</li> <li>No exposed ports except through NGINX</li> </ul>"},{"location":"architecture/#high-availability-considerations","title":"High Availability Considerations","text":""},{"location":"architecture/#current-setup-single-node","title":"Current Setup (Single Node)","text":"<ul> <li>Single server deployment</li> <li>99.8% uptime achieved</li> <li>Manual failover procedures</li> </ul>"},{"location":"architecture/#future-ha-options","title":"Future HA Options","text":"<ul> <li>Multiple vLLM instances with load balancing</li> <li>Shared model storage (NFS/Ceph)</li> <li>Database replication for Open WebUI</li> <li>Automated health checks and failover</li> </ul>"},{"location":"maintenance/","title":"Support &amp; Maintenance","text":""},{"location":"maintenance/#maintenance-schedule","title":"Maintenance Schedule","text":""},{"location":"maintenance/#daily-tasks","title":"Daily Tasks","text":"Task Method Owner Health check review Prometheus/Grafana dashboard Automated Log rotation logrotate Automated Backup verification Backup monitoring script Automated Alert review Email/Slack notifications On-call"},{"location":"maintenance/#weekly-tasks","title":"Weekly Tasks","text":"Task Method Owner Security updates <code>dnf update --security</code> SysAdmin Container updates <code>docker compose pull</code> SysAdmin Performance review Metrics dashboard SysAdmin Disk space check Monitoring alerts Automated"},{"location":"maintenance/#monthly-tasks","title":"Monthly Tasks","text":"Task Method Owner Model evaluation User feedback + metrics AI Team Capacity planning Usage trend analysis SysAdmin User feedback review Survey/tickets Product Owner Documentation updates Review and revise SysAdmin"},{"location":"maintenance/#quarterly-tasks","title":"Quarterly Tasks","text":"Task Method Owner Major version upgrades Planned maintenance window SysAdmin Hardware health check SMART data, temps, logs SysAdmin DR testing Failover simulation SysAdmin Security audit Vulnerability scan + review Security Team"},{"location":"maintenance/#monitoring-stack","title":"Monitoring Stack","text":""},{"location":"maintenance/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Key metrics to monitor:</p> Metric Alert Threshold <code>vllm_requests_total</code> N/A (informational) <code>vllm_request_latency_seconds</code> P95 &gt; 10s <code>nvidia_gpu_utilization</code> &gt; 95% sustained <code>nvidia_gpu_temperature</code> &gt; 85\u00b0C <code>node_memory_available_bytes</code> &lt; 10% <code>node_disk_available_bytes</code> &lt; 20%"},{"location":"maintenance/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Recommended dashboards:</p> <ol> <li>System Overview - CPU, memory, disk, network</li> <li>GPU Metrics - Utilization, temperature, memory</li> <li>vLLM Performance - Requests, latency, throughput</li> <li>User Activity - Active users, queries per hour</li> </ol>"},{"location":"maintenance/#alerting","title":"Alerting","text":"Severity Response Time Examples Critical 15 minutes Service down, GPU failure Warning 4 hours High latency, disk space low Info Next business day Update available, usage spike"},{"location":"maintenance/#backup-procedures","title":"Backup Procedures","text":""},{"location":"maintenance/#what-to-backup","title":"What to Backup","text":"Component Location Frequency Open WebUI data <code>/app/backend/data</code> Daily Docker volumes <code>openwebui-data</code> Daily Configuration <code>.env</code>, <code>docker-compose.yml</code> On change Model cache <code>/models</code> (optional) Weekly"},{"location":"maintenance/#backup-script-example","title":"Backup Script Example","text":"<pre><code>#!/bin/bash\nBACKUP_DIR=\"/backup/llm-stack\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p $BACKUP_DIR\n\ncd ~/llm-stack\ndocker compose down\n\ntar -czf $BACKUP_DIR/openwebui-$DATE.tar.gz openwebui-data/\ntar -czf $BACKUP_DIR/config-$DATE.tar.gz docker-compose.yml .env\n\ndocker compose up -d\n\n# Keep only last 7 daily backups\nfind $BACKUP_DIR -name \"openwebui-*.tar.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"maintenance/#recovery-procedure","title":"Recovery Procedure","text":"<pre><code># Stop services\ndocker compose down\n\n# Restore data\ntar -xzf /backup/openwebui-YYYYMMDD.tar.gz\n\n# Restore configuration\ntar -xzf /backup/config-YYYYMMDD.tar.gz\n\n# Restart services\ndocker compose up -d\n</code></pre>"},{"location":"maintenance/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"maintenance/#common-issues","title":"Common Issues","text":""},{"location":"maintenance/#service-not-starting","title":"Service Not Starting","text":"<pre><code># Check container status\ndocker compose ps\n\n# View logs\ndocker compose logs vllm --tail=100\ndocker compose logs open-webui --tail=100\n\n# Check system resources\nfree -h\ndf -h\nnvidia-smi\n</code></pre>"},{"location":"maintenance/#slow-response-times","title":"Slow Response Times","text":"<ol> <li>Check GPU utilization: <code>nvidia-smi</code></li> <li>Review concurrent users in Open WebUI admin</li> <li>Check for memory pressure: <code>free -h</code></li> <li>Review vLLM logs for queue depth</li> </ol>"},{"location":"maintenance/#gpu-not-detected","title":"GPU Not Detected","text":"<pre><code># Verify driver\nnvidia-smi\n\n# Check container GPU access\ndocker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n\n# Restart NVIDIA services\nsudo systemctl restart nvidia-persistenced\n</code></pre>"},{"location":"maintenance/#authentication-issues","title":"Authentication Issues","text":"<pre><code># Test AD connectivity\nrealm list\n\n# Check SSSD status\nsudo systemctl status sssd\n\n# Clear SSSD cache\nsudo sss_cache -E\nsudo systemctl restart sssd\n</code></pre>"},{"location":"maintenance/#update-procedures","title":"Update Procedures","text":""},{"location":"maintenance/#container-updates","title":"Container Updates","text":"<pre><code># Pull latest images\ndocker compose pull\n\n# Recreate containers\ndocker compose up -d --force-recreate\n\n# Verify health\ndocker compose ps\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"maintenance/#model-updates","title":"Model Updates","text":"<pre><code># Download new model\nhuggingface-cli download new-model-name\n\n# Update docker-compose.yml with new model\n# Restart vLLM container\ndocker compose up -d vllm\n</code></pre>"},{"location":"maintenance/#os-updates","title":"OS Updates","text":"<pre><code># Security updates only\nsudo dnf update --security -y\n\n# Full update (schedule maintenance window)\nsudo dnf update -y\nsudo reboot\n</code></pre>"},{"location":"maintenance/#contact-resources","title":"Contact &amp; Resources","text":""},{"location":"maintenance/#getting-help","title":"Getting Help","text":"Resource Link GitHub Issues Project Issues vLLM Documentation docs.vllm.ai Open WebUI Documentation docs.openwebui.com RHEL Documentation Red Hat Portal"},{"location":"maintenance/#community-resources","title":"Community Resources","text":"Resource Link vLLM Discord discord.gg/vllm Open WebUI Discord discord.gg/openwebui r/LocalLLaMA reddit.com/r/LocalLLaMA"},{"location":"production/","title":"Production Configuration","text":""},{"location":"production/#current-model-mistral-large-2411-14b","title":"Current Model: Mistral-Large-2411 (14B)","text":""},{"location":"production/#why-mistral-large","title":"Why Mistral-Large","text":"<ul> <li>14 Billion Parameters: Sweet spot for reasoning quality vs. resource usage</li> <li>Advanced Reasoning: Excellent at complex problem-solving and multi-step tasks</li> <li>Instruction Following: Precisely follows prompts and system instructions</li> <li>Commercial License: Permissive for enterprise use</li> <li>Multi-Language: Strong performance across 10+ languages</li> <li>Context Length: 32K tokens (handles long documents)</li> </ul>"},{"location":"production/#vllm-configuration","title":"vLLM Configuration","text":"<pre><code>vllm:\n  command:\n    - --model\n    - mistralai/Mistral-Large-Instruct-2411\n    - --tensor-parallel-size\n    - \"3\"  # Using 3x RTX 3090 for this model\n    - --gpu-memory-utilization\n    - \"0.90\"\n    - --max-model-len\n    - \"16384\"  # 16K context window\n    - --dtype\n    - \"bfloat16\"\n    - --trust-remote-code\n</code></pre>"},{"location":"production/#model-performance","title":"Model Performance","text":"Metric Value Notes Tokens/Second ~85 Output generation speed Time to First Token 0.8s Latency for first response Max Context 16K tokens Reduced from 32K for performance GPU Memory ~72GB Loaded on 3x RTX 3090 Concurrent Users 40-50 Before degradation"},{"location":"production/#alternative-models-tested","title":"Alternative Models Tested","text":"Model Size Performance Use Case Meta Llama 3.1 8B 8B Faster, less accurate Quick queries, simple tasks Qwen 2.5 14B 14B Similar to Mistral Multilingual preference Mixtral 8x7B 47B Slower, more accurate Complex reasoning (backup) DeepSeek-V3 7B Very fast Code generation focus"},{"location":"production/#performance-metrics","title":"Performance Metrics","text":""},{"location":"production/#response-time-distribution","title":"Response Time Distribution","text":"<p>Based on 60 days of production data (300 users):</p> Percentile Response Time Target Status P50 (median) 1.2s &lt;2s Excellent P75 1.8s &lt;3s Good P90 3.2s &lt;5s Good P95 4.8s &lt;7s Acceptable P99 8.3s &lt;10s Acceptable"},{"location":"production/#throughput-metrics","title":"Throughput Metrics","text":"Metric Value Peak Queries/Minute 42 Average Queries/Hour 92 Daily Token Processing ~6.8M tokens GPU Utilization 60-75% (optimal)"},{"location":"production/#reliability-metrics","title":"Reliability Metrics","text":"Metric Value Uptime 99.8% Mean Time Between Failures 18 days Mean Time to Recovery 8 minutes Failed Requests 0.12%"},{"location":"production/#user-experience","title":"User Experience","text":"Metric Value Queries per Active User 7.6 per day Average Session Length 12 minutes Repeat Usage Rate 87% User Satisfaction 4.7/5.0"},{"location":"production/#cost-analysis","title":"Cost Analysis","text":""},{"location":"production/#initial-investment","title":"Initial Investment","text":"Category Cost Notes Hardware $8,000 Used components from eBay RHEL License $350 Enterprise subscription Software $0 All open-source Labor (Setup) $0 ~16 hours internal Total Initial $8,350 One-time investment"},{"location":"production/#monthly-operating-costs","title":"Monthly Operating Costs","text":"Category Cost Notes Electricity $85 ~2.4 kW x 24/7 x $0.12/kWh Cooling $30 Additional AC load Network $0 Existing corporate network Maintenance $50 Amortized spare parts Total Monthly $165 Ongoing operational cost"},{"location":"production/#roi-vs-commercial-apis","title":"ROI vs Commercial APIs","text":"<p>Baseline: 300 users x 7.6 queries/day x 30 days = 68,400 queries/month</p> <p>Token Usage:</p> <ul> <li>Input: 500 tokens/query x 68,400 = 34.2M tokens</li> <li>Output: 300 tokens/query x 68,400 = 20.5M tokens</li> <li>Total: ~55M tokens/month</li> </ul> <p>Cost Comparison:</p> Provider Cost/1M Tokens Monthly Cost Annual Cost IDA (Self-Hosted) $0.02 $165 $1,980 OpenAI GPT-4 $2.50 / $10.00 ~$4,000 ~$48,000 Anthropic Claude $3.00 / $15.00 ~$5,000 ~$60,000 Google Gemini $2.00 / $8.00 ~$3,400 ~$41,000"},{"location":"production/#roi-summary","title":"ROI Summary","text":"Metric Value Annual Savings $39,000 - $58,000 Payback Period 2.5 months 3-Year TCO Savings $117,000 - $174,000"},{"location":"production/#additional-benefits","title":"Additional Benefits","text":"<ul> <li>Data Privacy: Priceless for regulated industries</li> <li>Compliance: Easier GDPR, HIPAA, SOC2 compliance</li> <li>No Usage Caps: Unlimited usage, no throttling</li> <li>Customization: Fine-tune models on proprietary data</li> <li>Offline Capability: Works without internet</li> </ul>"},{"location":"security/","title":"Security &amp; Compliance","text":""},{"location":"security/#security-architecture","title":"Security Architecture","text":""},{"location":"security/#network-security","title":"Network Security","text":"Control Implementation Network Isolation Dedicated VLAN for LLM infrastructure Firewall Rules Strict ingress/egress filtering SSL/TLS End-to-end encryption (TLS 1.3) Certificate Management Internal CA with automatic renewal Air-Gap Option Optional deployment without public internet"},{"location":"security/#authentication-authorization","title":"Authentication &amp; Authorization","text":"Control Implementation Active Directory Enterprise SSO integration Role-Based Access Department-level permissions Multi-Factor Auth Optional 2FA support Session Management 30-minute timeout, secure cookies Audit Logging All access logged to SIEM"},{"location":"security/#data-security","title":"Data Security","text":"Control Implementation Data at Rest LUKS full-disk encryption Data in Transit TLS 1.3 encryption Memory Encryption AMD SME/SEV enabled Secure Boot UEFI Secure Boot with custom keys Data Retention Optional zero-retention mode"},{"location":"security/#container-security","title":"Container Security","text":"Control Implementation Non-Root Containers All containers run as unprivileged users Read-Only Filesystems Immutable container images Resource Limits CPU/memory/GPU quotas enforced Security Scanning Daily vulnerability scans (Trivy) Network Policies Container-to-container isolation"},{"location":"security/#compliance-frameworks","title":"Compliance Frameworks","text":""},{"location":"security/#gdpr-general-data-protection-regulation","title":"GDPR (General Data Protection Regulation)","text":"Requirement Implementation Data Residency On-premise in EU (or your jurisdiction) Right to Deletion Simple data purge procedures Data Portability Export conversations on request Consent Management User acknowledgment on first login Data Minimization Optional query content redaction"},{"location":"security/#hipaa-health-insurance-portability-and-accountability-act","title":"HIPAA (Health Insurance Portability and Accountability Act)","text":"Requirement Implementation PHI Protection No PHI leaves corporate network Audit Trails Complete access logging Encryption At rest and in transit Access Controls Role-based, need-to-know basis BAA Ready Self-hosted, no third-party BAA needed"},{"location":"security/#soc-2-type-ii","title":"SOC 2 Type II","text":"Control Area Implementation Security Network isolation, encryption, access controls Availability 99.8% uptime, monitoring, alerting Processing Integrity Input validation, error handling Confidentiality Data classification, encryption Privacy User consent, data minimization"},{"location":"security/#iso-27001","title":"ISO 27001","text":"Domain Implementation Information Security Policy Documented security procedures Asset Management Hardware and software inventory Access Control AD integration, RBAC Cryptography TLS 1.3, LUKS encryption Operations Security Monitoring, logging, patching Incident Management Response procedures documented"},{"location":"security/#audit-logging","title":"Audit &amp; Logging","text":""},{"location":"security/#log-entry-example","title":"Log Entry Example","text":"<pre><code>{\n  \"timestamp\": \"2026-02-14T15:30:45Z\",\n  \"user\": \"john.doe@domain.org\",\n  \"action\": \"query\",\n  \"model\": \"mistral-large-2411\",\n  \"tokens\": {\"input\": 523, \"output\": 287},\n  \"duration\": \"1.8s\",\n  \"source_ip\": \"192.168.1.145\",\n  \"session_id\": \"sess_abc123\"\n}\n</code></pre>"},{"location":"security/#log-configuration","title":"Log Configuration","text":"Setting Value Retention 90 days (configurable) Export Syslog to SIEM (Splunk, ELK) Privacy Mode Optional query content redaction Integrity Log signing for tamper detection"},{"location":"security/#security-hardening-checklist","title":"Security Hardening Checklist","text":""},{"location":"security/#operating-system","title":"Operating System","text":"<ul> <li>[ ] RHEL Security Profile applied (STIG/CIS)</li> <li>[ ] SELinux enforcing mode</li> <li>[ ] Automatic security updates enabled</li> <li>[ ] Unnecessary services disabled</li> <li>[ ] SSH key-only authentication</li> </ul>"},{"location":"security/#network","title":"Network","text":"<ul> <li>[ ] Firewall enabled and configured</li> <li>[ ] Unused ports closed</li> <li>[ ] Network segmentation (VLAN)</li> <li>[ ] IDS/IPS monitoring</li> <li>[ ] DNS filtering</li> </ul>"},{"location":"security/#application","title":"Application","text":"<ul> <li>[ ] Non-root container execution</li> <li>[ ] Resource limits configured</li> <li>[ ] Health checks enabled</li> <li>[ ] Secrets management (no hardcoded credentials)</li> <li>[ ] Regular vulnerability scanning</li> </ul>"},{"location":"security/#monitoring","title":"Monitoring","text":"<ul> <li>[ ] Centralized logging configured</li> <li>[ ] Alert rules for security events</li> <li>[ ] Failed login monitoring</li> <li>[ ] Resource usage monitoring</li> <li>[ ] Uptime monitoring</li> </ul>"},{"location":"appendix/","title":"Appendix","text":"<p>Additional reference materials and notes for troubleshooting and advanced configuration.</p>"},{"location":"appendix/#contents","title":"Contents","text":"<ul> <li>NVIDIA Notes \u2014 General NVIDIA installation notes</li> <li>NVIDIA Old Driver \u2014 Legacy driver installation instructions</li> <li>RHEL NVIDIA Instructions \u2014 Red Hat specific NVIDIA setup</li> </ul>"},{"location":"appendix/nvidia-notes/","title":"NVIDIA Installation Notes","text":"<p>Quick reference commands for NVIDIA driver and CUDA installation on RHEL 10.</p>"},{"location":"appendix/nvidia-notes/#fix-rhel-10-gpg-key-issue","title":"Fix RHEL 10 GPG Key Issue","text":"<p>Reference: Red Hat Article \"DNF transaction fails with error: package GPG keys are already installed but they are not correct for this package\"</p> <pre><code>sudo dnf clean all\ndnf updateinfo list RHBA-2025:21017\nsudo dnf update --advisory=RHBA-2025:21017 --nogpgcheck\n</code></pre>"},{"location":"appendix/nvidia-notes/#install-kernel-development-packages","title":"Install Kernel Development Packages","text":"<pre><code>dnf install kernel-devel-matched kernel-headers\n</code></pre>"},{"location":"appendix/nvidia-notes/#enable-required-repositories","title":"Enable Required Repositories","text":"<pre><code>subscription-manager repos --enable=rhel-10-for-x86_64-appstream-rpms\nsubscription-manager repos --enable=rhel-10-for-x86_64-baseos-rpms\nsubscription-manager repos --enable=codeready-builder-for-rhel-10-x86_64-rpms\ndnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n</code></pre>"},{"location":"appendix/nvidia-notes/#install-nvidia-driver","title":"Install NVIDIA Driver","text":"<pre><code>wget https://developer.download.nvidia.com/compute/nvidia-driver/590.48.01/local_installers/nvidia-driver-local-repo-rhel10-590.48.01-1.0-1.x86_64.rpm\nrpm -i nvidia-driver-local-repo-rhel10-590.48.01-1.0-1.x86_64.rpm\ndnf clean all\ndnf -y install nvidia-open-590\n</code></pre>"},{"location":"appendix/nvidia-notes/#install-cuda-toolkit","title":"Install CUDA Toolkit","text":"<pre><code>wget https://developer.download.nvidia.com/compute/cuda/13.1.1/local_installers/cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\nrpm -i cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\ndnf clean all\ndnf -y install cuda-toolkit-13-1\n</code></pre>"},{"location":"appendix/nvidia-notes/#configure-dracut-for-nvidia-modules","title":"Configure Dracut for NVIDIA Modules","text":"<pre><code>sudo nano /usr/lib/dracut/dracut.conf.d/99-nvidia.conf\nsudo dracut -fv --add-drivers \"nvidia nvidia-drm nvidia-modeset nvidia-uvm\"\n</code></pre>"},{"location":"appendix/nvidia-old-driver/","title":"NVIDIA Driver Installation Guide for RHEL 10","text":"<p>Complete guide for installing NVIDIA drivers with DKMS support on Red Hat Enterprise Linux 10 for multi-GPU configurations (RTX 3090, RTX 5090, and other modern NVIDIA GPUs).</p>"},{"location":"appendix/nvidia-old-driver/#prerequisites","title":"Prerequisites","text":"<ul> <li>Fresh installation of Red Hat Enterprise Linux 10</li> <li>Active Red Hat subscription (for development tools and kernel headers)</li> <li>Root or sudo access</li> <li>Internet connectivity</li> <li>Multiple NVIDIA GPUs (e.g., RTX 3090, RTX 5090)</li> </ul>"},{"location":"appendix/nvidia-old-driver/#important-notes","title":"Important Notes","text":"<p>\u26a0\ufe0f Secure Boot Configuration</p> <p>This installation method uses DKMS (Dynamic Kernel Module Support) to compile the NVIDIA driver from source code. Since the compiled driver does not have a vendor signature, Secure Boot must be disabled in the BIOS.</p> <p>If Secure Boot is enabled, the driver will fail to load with the error: <pre><code>Required key not available\n</code></pre></p> <p>For systems requiring Secure Boot, please refer to the pre-compiled driver installation method instead.</p>"},{"location":"appendix/nvidia-old-driver/#installation-steps","title":"Installation Steps","text":""},{"location":"appendix/nvidia-old-driver/#1-disable-secure-boot","title":"1. Disable Secure Boot","text":"<p>Verify Current Secure Boot Status:</p> <pre><code>mokutil --sb-state\n</code></pre> <p>Expected output when disabled: <pre><code>SecureBoot disabled\n</code></pre></p> <p>To Disable Secure Boot:</p> <ol> <li>Reboot your system</li> <li>Press F2 (or your system's BIOS key) during POST</li> <li>Navigate to the Security or Boot settings</li> <li>Disable Secure Boot</li> <li>Save changes and exit</li> </ol>"},{"location":"appendix/nvidia-old-driver/#2-download-nvidia-driver","title":"2. Download NVIDIA Driver","text":"<p>Visit the NVIDIA Driver Downloads page:</p> <ol> <li>Select your operating system:</li> <li>Operating System: <code>Linux 64-bit</code></li> <li> <p>Distribution: <code>Red Hat Enterprise Linux 10</code></p> </li> <li> <p>Select CUDA Toolkit version:</p> </li> <li>Choose the CUDA version you plan to use (e.g., CUDA 13.1 or later)</li> <li> <p>For RTX 3090/5090, ensure you select a driver version that supports these GPUs</p> </li> <li> <p>Download the RPM package:</p> </li> <li>Example: <code>nvidia-driver-local-repo-rhel10-580.126.09.x86_64.rpm</code></li> </ol> <p>Transfer the downloaded RPM to your RHEL 10 system.</p>"},{"location":"appendix/nvidia-old-driver/#3-install-driver-repository","title":"3. Install Driver Repository","text":"<pre><code># Navigate to download location\ncd /path/to/downloads\n\n# Install the local repository RPM\nsudo yum localinstall ./nvidia-driver-local-repo-rhel10-580.126.09.x86_64.rpm\n</code></pre> <p>Verify repository installation:</p> <pre><code>sudo yum repolist\n</code></pre> <p>You should see the NVIDIA repository listed: <pre><code>nvidia-driver-local-rhel10-580.126.09  nvidia-driver-local-rhel10-580.126.09\n</code></pre></p>"},{"location":"appendix/nvidia-old-driver/#4-install-dkms","title":"4. Install DKMS","text":"<p>DKMS is not included in RHEL by default. It is available through EPEL (Extra Packages for Enterprise Linux).</p> <p>Install EPEL repository:</p> <pre><code>sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n</code></pre> <p>Install DKMS:</p> <pre><code>sudo yum install dkms\n</code></pre> <p>Optional - Disable/Remove EPEL after installation:</p> <p>To disable EPEL (keep installed but inactive): <pre><code>sudo vi /etc/yum.repos.d/epel.repo\n# Change \"enabled=1\" to \"enabled=0\"\n</code></pre></p> <p>To completely remove EPEL: <pre><code>sudo yum remove epel-release\n</code></pre></p>"},{"location":"appendix/nvidia-old-driver/#5-install-development-tools","title":"5. Install Development Tools","text":"<p>Ensure your Red Hat subscription is active and attached.</p> <p>Install Development Tools:</p> <pre><code>sudo yum groupinstall \"Development Tools\"\n</code></pre> <p>Install kernel headers and development packages:</p> <pre><code>sudo yum install kernel-devel-$(uname -r)\n</code></pre>"},{"location":"appendix/nvidia-old-driver/#6-install-cuda-driver","title":"6. Install CUDA Driver","text":"<pre><code>sudo yum install cuda-driver\n</code></pre> <p>This will install the NVIDIA driver along with CUDA components compatible with your selected version.</p>"},{"location":"appendix/nvidia-old-driver/#7-verify-installation","title":"7. Verify Installation","text":"<p>Check DKMS status:</p> <pre><code>sudo dkms status\n</code></pre> <p>Expected output: <pre><code>nvidia/580.126.09, 4.18.0-425.3.1.el8.x86_64, x86_64: installed\n</code></pre></p> <p>Troubleshooting DKMS status:</p> <p>If status shows <code>added</code> instead of <code>installed</code>: <pre><code>sudo dkms build nvidia/580.126.09\n</code></pre></p> <p>If status shows <code>built</code> but not <code>installed</code>: <pre><code>sudo dkms install nvidia/580.126.09\n</code></pre></p> <p>If build or installation fails, check logs: <pre><code>sudo ls /var/lib/dkms/nvidia/580.126.09/$(uname -r)/x86_64/log/make.log\n</code></pre></p>"},{"location":"appendix/nvidia-old-driver/#8-reboot-system","title":"8. Reboot System","text":"<pre><code>sudo systemctl reboot\n</code></pre>"},{"location":"appendix/nvidia-old-driver/#9-post-installation-verification","title":"9. Post-Installation Verification","text":"<p>After reboot, verify the driver is loaded and functioning correctly.</p> <p>Check loaded kernel modules:</p> <pre><code>sudo lsmod | grep nvidia\n</code></pre> <p>Expected output: <pre><code>nvidia_drm             73728  0\nnvidia_modeset       1306624  1 nvidia_drm\nnvidia_uvm           1523712  0\nnvidia              56426496  2 nvidia_uvm,nvidia_modeset\ndrm_kms_helper        176128  4 qxl,nvidia_drm\ndrm                   565248  7 drm_kms_helper,qxl,nvidia,drm_ttm_helper,nvidia_drm,ttm\n</code></pre></p> <p>Run nvidia-smi to check GPU status:</p> <pre><code>sudo nvidia-smi\n</code></pre> <p>Expected output (example with multiple GPUs): <pre><code>+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.126.09     Driver Version: 580.126.09     CUDA Version: 13.1          |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n| 30%   35C    P8              25W / 350W |      0MiB / 24576MiB |      0%      Default |\n+-----------------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce RTX 5090        Off | 00000000:02:00.0 Off |                  N/A |\n| 30%   33C    P8              28W / 450W |      0MiB / 32768MiB |      0%      Default |\n+-----------------------------------------+----------------------+----------------------+\n</code></pre></p> <p>Verify driver module information:</p> <pre><code>sudo modinfo nvidia\n</code></pre> <p>This displays detailed information about the NVIDIA kernel module, including version and supported firmware.</p>"},{"location":"appendix/nvidia-old-driver/#troubleshooting","title":"Troubleshooting","text":""},{"location":"appendix/nvidia-old-driver/#black-screen-after-reboot-graphical-target","title":"Black Screen After Reboot (Graphical Target)","text":"<p>If your system boots to a black screen when running <code>graphical.target</code>:</p> <pre><code># Boot to recovery mode or multi-user target\n# Then move the X11 configuration:\nsudo mv /etc/X11/xorg.conf.d/10-nvidia.conf /root/10-nvidia.conf.backup\nsudo systemctl reboot\n</code></pre>"},{"location":"appendix/nvidia-old-driver/#gpu-passthrough-for-kvm-virtual-machines","title":"GPU Passthrough for KVM Virtual Machines","text":"<p>If using GPU passthrough with KVM, boot the hypervisor into <code>multi-user.target</code> instead of <code>graphical.target</code>:</p> <pre><code>sudo systemctl set-default multi-user.target\nsudo systemctl reboot\n</code></pre> <p>The graphical target prevents the NVIDIA driver from unloading properly before VM passthrough.</p>"},{"location":"appendix/nvidia-old-driver/#driver-build-failures","title":"Driver Build Failures","text":"<p>Check DKMS logs for detailed error messages:</p> <pre><code>sudo cat /var/lib/dkms/nvidia/580.126.09/$(uname -r)/x86_64/log/make.log\n</code></pre> <p>Common issues: - Missing kernel headers: <code>sudo yum install kernel-devel-$(uname -r)</code> - Missing development tools: <code>sudo yum groupinstall \"Development Tools\"</code> - Kernel version mismatch: Ensure running kernel matches installed headers</p>"},{"location":"appendix/nvidia-old-driver/#collecting-diagnostic-information","title":"Collecting Diagnostic Information","text":"<p>If you need to contact support, collect the following:</p> <pre><code># Generate system report\nsudo sosreport\n\n# DKMS logs\nsudo tar -czf dkms-logs.tar.gz /var/lib/dkms/nvidia/*/log/\n\n# NVIDIA installer logs (if present)\nsudo tar -czf nvidia-logs.tar.gz /var/log/nvidia-installer.log\n</code></pre>"},{"location":"appendix/nvidia-old-driver/#known-issues","title":"Known Issues","text":"<ul> <li>Multiple GPU Performance: Ensure adequate power supply and PCIe bandwidth for multi-GPU configurations</li> <li>Mixed GPU Models: RTX 3090 and RTX 5090 can coexist but may require specific CUDA versions</li> <li>Kernel Updates: After kernel updates, DKMS will automatically rebuild the driver for the new kernel</li> </ul>"},{"location":"appendix/nvidia-old-driver/#additional-resources","title":"Additional Resources","text":"<ul> <li>NVIDIA Driver Documentation</li> <li>RHEL DKMS Information</li> <li>NVIDIA CUDA Toolkit Documentation</li> <li>Detailed Installation Blog Post</li> </ul>"},{"location":"appendix/nvidia-old-driver/#license","title":"License","text":"<p>This guide is provided as-is for educational and informational purposes.</p>"},{"location":"appendix/nvidia-old-driver/#contributing","title":"Contributing","text":"<p>Contributions, corrections, and improvements are welcome. Please submit a pull request or open an issue.</p> <p>Last Updated: February 2026 RHEL Version: 10 Tested GPUs: RTX 3090, RTX 5090 Driver Version: 580.126.09 (example)</p>"},{"location":"appendix/redhat-nvidia/","title":"RHEL NVIDIA Driver Installation with DKMS","text":"<p>This guide covers compiling and installing an NVIDIA driver with DKMS in Red Hat Enterprise Linux with Secure Boot disabled.</p> <p>Secure Boot</p> <p>Ensure Secure Boot is disabled in BIOS before proceeding. DKMS compiles the driver from source without a vendor signature. If Secure Boot is enabled, the driver fails to load with \"Required key not available\".</p> <p>Verify status: <code>mokutil --sb-state</code></p> <p>Alternative for Secure Boot</p> <p>If Secure Boot is required, see Red Hat article: \"How to Install NVIDIA Driver Online in Red Hat Enterprise Linux with Secure Boot Enabled\"</p>"},{"location":"appendix/redhat-nvidia/#step-1-download-driver","title":"Step 1: Download Driver","text":"<ol> <li>Go to the NVIDIA website</li> <li>Select Red Hat Enterprise Linux 10</li> <li>Select CUDA version (e.g., 13.1)</li> <li>Download the RPM (e.g., <code>nvidia-driver-local-repo-rhel10-580.126.09.x86_64.rpm</code>)</li> </ol>"},{"location":"appendix/redhat-nvidia/#step-2-install-local-repository","title":"Step 2: Install Local Repository","text":"<pre><code>sudo yum localinstall ./nvidia-driver-local-repo-rhel10-580.126.09.x86_64.rpm\nsudo yum repolist\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-3-install-dkms","title":"Step 3: Install DKMS","text":"<p>DKMS is available from EPEL (Extra Packages for Enterprise Linux):</p> <pre><code>sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\nsudo yum install dkms\n</code></pre> <p>To disable EPEL after installation:</p> <pre><code>sudo vi /etc/yum.repos.d/epel.repo\n# Change to: enabled=0\n</code></pre> <p>Or remove completely:</p> <pre><code>sudo yum remove epel-release\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-4-install-build-tools-and-kernel-headers","title":"Step 4: Install Build Tools and Kernel Headers","text":"<p>Ensure Red Hat subscription is attached:</p> <pre><code>sudo yum groupinstall \"Development Tools\"\nsudo yum install kernel-devel-$(uname -r)\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-5-install-cuda-driver","title":"Step 5: Install CUDA Driver","text":"<pre><code>sudo yum install cuda-driver\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-6-verify-installation","title":"Step 6: Verify Installation","text":"<pre><code>sudo dkms status\n# Expected: nvidia/580.126.09, x86_64: installed\n</code></pre> <p>If status shows \"Added\" instead of \"installed\":</p> <pre><code>sudo dkms build nvidia/580.126.09\nsudo dkms install nvidia/580.126.09\n</code></pre> <p>If build/install fails, check logs:</p> <pre><code>sudo cat /var/lib/dkms/nvidia/580.126.09/$(uname -r)/x86_64/log/make.log\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-7-reboot","title":"Step 7: Reboot","text":"<pre><code>sudo systemctl reboot\n</code></pre>"},{"location":"appendix/redhat-nvidia/#step-8-verify-driver","title":"Step 8: Verify Driver","text":"<pre><code>sudo lsmod | grep nvidia\nsudo nvidia-smi\nsudo modinfo nvidia\n</code></pre> <p>Expected output from <code>lsmod</code>:</p> <pre><code>nvidia_drm             73728  0\nnvidia_modeset       1306624  1 nvidia_drm\nnvidia_uvm           1523712  0\nnvidia              56426496  2 nvidia_uvm,nvidia_modeset\n</code></pre>"},{"location":"appendix/redhat-nvidia/#troubleshooting","title":"Troubleshooting","text":""},{"location":"appendix/redhat-nvidia/#black-screen-after-reboot-graphical-target","title":"Black Screen After Reboot (Graphical Target)","text":"<p>If RHEL boots to graphical.target and shows black screen:</p> <pre><code>sudo mv /etc/X11/xorg.conf.d/10-nvidia.conf /root/\nsudo systemctl reboot\n</code></pre>"},{"location":"appendix/redhat-nvidia/#gpu-passthrough-to-kvm-vm","title":"GPU Passthrough to KVM VM","text":"<p>If passing GPU to VM with graphical.target enabled, it will fail. Boot hypervisor to multi-user.target:</p> <pre><code>sudo systemctl set-default multi-user.target\n</code></pre>"},{"location":"appendix/redhat-nvidia/#support","title":"Support","text":"<p>Collect these logs for Dell Support:</p> <ul> <li><code>sosreport</code></li> <li>Build/make log files</li> <li><code>/var/log/nvidia-installer.log</code></li> </ul>"},{"location":"appendix/redhat-nvidia/#references","title":"References","text":"<ul> <li>Step-by-Step NVIDIA Driver CUDA Toolkit Install for RHEL9</li> </ul>"},{"location":"guide/","title":"Deployment Guide","text":"<p>This guide walks you through the complete installation of an on-premise LLM server, from hardware procurement to production deployment.</p>"},{"location":"guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic Linux administration experience</li> <li>Access to enterprise hardware procurement</li> <li>RHEL subscription or evaluation license</li> <li>Network access for software downloads</li> </ul>"},{"location":"guide/#steps-overview","title":"Steps Overview","text":"Step Description Time Estimate Step 1: Hardware Hardware procurement and assembly 1-2 weeks Step 2: RHEL Red Hat Enterprise Linux installation 2-4 hours Step 3: NVIDIA NVIDIA driver installation 1-2 hours Step 4: App Stack Software stack deployment 2-3 hours Step 5: WebUI &amp; vLLM Open WebUI and vLLM deployment 1-2 hours Step 6: AD Integration Active Directory integration 2-4 hours <p>Total Estimated Time: 2-3 days (excluding hardware procurement)</p>"},{"location":"guide/#quick-start","title":"Quick Start","text":"<ol> <li>Start with Step 1: Hardware to understand hardware requirements</li> <li>Follow each step sequentially</li> <li>Refer to the Appendix for troubleshooting and additional notes</li> </ol>"},{"location":"guide/step1-hardware/","title":"LLM Hardware Requirements and Build Guide","text":"<p>Complete hardware specification and assembly guide for building a high-performance, cost-effective multi-GPU LLM inference workstation using enterprise-grade components sourced from eBay.</p>"},{"location":"guide/step1-hardware/#overview","title":"Overview","text":"<p>This guide provides detailed instructions for building a professional-grade LLM inference workstation optimized for running large language models with multiple GPU configurations. The system leverages enterprise server components purchased used from eBay to provide exceptional performance at a fraction of the cost of new equipment.</p>"},{"location":"guide/step1-hardware/#system-highlights","title":"System Highlights","text":"Component Specification GPUs 5 total: 4x RTX 3090 (24GB each) + 1x RTX 5090 (32GB) = 128GB GPU memory CPU AMD EPYC 7443P, 24 cores / 48 threads, unlocked RAM 256GB DDR4 ECC PCIe 7x PCIe 4.0 x16 slots (ASRock ROMED8-2T) Power 3200W total (dual 1600W PSUs) Storage 4TB NVMe Gen4"},{"location":"guide/step1-hardware/#target-use-cases","title":"Target Use Cases","text":"<ul> <li>Large language model inference (Llama 3.1 70B, Mixtral 8x22B, etc.)</li> <li>Multi-model serving</li> <li>Fine-tuning and training medium-sized models</li> <li>Research and development</li> <li>Production LLM deployment</li> </ul>"},{"location":"guide/step1-hardware/#cost-summary","title":"Cost Summary","text":"Price Range Used Parts (eBay) $7,000 - $9,000 New Equivalent $18,000 - $25,000"},{"location":"guide/step1-hardware/#system-specifications","title":"System Specifications","text":"Component Specification Purpose Motherboard ASRock ROMED8-2T 7\u00d7 PCIe 4.0 x16 slots for multi-GPU CPU AMD EPYC 7443P (unlocked) 24C/48T, 2.85GHz base, 4.0GHz boost CPU Cooler Noctua NH-U14S TR4-SP3 or Dynatron A26 SP3 socket compatible RAM 256GB DDR4-3200 ECC (8\u00d7 32GB) Large model loading and caching GPU Primary 4\u00d7 NVIDIA RTX 3090 24GB Main inference workhorses GPU Secondary 1\u00d7 NVIDIA RTX 5090 32GB Latest architecture, highest performance Storage 4TB NVMe Gen4 (Samsung 980 Pro or similar) Models, datasets, cache PSU 2\u00d7 1600W 80+ Platinum/Titanium Dual PSU for 5 GPUs PCIe Risers 5\u00d7 PCIe 4.0 x16 Riser Cables Flexible GPU placement Case Open-air mining rig frame Optimal cooling and accessibility Monitor 24\" 1080p or 27\" 1440p System management Keyboard/Mouse Standard USB Basic I/O"},{"location":"guide/step1-hardware/#complete-parts-list","title":"Complete Parts List","text":""},{"location":"guide/step1-hardware/#required-components","title":"Required Components","text":""},{"location":"guide/step1-hardware/#1-motherboard","title":"1. Motherboard","text":"<p>ASRock ROMED8-2T</p> <p>Specifications: - Socket: AMD SP3 (EPYC 7001/7002/7003 series) - PCIe Slots: 7\u00d7 PCIe 4.0 x16 (full electrical x16) - Memory: 8\u00d7 DDR4 DIMM slots, up to 2TB, ECC support - M.2 Slots: 2\u00d7 M.2 (PCIe 4.0 x4) - Network: Dual 10GbE - Form Factor: EEB (12\" \u00d7 13\")</p> <p>eBay Search Terms: - \"ASRock ROMED8-2T motherboard\" - \"ROMED8-2T SP3\" - \"ASRock EPYC 7 PCIe motherboard\"</p> <p>What to Look For: - \u2705 All PCIe slots intact - \u2705 No bent pins in SP3 socket - \u2705 Includes I/O shield - \u2705 BIOS version 1.40 or higher - \u2705 Seller offers returns</p> <p>Expected Price: $400 - $700 used</p>"},{"location":"guide/step1-hardware/#2-cpu","title":"2. CPU","text":"<p>AMD EPYC 7443P (Unlocked)</p> <p>Specifications: - Cores/Threads: 24C/48T - Base Clock: 2.85 GHz - Boost Clock: 4.0 GHz - Cache: 128MB L3 - TDP: 200W - Memory Support: DDR4-3200, 8-channel - PCIe Lanes: 128\u00d7 PCIe 4.0</p> <p>Why This CPU: - Unlocked multiplier for overclocking - Excellent single-thread and multi-thread performance - 128 PCIe 4.0 lanes (enough for 7 GPUs at full x16) - Strong price/performance ratio used</p> <p>eBay Search Terms: - \"AMD EPYC 7443P\" - \"EPYC 7443P unlocked\" - \"7443P Milan processor\"</p> <p>What to Look For: - \u2705 OPN: 100-000000340 - \u2705 Verify \"P\" suffix (unlocked) - \u2705 No bent pins - \u2705 Thermal paste not hardened/crusted - \u2705 Comes from reputable seller</p> <p>Expected Price: $800 - $1,200 used</p>"},{"location":"guide/step1-hardware/#3-cpu-cooler","title":"3. CPU Cooler","text":"<p>Noctua NH-U14S TR4-SP3 or Dynatron A26</p> <p>Option 1: Noctua NH-U14S TR4-SP3 (Recommended for quiet operation) - Height: 165mm - Noise: 19.2 - 24.6 dB(A) - Includes SecuFirm2 SP3 mounting kit - Premium quality, 6-year warranty</p> <p>Option 2: Dynatron A26 (Server-grade, higher airflow) - 2U height compatible - High-static pressure fan - Designed for EPYC 7003 series - Louder but better for open-air rigs</p> <p>eBay Search Terms: - \"Noctua NH-U14S TR4-SP3\" - \"SP3 CPU cooler EPYC\" - \"Dynatron A26\" - \"Threadripper SP3 cooler\"</p> <p>Expected Price: $60 - $120 used</p>"},{"location":"guide/step1-hardware/#4-memory","title":"4. Memory","text":"<p>256GB DDR4 ECC (8\u00d7 32GB DIMMs)</p> <p>Specifications: - Type: DDR4 ECC RDIMM or LRDIMM - Speed: 3200MHz (PC4-25600) - Configuration: 8\u00d7 32GB sticks - Rank: 2Rx4 or 4Rx4 - Voltage: 1.2V</p> <p>Recommended Brands: - Samsung (M393A4K40DB3-CWE) - Micron - SK Hynix - Kingston Server Premier</p> <p>eBay Search Terms: - \"32GB DDR4 3200 ECC RDIMM\" - \"Samsung 32GB DDR4 server memory\" - \"DDR4 ECC 3200 EPYC\"</p> <p>What to Look For: - \u2705 Match speeds (all 3200MHz) - \u2705 Match types (all RDIMM or all LRDIMM) - \u2705 Same manufacturer (preferred for stability) - \u2705 Tested/working condition</p> <p>Expected Price: $400 - $650 for 256GB set</p> <p>Pro Tip: You can start with 128GB (4\u00d7 32GB) and add more later. Populate all 8 channels for best performance (8\u00d7 16GB or 8\u00d7 32GB).</p>"},{"location":"guide/step1-hardware/#5-graphics-cards","title":"5. Graphics Cards","text":"<p>Primary GPUs: 4\u00d7 NVIDIA RTX 3090 (24GB)</p> <p>Specifications: - CUDA Cores: 10,496 - Memory: 24GB GDDR6X - Memory Bandwidth: 936 GB/s - TDP: 350W - Power Connectors: 2\u00d7 8-pin or 3\u00d7 8-pin</p> <p>Recommended Models: - Founders Edition (best cooling) - ASUS TUF Gaming - EVGA FTW3 - MSI Gaming X Trio</p> <p>Avoid: - Single-fan blower models (poor cooling) - Cards with obvious physical damage - Cards used for mining 24/7 (if disclosed)</p> <p>eBay Search Terms: - \"RTX 3090 24GB\" - \"NVIDIA RTX 3090 Founders Edition\" - \"RTX 3090 ASUS TUF\"</p> <p>Expected Price: $650 - $900 each \u00d7 4 = $2,600 - $3,600</p> <p>Secondary GPU: 1\u00d7 NVIDIA RTX 5090 (32GB)</p> <p>Specifications: - CUDA Cores: 21,760 - Memory: 32GB GDDR7 - Memory Bandwidth: 1,792 GB/s - TDP: 575W - Power Connectors: 1\u00d7 12VHPWR (600W)</p> <p>Note: RTX 5090 is brand new as of 2025, so used prices may not be available yet. Consider new or refurbished.</p> <p>Alternatives if RTX 5090 too expensive: - RTX 4090 (24GB) - still excellent - 5th RTX 3090 for uniformity</p> <p>eBay Search Terms: - \"RTX 5090 32GB\" - \"NVIDIA GeForce RTX 5090\"</p> <p>Expected Price: $1,500 - $2,000 (may need to buy new)</p>"},{"location":"guide/step1-hardware/#6-storage","title":"6. Storage","text":"<p>4TB NVMe Gen4 SSD</p> <p>Recommended Models: - Samsung 990 Pro 4TB - WD Black SN850X 4TB - Crucial T700 4TB - Seagate FireCuda 530 4TB</p> <p>Specifications: - Interface: M.2 2280, PCIe 4.0 x4 - Sequential Read: 7,000+ MB/s - Sequential Write: 6,000+ MB/s - Endurance: 2,400+ TBW</p> <p>eBay Search Terms: - \"4TB NVMe Gen4\" - \"Samsung 990 Pro 4TB\" - \"M.2 4TB PCIe 4.0\"</p> <p>What to Look For: - \u2705 Check SMART health data - \u2705 Low power-on hours - \u2705 Good endurance remaining (&gt;90%) - \u2705 Includes heatsink or buy separately</p> <p>Expected Price: $200 - $350 used</p> <p>Alternative: Start with 2TB and add second drive later.</p>"},{"location":"guide/step1-hardware/#7-power-supplies","title":"7. Power Supplies","text":"<p>2\u00d7 1600W 80+ Platinum or Titanium PSUs</p> <p>Why Dual PSU: - Total GPU power: ~2,125W (4\u00d7 350W + 1\u00d7 575W) - CPU: 200W - System: ~100W - Total: ~2,425W - 2\u00d7 1600W = 3,200W capacity (good headroom)</p> <p>Recommended Server PSUs: - HP 1600W 80+ Platinum (DPS-1600AB A, 750504-001) - Delta 1600W 80+ Platinum - Cisco UCSC-PSU2-1600W - IBM 1600W</p> <p>eBay Search Terms: - \"1600W server PSU platinum\" - \"HP 1600W power supply\" - \"Dell 1600W PSU\"</p> <p>What to Look For: - \u2705 80+ Platinum or Titanium efficiency - \u2705 Includes breakout board or buy X11 board - \u2705 All cables included - \u2705 Tested working</p> <p>Expected Price: $80 - $150 each \u00d7 2 = $160 - $300</p> <p>Also Need: - 2\u00d7 X11 or X12 PSU Breakout Boards ($15-30 each) - PCIe 6-pin to 8-pin cables (for GPUs) - 24-pin ATX adapter for motherboard</p>"},{"location":"guide/step1-hardware/#8-pcie-riser-cables","title":"8. PCIe Riser Cables","text":"<p>5\u00d7 PCIe 4.0 x16 Riser Cables</p> <p>Specifications: - Standard: PCIe 4.0 - Length: 30cm - 50cm (depending on case layout) - Connectors: x16 to x16 - Shielding: Required for PCIe 4.0 speeds</p> <p>Recommended Brands: - Thermaltake TT Premium PCIe 4.0 - LINKUP Ultra PCIe 4.0 - ASUS ROG Strix Riser Cable</p> <p>eBay Search Terms: - \"PCIe 4.0 riser cable x16\" - \"PCIe Gen4 extender 40cm\" - \"mining riser cable PCIe 4.0\"</p> <p>What to Look For: - \u2705 PCIe 4.0 certified (not 3.0) - \u2705 Proper shielding - \u2705 Correct length for your frame - \u2705 Angled connectors (helpful for tight spaces)</p> <p>Expected Price: $25 - $50 each \u00d7 5 = $125 - $250</p> <p>Note: You can mount 2 GPUs directly on motherboard and use 3 risers to save cost.</p>"},{"location":"guide/step1-hardware/#9-open-air-mining-rig-frame","title":"9. Open-Air Mining Rig Frame","text":"<p>8-GPU Compatible Frame</p> <p>Specifications: - Material: Steel or aluminum - GPU Capacity: 8-12 GPUs - Dimensions: ~90cm \u00d7 45cm \u00d7 45cm - Includes: GPU mounting brackets, PSU mounting</p> <p>Recommended Features: - Adjustable GPU spacing - Sturdy construction (steel preferred) - Stackable design - Cable management provisions</p> <p>eBay Search Terms: - \"8 GPU mining rig frame\" - \"open air mining case 12 GPU\" - \"cryptocurrency mining frame\" - \"GPU rig chassis steel\"</p> <p>What to Look For: - \u2705 Heavy-duty construction - \u2705 All mounting hardware included - \u2705 Motherboard mounting tray - \u2705 PSU mounting brackets (for 2 PSUs)</p> <p>Expected Price: $80 - $150 used</p> <p>Alternative: Build your own with aluminum extrusion.</p>"},{"location":"guide/step1-hardware/#10-monitor-keyboard-mouse","title":"10. Monitor, Keyboard, Mouse","text":"<p>Monitor: - 24\" 1080p or 27\" 1440p - IPS panel preferred - HDMI or DisplayPort input - Expected Price: $80 - $150 used</p> <p>Keyboard: - Standard USB keyboard - Mechanical or membrane - Expected Price: $15 - $40 used</p> <p>Mouse: - USB wired or wireless - Basic optical mouse sufficient - Expected Price: $10 - $25 used</p> <p>eBay Search Terms: - \"24 inch monitor 1080p\" - \"Dell monitor P2419H\" - \"USB keyboard\" - \"Logitech wireless mouse\"</p>"},{"location":"guide/step1-hardware/#additional-required-components","title":"Additional Required Components","text":""},{"location":"guide/step1-hardware/#11-thermal-paste","title":"11. Thermal Paste","text":"<p>High-Performance Thermal Compound</p> <ul> <li>Noctua NT-H1 or NT-H2</li> <li>Thermal Grizzly Kryonaut</li> <li>Arctic MX-5</li> </ul> <p>Expected Price: $8 - $15</p>"},{"location":"guide/step1-hardware/#12-additional-fans","title":"12. Additional Fans","text":"<p>Case Fans for GPU Cooling</p> <p>Recommended: - 3-5\u00d7 120mm or 140mm fans - High static pressure fans - PWM control preferred</p> <p>Models: - Noctua NF-P12 redux - Arctic P12 PWM - be quiet! Pure Wings 2</p> <p>Expected Price: $10 - $20 each \u00d7 3-5 = $30 - $100</p>"},{"location":"guide/step1-hardware/#13-power-distribution","title":"13. Power Distribution","text":"<p>PSU Breakout Boards and Cables</p> <p>Required: - 2\u00d7 X11/X12 Server PSU Breakout Boards - ATX 24-pin adapter - Multiple PCIe 8-pin cables - SATA power cables</p> <p>Expected Price: $50 - $100 total</p>"},{"location":"guide/step1-hardware/#14-cable-ties-and-management","title":"14. Cable Ties and Management","text":"<p>Organization Supplies</p> <ul> <li>100pk Velcro cable ties</li> <li>Zip ties (various sizes)</li> <li>Cable sleeves (optional)</li> <li>Label maker or labels</li> </ul> <p>Expected Price: $15 - $30</p>"},{"location":"guide/step1-hardware/#15-anti-static-wrist-strap","title":"15. Anti-Static Wrist Strap","text":"<p>ESD Protection</p> <p>Essential for handling components safely.</p> <p>Expected Price: $5 - $10</p>"},{"location":"guide/step1-hardware/#16-toolkit","title":"16. Toolkit","text":"<p>Screwdriver Set</p> <ul> <li>Phillips #1 and #2</li> <li>Magnetic tip preferred</li> <li>Hex drivers (if needed)</li> </ul> <p>Expected Price: $15 - $30</p>"},{"location":"guide/step1-hardware/#sourcing-components-on-ebay","title":"Sourcing Components on eBay","text":""},{"location":"guide/step1-hardware/#general-ebay-shopping-tips","title":"General eBay Shopping Tips","text":"<p>1. Search Strategies: <pre><code>Use multiple search terms:\n- \"ASRock ROMED8-2T\" + \"SP3\"\n- \"RTX 3090\" + \"ASUS\" + \"working\"\n- \"EPYC 7443P\" + \"unlocked\"\n\nSet alerts for new listings\nUse \"Sold Listings\" to gauge market price\n</code></pre></p> <p>2. Seller Evaluation: - \u2705 98%+ positive feedback - \u2705 &gt;100 transactions - \u2705 Returns accepted (14-30 days) - \u2705 \"Top Rated Seller\" badge - \u2705 Detailed photos of actual item - \u2705 Clear description of condition</p> <p>3. Listing Red Flags: - \u274c Stock photos only - \u274c Vague description (\"untested\", \"as-is\") - \u274c New seller with expensive items - \u274c No returns accepted - \u274c Suspiciously low price</p> <p>4. Best Offers: - Most sellers accept 10-15% off asking price - Start at 20% below asking - Be polite and reasonable - Bundle multiple items for better deals</p> <p>5. Timing: - Best deals: Tuesday-Thursday evenings - Avoid: Weekend bidding wars - End of month: Sellers more motivated</p>"},{"location":"guide/step1-hardware/#component-specific-sourcing","title":"Component-Specific Sourcing","text":""},{"location":"guide/step1-hardware/#motherboard-romed8-2t","title":"Motherboard (ROMED8-2T)","text":"<p>Questions to Ask Seller: - \"Has this been tested? What CPU/RAM?\" - \"Are all PCIe slots working?\" - \"What BIOS version is installed?\" - \"Any included accessories (SATA cables, etc.)?\"</p> <p>Test Before Purchase: Request seller to test with CPU if possible.</p>"},{"location":"guide/step1-hardware/#cpu-epyc-7443p","title":"CPU (EPYC 7443P)","text":"<p>Questions to Ask Seller: - \"What was this CPU used for?\" - \"How many hours of runtime?\" - \"Was it overclocked?\" - \"Confirm OPN: 100-000000340\"</p> <p>Verification: OPN marking on CPU IHS should read 100-000000340.</p>"},{"location":"guide/step1-hardware/#gpus-rtx-30905090","title":"GPUs (RTX 3090/5090)","text":"<p>Questions to Ask Seller: - \"Was this used for mining?\" - \"What are the temps under load?\" - \"Any coil whine or artifacts?\" - \"Will you provide GPU-Z screenshot?\"</p> <p>Red Flags: - Mining operation sales (24/7 usage) - Repasted recently (may indicate overheating issues) - Missing backplate or shroud</p>"},{"location":"guide/step1-hardware/#memory-256gb-ddr4-ecc","title":"Memory (256GB DDR4 ECC)","text":"<p>Questions to Ask Seller: - \"Has this been tested with MemTest86?\" - \"Any errors in BIOS detection?\" - \"What server/motherboard was this used in?\"</p> <p>Tip: Buy all from same seller if possible for matched set.</p>"},{"location":"guide/step1-hardware/#cost-breakdown","title":"Cost Breakdown","text":""},{"location":"guide/step1-hardware/#detailed-budget-used-parts-from-ebay","title":"Detailed Budget (Used Parts from eBay)","text":"Component Quantity Unit Price Total ASRock ROMED8-2T 1 $400-700 $550 AMD EPYC 7443P 1 $800-1,200 $1,000 SP3 CPU Cooler 1 $60-120 $90 32GB DDR4 ECC 8 $50-80 $560 RTX 3090 24GB 4 $650-900 $3,000 RTX 5090 32GB 1 $1,500-2,000 $1,750 4TB NVMe Gen4 1 $200-350 $275 1600W PSU 2 $80-150 $240 PCIe 4.0 Riser 5 $25-50 $175 Mining Rig Frame 1 $80-150 $115 Monitor 24\" 1 $80-150 $115 Keyboard 1 $15-40 $25 Mouse 1 $10-25 $15 PSU Breakout Boards 2 $15-30 $45 Case Fans 4 $10-20 $60 Thermal Paste 1 $8-15 $12 Cables/Accessories - - $75 TOTAL $8,102 <p>Budget Range: $7,000 - $9,000 depending on deals</p> <p>Cost Savings vs New: ~$12,000 - $16,000</p>"},{"location":"guide/step1-hardware/#pre-build-preparation","title":"Pre-Build Preparation","text":""},{"location":"guide/step1-hardware/#1-workspace-setup","title":"1. Workspace Setup","text":"<p>Requirements: - Large work surface (6ft \u00d7 3ft minimum) - Good lighting (overhead + task light) - Anti-static mat (or cardboard) - Organize parts by category</p> <p>Checklist: - [ ] Clear, clean workspace - [ ] Anti-static protection - [ ] Tools laid out - [ ] All parts unboxed and verified - [ ] Assembly instructions printed</p>"},{"location":"guide/step1-hardware/#2-inventory-check","title":"2. Inventory Check","text":"<p>Verify you have: - [ ] Motherboard with I/O shield - [ ] CPU with no bent pins - [ ] CPU cooler with mounting hardware - [ ] All 8 RAM sticks - [ ] All 5 GPUs - [ ] NVMe drive - [ ] 2\u00d7 PSUs with cables - [ ] 5\u00d7 PCIe risers - [ ] Mining frame with all brackets - [ ] Monitor, keyboard, mouse - [ ] Thermal paste - [ ] Cable ties - [ ] Screwdriver set</p>"},{"location":"guide/step1-hardware/#3-component-testing-optional-but-recommended","title":"3. Component Testing (Optional but Recommended)","text":"<p>Motherboard + CPU + RAM Test: Before full assembly, test core components:</p> <ol> <li>Place motherboard on anti-static surface</li> <li>Install CPU and cooler</li> <li>Install 1 stick of RAM in slot A1</li> <li>Connect PSU (24-pin + 8-pin CPU)</li> <li>Connect monitor to onboard video (if available) or install 1 GPU</li> <li>Power on and enter BIOS</li> <li>Verify CPU and RAM detected</li> <li>Power off and proceed with full build</li> </ol>"},{"location":"guide/step1-hardware/#assembly-instructions","title":"Assembly Instructions","text":""},{"location":"guide/step1-hardware/#step-1-assemble-mining-rig-frame","title":"Step 1: Assemble Mining Rig Frame","text":"<p>Time Required: 30-45 minutes</p> <ol> <li>Lay out all frame parts</li> <li>Base rails</li> <li>Vertical supports</li> <li>GPU mounting bars</li> <li>Motherboard tray</li> <li> <p>PSU brackets</p> </li> <li> <p>Assemble base frame</p> </li> <li>Connect base rails with vertical supports</li> <li>Use provided bolts/screws</li> <li> <p>Ensure frame is square and level</p> </li> <li> <p>Install motherboard tray</p> </li> <li>Mount tray to frame</li> <li>Position for cable access from bottom</li> <li> <p>Leave space for PSU(s) below</p> </li> <li> <p>Install GPU mounting bars</p> </li> <li>Space bars 2-3 slots apart (depends on GPU thickness)</li> <li>Allow 40-50mm between GPUs for airflow</li> <li> <p>Position for riser cable routing</p> </li> <li> <p>Install PSU mounting brackets</p> </li> <li>Bottom of frame or rear mounting</li> <li>Ensure both PSUs fit</li> <li> <p>Fan orientation: intake from outside</p> </li> <li> <p>Verify stability</p> </li> <li>Frame should not wobble</li> <li>All connections tight</li> <li>Ready for component installation</li> </ol>"},{"location":"guide/step1-hardware/#step-2-install-cpu-and-cooler-on-motherboard","title":"Step 2: Install CPU and Cooler on Motherboard","text":"<p>Time Required: 20-30 minutes</p> <p>\u26a0\ufe0f CRITICAL: Use anti-static protection throughout!</p> <ol> <li>Place motherboard on anti-static surface</li> <li>Use motherboard box or anti-static mat</li> <li> <p>Ensure good lighting</p> </li> <li> <p>Install CPU <pre><code>SP3 Socket Installation:\na. Lift CPU socket lever (may require significant force)\nb. Remove protective cover\nc. Align CPU triangle marker with socket triangle\nd. Gently place CPU - DO NOT FORCE\ne. CPU should drop into place with no pressure\nf. Close socket lever (requires firm pressure)\ng. Verify CPU is flush and secure\n</code></pre></p> </li> <li> <p>Apply thermal paste</p> </li> <li>Clean CPU IHS with isopropyl alcohol</li> <li>Apply pea-sized dot in center</li> <li> <p>Or use spread method for large EPYC die</p> </li> <li> <p>Install CPU cooler <pre><code>For Noctua NH-U14S TR4-SP3:\na. Install backplate on rear of motherboard\nb. Align mounting brackets over CPU\nc. Attach retention clips\nd. Lower heatsink onto CPU\ne. Secure with spring-loaded screws\nf. Tighten in cross pattern (don't over-tighten)\ng. Connect fan to CPU_FAN header\n</code></pre></p> </li> <li> <p>Verify installation</p> </li> <li>Cooler is firmly mounted</li> <li>No gaps between heatsink and CPU</li> <li>Fan spins freely</li> <li>Fan cable routed cleanly</li> </ol>"},{"location":"guide/step1-hardware/#step-3-install-memory","title":"Step 3: Install Memory","text":"<p>Time Required: 10-15 minutes</p> <p>ROMED8-2T Memory Configuration: - 8\u00d7 DIMM slots (4 channels \u00d7 2 DIMMs) - Channels: A, B, C, D - Slots per channel: 1, 2</p> <p>Population Order for 8\u00d7 32GB: <pre><code>Install in this order for 8-channel operation:\n1. A1 (furthest from CPU)\n2. B1\n3. C1\n4. D1\n5. A2\n6. B2\n7. C2\n8. D2\n</code></pre></p> <p>Installation Procedure: 1. Open DIMM slot latches 2. Align DIMM notch with slot key 3. Press down firmly until latches click (requires force) 4. Verify both latches are locked 5. Repeat for all 8 DIMMs</p> <p>Pro Tip: Install in pairs (A1+A2, B1+B2, etc.) for better organization.</p>"},{"location":"guide/step1-hardware/#step-4-install-nvme-drive","title":"Step 4: Install NVMe Drive","text":"<p>Time Required: 5 minutes</p> <p>ROMED8-2T has 2\u00d7 M.2 slots: - M.2_1: Near CPU (primary) - M.2_2: Near bottom (secondary)</p> <p>Installation: 1. Locate M.2_1 slot (check motherboard manual) 2. Remove retention screw 3. Insert NVMe drive at 30\u00b0 angle 4. Press down gently 5. Secure with retention screw 6. Install heatsink if included</p>"},{"location":"guide/step1-hardware/#step-5-mount-motherboard-in-frame","title":"Step 5: Mount Motherboard in Frame","text":"<p>Time Required: 15-20 minutes</p> <ol> <li>Install I/O shield</li> <li>Snap I/O shield into motherboard tray</li> <li>Ensure tight fit</li> <li> <p>Metal tabs face inward</p> </li> <li> <p>Position motherboard standoffs</p> </li> <li>ROMED8-2T is EEB (12\" \u00d7 13\")</li> <li>Install standoffs in all matching holes</li> <li> <p>Typically 9-10 standoffs for EEB</p> </li> <li> <p>Place motherboard on standoffs</p> </li> <li>Align with I/O shield</li> <li>Line up standoff holes</li> <li> <p>DO NOT force</p> </li> <li> <p>Secure motherboard</p> </li> <li>Install screws in cross pattern</li> <li>Finger-tight first, then snug</li> <li> <p>Don't over-tighten (risk of cracking)</p> </li> <li> <p>Verify installation</p> </li> <li>Motherboard is level</li> <li>No flex when pressing on corners</li> <li>I/O ports align with shield</li> </ol>"},{"location":"guide/step1-hardware/#step-6-install-power-supplies","title":"Step 6: Install Power Supplies","text":"<p>Time Required: 20 minutes</p> <ol> <li>Mount first PSU (PSU1 - Motherboard/CPU)</li> <li>Position fan facing outward for intake</li> <li>Secure with mounting screws</li> <li> <p>Route cables toward motherboard</p> </li> <li> <p>Mount second PSU (PSU2 - GPUs)</p> </li> <li>Position next to PSU1</li> <li>Same fan orientation</li> <li> <p>Route cables toward GPU area</p> </li> <li> <p>Install PSU breakout boards</p> </li> <li>Connect to 12V output on server PSUs</li> <li>Secure breakout boards to frame</li> <li> <p>Label: \"PSU1 - MOBO\" and \"PSU2 - GPU\"</p> </li> <li> <p>Cable preparation</p> </li> <li>Organize cables by function</li> <li>Don't connect to motherboard yet</li> <li>Keep extra cables bundled</li> </ol>"},{"location":"guide/step1-hardware/#step-7-connect-power-to-motherboard","title":"Step 7: Connect Power to Motherboard","text":"<p>Time Required: 10 minutes</p> <p>PSU1 Connections (Motherboard PSU):</p> <ol> <li>24-pin ATX power</li> <li>Locate ATX_PWR1 on motherboard</li> <li>Connect 24-pin from PSU breakout</li> <li> <p>Ensure latch clicks</p> </li> <li> <p>8-pin CPU power (\u00d72)</p> </li> <li>ROMED8-2T requires 2\u00d7 8-pin CPU power</li> <li>Locate CPU_PWR1 and CPU_PWR2 near CPU socket</li> <li>Connect both 8-pin EPS connectors</li> <li> <p>Essential for high CPU power delivery</p> </li> <li> <p>SATA/Peripheral power</p> </li> <li>Connect to NVMe heatsink fan (if applicable)</li> <li>Reserve for additional drives later</li> </ol> <p>Verify all connections are secure before proceeding.</p>"},{"location":"guide/step1-hardware/#step-8-install-gpus","title":"Step 8: Install GPUs","text":"<p>Time Required: 45-60 minutes</p> <p>GPU Installation Strategy:</p> <p>Direct PCIe Slots (No Riser): - GPU 1: PCIe Slot 1 (closest to CPU) - RTX 5090 - GPU 2: PCIe Slot 3 (skip slot 2 for spacing) - RTX 3090</p> <p>With PCIe Risers: - GPU 3: Riser to Slot 4 - RTX 3090 - GPU 4: Riser to Slot 5 - RTX 3090 - GPU 5: Riser to Slot 6 - RTX 3090</p> <p>Installation Procedure:</p> <p>For Direct PCIe Installation: 1. Remove PCIe slot covers from motherboard I/O area 2. Align GPU with PCIe slot 3. Press down firmly until click 4. Secure GPU bracket with screw 5. Leave power cables disconnected for now</p> <p>For Riser Installation: 1. Connect riser to PCIe slot on motherboard 2. Mount GPU on frame's GPU bars 3. Connect riser to GPU 4. Secure GPU to mounting bar 5. Ensure riser cable not twisted or kinked</p> <p>GPU Spacing: - Maintain 40-50mm between GPUs - Avoid blocking fan intakes - Stagger heights if needed for airflow</p>"},{"location":"guide/step1-hardware/#step-9-power-gpu-connections","title":"Step 9: Power GPU Connections","text":"<p>Time Required: 30 minutes</p> <p>PSU2 Dedicated to GPUs:</p> <p>Power Requirements: - RTX 5090: 600W (1\u00d7 12VHPWR connector) - RTX 3090: 350W each (2\u00d7 8-pin or 3\u00d7 8-pin per GPU)</p> <p>Connection Strategy:</p> <p>Option A: Server PSU with Breakout Board <pre><code>X12 Breakout Board provides:\n- Multiple PCIe 8-pin outputs\n- Direct 12V power\n\nConnect:\nGPU1 (RTX 5090): Use 12VHPWR adapter or 3\u00d7 8-pin to 12VHPWR\nGPU2 (RTX 3090): 2\u00d7 8-pin PCIe\nGPU3 (RTX 3090): 2\u00d7 8-pin PCIe\nGPU4 (RTX 3090): 2\u00d7 8-pin PCIe\nGPU5 (RTX 3090): 2\u00d7 8-pin PCIe\n</code></pre></p> <p>Load Balancing: <pre><code>PSU1 (1600W): Motherboard (150W) + CPU (200W) = 350W used\nPSU2 (1600W): 5 GPUs (2125W total) - OVERLOAD!\n\nSOLUTION: Split GPU power across both PSUs\nPSU1: RTX 5090 (600W) + 1\u00d7 RTX 3090 (350W) = 950W + overhead\nPSU2: 3\u00d7 RTX 3090 (1050W)\n</code></pre></p> <p>Revised Connection: <pre><code>PSU1 (After mobo/CPU):\n- GPU1: RTX 5090 (3\u00d7 8-pin or 12VHPWR)\n- GPU2: RTX 3090 (2\u00d7 8-pin)\n\nPSU2:\n- GPU3: RTX 3090 (2\u00d7 8-pin)\n- GPU4: RTX 3090 (2\u00d7 8-pin)  \n- GPU5: RTX 3090 (2\u00d7 8-pin)\n</code></pre></p> <p>Cable Management: - Use separate PCIe cables per GPU (don't daisy-chain) - Route cables cleanly - Label each GPU and its power source - Secure with velcro ties</p>"},{"location":"guide/step1-hardware/#step-10-install-additional-fans","title":"Step 10: Install Additional Fans","text":"<p>Time Required: 15 minutes</p> <p>Fan Placement Strategy: 1. Front fans (intake): 2\u00d7 120mm or 140mm    - Push cool air toward GPUs    - Low-medium speed</p> <ol> <li>Rear fans (exhaust): 2\u00d7 120mm</li> <li>Pull hot air away from GPUs</li> <li> <p>Medium-high speed</p> </li> <li> <p>Side fans (optional): 1\u00d7 140mm</p> </li> <li>Direct airflow between GPU rows</li> </ol> <p>Fan Connections: - Connect to motherboard fan headers - Or use PSU SATA to 4-pin adapters - Set to 40-60% speed initially</p> <p>Airflow Direction: - Front to back - Bottom to top - Create positive pressure (more intake than exhaust)</p>"},{"location":"guide/step1-hardware/#step-11-cable-management","title":"Step 11: Cable Management","text":"<p>Time Required: 30 minutes</p> <p>Organize cables by type:</p> <ol> <li>Power cables:</li> <li>Route along frame edges</li> <li>Use cable ties every 6-8 inches</li> <li> <p>Keep away from fans</p> </li> <li> <p>PCIe risers:</p> </li> <li>Avoid sharp bends (&gt;90\u00b0)</li> <li>Secure to prevent sagging</li> <li> <p>Don't cross power cables if possible</p> </li> <li> <p>Front panel connections:</p> </li> <li>Power button</li> <li>Power LED</li> <li>HDD LED</li> <li> <p>USB headers (if needed)</p> </li> <li> <p>Label everything:</p> </li> <li>GPU numbers (GPU1-GPU5)</li> <li>PSU assignments</li> <li>Fan connections</li> </ol> <p>Pro Tips: - Use velcro ties (reusable) - Leave slack for maintenance - Take photos for reference</p>"},{"location":"guide/step1-hardware/#step-12-connect-peripherals","title":"Step 12: Connect Peripherals","text":"<p>Time Required: 5 minutes</p> <ol> <li>Monitor:</li> <li>Connect to RTX 5090 DisplayPort/HDMI</li> <li> <p>Use GPU1 for primary display</p> </li> <li> <p>Keyboard and Mouse:</p> </li> <li> <p>USB 2.0 or 3.0 ports on rear I/O</p> </li> <li> <p>Network:</p> </li> <li>Connect Ethernet to onboard 10GbE (optional)</li> <li>Or use Wi-Fi if installing card later</li> </ol>"},{"location":"guide/step1-hardware/#step-13-pre-power-on-checklist","title":"Step 13: Pre-Power-On Checklist","text":"<p>Time Required: 15 minutes</p> <p>\u26a0\ufe0f CRITICAL: Verify before first power-on!</p> <p>Motherboard: - [ ] CPU installed correctly - [ ] Cooler mounted securely - [ ] All 8 RAM sticks installed - [ ] 24-pin ATX power connected - [ ] 2\u00d7 8-pin CPU power connected - [ ] NVMe drive installed</p> <p>GPUs: - [ ] All 5 GPUs seated properly - [ ] All GPUs have power connected - [ ] Risers connected firmly - [ ] No loose cables near fans</p> <p>Power Supplies: - [ ] Both PSUs plugged in - [ ] PSU switches OFF - [ ] All cables connected - [ ] No short circuits visible</p> <p>Cooling: - [ ] CPU fan connected - [ ] Case fans connected - [ ] All fans spin freely - [ ] No obstructions</p> <p>Peripherals: - [ ] Monitor connected to GPU1 - [ ] Keyboard connected - [ ] Mouse connected</p> <p>Safety: - [ ] No loose screws in system - [ ] No metal touching motherboard - [ ] Cable management complete - [ ] Frame stable and level</p>"},{"location":"guide/step1-hardware/#step-14-first-power-on","title":"Step 14: First Power-On","text":"<p>Time Required: 10 minutes</p> <p>Procedure:</p> <ol> <li>Turn on PSU switches</li> <li>PSU1 first (motherboard)</li> <li>PSU2 second (GPUs)</li> <li> <p>Wait 5 seconds</p> </li> <li> <p>Press power button</p> </li> <li>Short press</li> <li> <p>Watch for:</p> <ul> <li>CPU fan spinning</li> <li>GPU fans spinning</li> <li>Monitor signal</li> <li>POST beep (if speaker installed)</li> </ul> </li> <li> <p>Expected behavior:</p> </li> <li>Fans start spinning</li> <li>LEDs light up</li> <li>Monitor shows BIOS splash screen</li> <li> <p>System may reboot once (training memory)</p> </li> <li> <p>If no display:</p> </li> <li>Wait 60-90 seconds (EPYC POST is slow)</li> <li>Check debug LEDs on motherboard</li> <li>Verify monitor input source</li> <li> <p>Reseat GPU if needed</p> </li> <li> <p>If successful:</p> </li> <li>Proceed to BIOS configuration</li> <li>Do not install OS yet</li> </ol>"},{"location":"guide/step1-hardware/#bios-configuration","title":"BIOS Configuration","text":""},{"location":"guide/step1-hardware/#initial-bios-setup","title":"Initial BIOS Setup","text":"<p>Time Required: 20-30 minutes</p> <p>Access BIOS: - Press <code>DEL</code> or <code>F2</code> during POST - May take 60+ seconds to appear on first boot</p>"},{"location":"guide/step1-hardware/#step-1-load-defaults","title":"Step 1: Load Defaults","text":"<ol> <li>Press F9 or find \"Load Optimized Defaults\"</li> <li>Select \"Yes\"</li> <li>Press F10 to save and reboot</li> </ol>"},{"location":"guide/step1-hardware/#step-2-update-bios-recommended","title":"Step 2: Update BIOS (Recommended)","text":"<ol> <li>Download latest BIOS from ASRock website</li> <li>Copy to USB drive (FAT32)</li> <li>Enter BIOS</li> <li>Go to \"Tool\" \u2192 \"Instant Flash\"</li> <li>Select BIOS file</li> <li>Follow prompts (do NOT power off)</li> <li>Reboot after completion</li> </ol> <p>Current recommended version: 2.10 or higher</p>"},{"location":"guide/step1-hardware/#step-3-configure-memory","title":"Step 3: Configure Memory","text":"<p>Location: Advanced \u2192 AMD CBS \u2192 UMC Common Options</p> <ol> <li>Enable XMP/DOCP:</li> <li>AMD CBS \u2192 NBIO Common Options</li> <li>Memory Clock Speed: 3200MHz</li> <li> <p>Or use \"Auto\" for auto-detection</p> </li> <li> <p>Verify memory configuration:</p> </li> <li>Main screen shows: 256GB DDR4-3200</li> <li>All 8 channels populated</li> </ol>"},{"location":"guide/step1-hardware/#step-4-configure-pcie","title":"Step 4: Configure PCIe","text":"<p>Location: Advanced \u2192 PCI Subsystem Settings</p> <ol> <li>PCIe Speed:</li> <li>Set to \"Gen4\" or \"Auto\"</li> <li> <p>Enables PCIe 4.0 for GPUs</p> </li> <li> <p>Above 4G Decoding:</p> </li> <li>Enable: Yes</li> <li> <p>Required for multiple GPUs</p> </li> <li> <p>Re-Size BAR Support:</p> </li> <li>Enable: Yes</li> <li> <p>Improves GPU performance</p> </li> <li> <p>SR-IOV Support:</p> </li> <li>Auto or Disabled (not needed for LLM use)</li> </ol>"},{"location":"guide/step1-hardware/#step-5-configure-boot","title":"Step 5: Configure Boot","text":"<p>Location: Boot Menu</p> <ol> <li>Boot Mode:</li> <li> <p>UEFI only (disable Legacy)</p> </li> <li> <p>Boot Priority:</p> </li> <li> <p>Set NVMe drive as first boot device</p> </li> <li> <p>Fast Boot:</p> </li> <li>Disabled (easier troubleshooting)</li> </ol>"},{"location":"guide/step1-hardware/#step-6-configure-cpu-optional","title":"Step 6: Configure CPU (Optional)","text":"<p>Location: Advanced \u2192 AMD CBS \u2192 CPU Common Options</p> <p>For stock operation: - Leave all at Auto</p> <p>For overclocking (advanced): - Adjust Core Frequency - Adjust voltage (carefully!) - Monitor temperatures</p>"},{"location":"guide/step1-hardware/#step-7-configure-fans","title":"Step 7: Configure Fans","text":"<p>Location: Monitor \u2192 Fan Settings</p> <ol> <li>CPU Fan:</li> <li>Mode: PWM or DC (match your cooler)</li> <li>Profile: Performance or Silent</li> <li> <p>Target temp: 70\u00b0C</p> </li> <li> <p>Chassis Fans:</p> </li> <li>Mode: PWM or DC</li> <li>Speed: 40-60%</li> <li>Increase if GPU temps high</li> </ol>"},{"location":"guide/step1-hardware/#step-8-verify-all-components","title":"Step 8: Verify All Components","text":"<p>Location: Main BIOS Screen</p> <p>Verify detected: - [ ] CPU: AMD EPYC 7443P, 24C/48T - [ ] Memory: 256GB DDR4-3200 - [ ] NVMe: 4TB drive detected - [ ] All 5 GPUs in PCIe Configuration page</p> <p>Check PCIe Configuration: - Advanced \u2192 Chipset Configuration \u2192 PCIe Configuration - Should show 5 GPUs in slots - Each running at PCIe 4.0 x16 or x8</p>"},{"location":"guide/step1-hardware/#step-9-save-and-exit","title":"Step 9: Save and Exit","text":"<ol> <li>Press F10</li> <li>Select \"Save Changes and Reset\"</li> <li>System will reboot</li> </ol>"},{"location":"guide/step1-hardware/#power-distribution-strategy","title":"Power Distribution Strategy","text":""},{"location":"guide/step1-hardware/#detailed-power-analysis","title":"Detailed Power Analysis","text":"<p>Component Power Draw:</p> Component Power Draw Notes EPYC 7443P 200W TDP, can spike to 240W Motherboard 50W Chipset, fans, peripherals 256GB DDR4 80W ~10W per 32GB stick NVMe 4TB 10W Peak during writes RTX 5090 575W TDP, can spike to 600W+ RTX 3090 #1 350W TDP per card RTX 3090 #2 350W TDP per card RTX 3090 #3 350W TDP per card RTX 3090 #4 350W TDP per card Case Fans (4\u00d7) 20W ~5W each TOTAL 2,335W Peak power draw"},{"location":"guide/step1-hardware/#power-supply-load-distribution","title":"Power Supply Load Distribution","text":"<p>PSU1 (1600W) - Primary System: - 24-pin ATX: Motherboard (50W) - 2\u00d7 8-pin EPS: CPU (200W) - SATA: NVMe, Fans (30W) - PCIe: RTX 5090 (600W) - PCIe: RTX 3090 #1 (350W) - Total: 1,230W (77% load)</p> <p>PSU2 (1600W) - GPUs: - PCIe: RTX 3090 #2 (350W) - PCIe: RTX 3090 #3 (350W) - PCIe: RTX 3090 #4 (350W) - Total: 1,050W (66% load)</p> <p>Efficiency Sweet Spot: Both PSUs running at 65-80% load (optimal for 80+ Platinum)</p>"},{"location":"guide/step1-hardware/#power-sequencing","title":"Power Sequencing","text":"<p>Startup: 1. Turn on PSU2 (GPUs) first 2. Wait 3 seconds 3. Turn on PSU1 (motherboard) 4. Press power button</p> <p>Shutdown: 1. OS shutdown command 2. Wait for complete power down 3. Turn off PSU1 4. Turn off PSU2</p> <p>Why this order: - Prevents motherboard from trying to power GPUs during boot - Reduces inrush current to motherboard - Extends PSU lifespan</p>"},{"location":"guide/step1-hardware/#surge-protection","title":"Surge Protection","text":"<p>Recommended: - Use 2\u00d7 separate surge protectors (1 per PSU) - Or 1\u00d7 high-capacity UPS (2000VA+) - Avoid daisy-chaining power strips</p> <p>UPS Recommendations: - APC Smart-UPS 2200VA - CyberPower CP1500PFCLCD - Tripp Lite SMART3000RM2U</p>"},{"location":"guide/step1-hardware/#cooling-and-thermal-management","title":"Cooling and Thermal Management","text":""},{"location":"guide/step1-hardware/#temperature-targets","title":"Temperature Targets","text":"Component Idle Load Max Safe EPYC 7443P 35-45\u00b0C 60-75\u00b0C 95\u00b0C RTX 5090 30-40\u00b0C 70-80\u00b0C 90\u00b0C RTX 3090 30-40\u00b0C 75-85\u00b0C 93\u00b0C Memory 35-45\u00b0C 50-60\u00b0C 85\u00b0C NVMe SSD 35-45\u00b0C 60-70\u00b0C 85\u00b0C"},{"location":"guide/step1-hardware/#airflow-optimization","title":"Airflow Optimization","text":"<p>Ideal Setup: <pre><code>[Front Intake Fans] \u2192 [GPUs] \u2192 [Rear Exhaust Fans]\n         \u2191                            \u2191\n    Cool Air                     Hot Air\n</code></pre></p> <p>Fan Configuration: - Front: 2\u00d7 140mm intake @ 800-1000 RPM - Rear: 2\u00d7 120mm exhaust @ 1000-1200 RPM - Side: 1\u00d7 140mm intake (between GPUs)</p>"},{"location":"guide/step1-hardware/#gpu-cooling-considerations","title":"GPU Cooling Considerations","text":"<p>GPU Spacing: - Minimum 40mm between GPUs - Stagger heights if possible - Direct cool air flow between cards</p> <p>GPU Fan Curves (Adjust in NVIDIA Control Panel): <pre><code>30\u00b0C: 30% fan speed\n50\u00b0C: 40% fan speed\n60\u00b0C: 50% fan speed\n70\u00b0C: 65% fan speed\n80\u00b0C: 85% fan speed\n85\u00b0C: 100% fan speed\n</code></pre></p>"},{"location":"guide/step1-hardware/#thermal-monitoring","title":"Thermal Monitoring","text":"<p>Software: - <code>nvidia-smi</code> - GPU temps - <code>sensors</code> - CPU and motherboard temps - <code>nvitop</code> - Real-time GPU monitoring - <code>btop</code> - System-wide monitoring</p> <p>Automated monitoring script: <pre><code>#!/bin/bash\nwhile true; do\n  echo \"=== $(date) ===\"\n  echo \"CPU Temp: $(sensors | grep Tctl | awk '{print $2}')\"\n  nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader\n  sleep 60\ndone\n</code></pre></p>"},{"location":"guide/step1-hardware/#cable-management","title":"Cable Management","text":""},{"location":"guide/step1-hardware/#cable-organization-strategy","title":"Cable Organization Strategy","text":"<p>Color Coding (Optional but Helpful): - Red: PSU1 power cables - Blue: PSU2 power cables - Yellow: PCIe risers - Black: Data cables (SATA, USB)</p> <p>Routing Paths: 1. Power cables: Along frame bottom and sides 2. PCIe risers: Direct paths, no crossing 3. Fan cables: Along vertical supports</p> <p>Securing Methods: - Velcro ties: Every 6-8 inches - Zip ties: Permanent locations only - Cable clips: Attach to frame</p>"},{"location":"guide/step1-hardware/#testing-and-validation","title":"Testing and Validation","text":""},{"location":"guide/step1-hardware/#post-assembly-testing","title":"Post-Assembly Testing","text":"<p>Time Required: 1-2 hours</p>"},{"location":"guide/step1-hardware/#test-1-bios-post","title":"Test 1: BIOS POST","text":"<p>\u2713 Pass Criteria: - System boots to BIOS - All components detected - No error beeps</p> <p>If Failed: - Check all power connections - Reseat RAM - Remove all GPUs except one, test</p>"},{"location":"guide/step1-hardware/#test-2-memory-test","title":"Test 2: Memory Test","text":"<p>Run MemTest86: 1. Download from memtest86.com 2. Create bootable USB 3. Boot from USB 4. Run full test (4-8 hours) 5. 0 errors = PASS</p>"},{"location":"guide/step1-hardware/#test-3-cpu-stress-test","title":"Test 3: CPU Stress Test","text":"<p>After OS installation: <pre><code># Install stress-ng\nsudo dnf install stress-ng\n\n# Run CPU stress test\nstress-ng --cpu 48 --timeout 300s --metrics\n\n# Monitor temps\nwatch -n 1 sensors\n</code></pre></p> <p>\u2713 Pass Criteria: - CPU temp &lt; 85\u00b0C under load - No throttling - System stable for 5 minutes</p>"},{"location":"guide/step1-hardware/#test-4-gpu-detection","title":"Test 4: GPU Detection","text":"<p>Verify all GPUs detected: <pre><code>nvidia-smi -L\n</code></pre></p> <p>Expected output: <pre><code>GPU 0: NVIDIA GeForce RTX 5090\nGPU 1: NVIDIA GeForce RTX 3090\nGPU 2: NVIDIA GeForce RTX 3090\nGPU 3: NVIDIA GeForce RTX 3090\nGPU 4: NVIDIA GeForce RTX 3090\n</code></pre></p>"},{"location":"guide/step1-hardware/#test-5-gpu-stress-test","title":"Test 5: GPU Stress Test","text":"<p>Run on each GPU individually: <pre><code># GPU 0\nnvidia-smi -i 0\n# Note idle temp\n\n# Install CUDA samples or use gpu-burn\ngit clone https://github.com/wilicc/gpu-burn\ncd gpu-burn\nmake\n./gpu_burn 300  # 5 minute burn test\n\n# Monitor temps\nwatch -n 1 nvidia-smi\n</code></pre></p> <p>\u2713 Pass Criteria: - GPU temp &lt; 85\u00b0C - No artifacts or crashes - Fans functioning</p> <p>Repeat for all 5 GPUs</p>"},{"location":"guide/step1-hardware/#test-6-multi-gpu-stress","title":"Test 6: Multi-GPU Stress","text":"<p>Test all GPUs simultaneously: <pre><code># Run gpu-burn on all GPUs\n./gpu_burn -d 0,1,2,3,4 300\n\n# Or use nvidia-smi dmon\nnvidia-smi dmon -s pucvmet -d 1\n</code></pre></p> <p>\u2713 Pass Criteria: - All GPUs stable - PSUs handling load - No power cycling - Temps acceptable</p>"},{"location":"guide/step1-hardware/#test-7-storage-performance","title":"Test 7: Storage Performance","text":"<p>Test NVMe speed: <pre><code># Install fio\nsudo dnf install fio\n\n# Sequential read test\nfio --name=seqread --rw=read --bs=1M --size=10G --numjobs=1 --runtime=60\n\n# Sequential write test\nfio --name=seqwrite --rw=write --bs=1M --size=10G --numjobs=1 --runtime=60\n</code></pre></p> <p>\u2713 Pass Criteria: - Read: &gt;5,000 MB/s - Write: &gt;4,000 MB/s</p>"},{"location":"guide/step1-hardware/#test-8-network-if-configured","title":"Test 8: Network (If Configured)","text":"<p>Test 10GbE: <pre><code># Install iperf3\nsudo dnf install iperf3\n\n# Server on one machine\niperf3 -s\n\n# Client on this machine\niperf3 -c &lt;server-ip&gt;\n</code></pre></p> <p>\u2713 Pass Criteria: - Throughput: &gt;9 Gbps - No packet loss</p>"},{"location":"guide/step1-hardware/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/step1-hardware/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"guide/step1-hardware/#issue-system-wont-post","title":"Issue: System Won't POST","text":"<p>Symptoms: - No display - No beeps - Fans spin but nothing happens</p> <p>Solutions: 1. Clear CMOS    - Remove CMOS battery for 30 seconds    - Or use CMOS clear jumper    - Reboot</p> <ol> <li>Breadboard test</li> <li>Remove all GPUs</li> <li>Keep only 1 stick of RAM</li> <li>Test outside of case</li> <li> <p>Add components back one at a time</p> </li> <li> <p>Check power</p> </li> <li>Verify 24-pin ATX seated</li> <li>Verify both 8-pin CPU power connected</li> <li>Try different PSU</li> </ol>"},{"location":"guide/step1-hardware/#issue-memory-not-detected","title":"Issue: Memory Not Detected","text":"<p>Symptoms: - BIOS shows less than 256GB - Beep codes - Memory training fails</p> <p>Solutions: 1. Reseat all DIMMs    - Remove and reinstall firmly    - Ensure latches click</p> <ol> <li>Test individually</li> <li>Install one DIMM in slot A1</li> <li>Boot and test</li> <li> <p>Mark working DIMMs</p> </li> <li> <p>Update BIOS</p> </li> <li> <p>Newer BIOS may improve compatibility</p> </li> <li> <p>Check compatibility</p> </li> <li>Verify DIMMs are ECC RDIMM</li> <li>All same speed (3200MHz)</li> </ol>"},{"location":"guide/step1-hardware/#issue-gpu-not-detected","title":"Issue: GPU Not Detected","text":"<p>Symptoms: - nvidia-smi shows fewer than 5 GPUs - PCIe errors in BIOS</p> <p>Solutions: 1. Reseat GPU    - Remove and reinstall    - Check PCIe latch</p> <ol> <li>Test direct vs riser</li> <li>Remove riser, test GPU directly</li> <li> <p>Replace faulty riser</p> </li> <li> <p>Check power</p> </li> <li>Verify all PCIe power connected</li> <li> <p>Try different PSU cables</p> </li> <li> <p>BIOS settings</p> </li> <li>Enable \"Above 4G Decoding\"</li> <li>Enable \"Re-Size BAR\"</li> <li>PCIe Gen set to Auto or Gen4</li> </ol>"},{"location":"guide/step1-hardware/#issue-high-gpu-temperatures","title":"Issue: High GPU Temperatures","text":"<p>Symptoms: - GPUs exceed 85\u00b0C under load - Thermal throttling</p> <p>Solutions: 1. Improve airflow    - Add intake fans    - Increase fan speed    - Space GPUs further apart</p> <ol> <li>Check thermal paste</li> <li>May need repaste (for used GPUs)</li> <li> <p>Use quality paste (Thermal Grizzly)</p> </li> <li> <p>Reduce power limit <pre><code>nvidia-smi -i 0 -pl 300  # Limit to 300W\n</code></pre></p> </li> <li> <p>Undervolt GPU</p> </li> <li>Use MSI Afterburner</li> <li>Reduce voltage by 50-100mV</li> </ol>"},{"location":"guide/step1-hardware/#issue-system-crashes-under-load","title":"Issue: System Crashes Under Load","text":"<p>Symptoms: - Random reboots during inference - Power cycles - Black screen crashes</p> <p>Solutions: 1. PSU issue    - Check PSU capacity    - Verify all power cables    - Try balancing load differently</p> <ol> <li>Memory error</li> <li>Run MemTest86</li> <li> <p>Replace faulty DIMMs</p> </li> <li> <p>GPU driver</p> </li> <li>Update to latest NVIDIA driver</li> <li> <p>Try different driver version</p> </li> <li> <p>Overheating</p> </li> <li>Monitor temps during crash</li> <li>Improve cooling</li> </ol>"},{"location":"guide/step1-hardware/#issue-pcie-riser-problems","title":"Issue: PCIe Riser Problems","text":"<p>Symptoms: - GPU not detected on riser - Instability with risers - Lower performance</p> <p>Solutions: 1. Check riser quality    - Use PCIe 4.0 rated risers    - Replace cheap risers</p> <ol> <li>Reduce PCIe speed</li> <li>BIOS: Set to Gen3 instead of Gen4</li> <li> <p>Improves stability with lower-quality risers</p> </li> <li> <p>Shorter risers</p> </li> <li>Use shortest risers possible</li> <li>30cm max for stability</li> </ol>"},{"location":"guide/step1-hardware/#upgrade-path","title":"Upgrade Path","text":""},{"location":"guide/step1-hardware/#future-upgrade-options","title":"Future Upgrade Options","text":"<p>Short Term (1 year): - [ ] Add second 4TB NVMe drive - [ ] Upgrade to 512GB RAM (requires 8\u00d7 64GB DIMMs) - [ ] Add 10GbE network card (if not using onboard)</p> <p>Medium Term (2-3 years): - [ ] Replace RTX 3090s with newer generation - [ ] Upgrade to faster NVMe (PCIe 5.0) - [ ] Add more powerful CPU cooler for overclocking</p> <p>Long Term (3-5 years): - [ ] Upgrade to newer EPYC CPU (7004/7005 series) - [ ] Replace all GPUs with latest generation - [ ] Add redundant NVMe drives (RAID configuration)</p>"},{"location":"guide/step1-hardware/#compatibility-notes","title":"Compatibility Notes","text":"<p>CPU Compatibility: - ROMED8-2T supports EPYC 7001/7002/7003 - BIOS update required for 7003 series (Milan) - Consider EPYC 7543P (32-core) or 7643 (48-core) upgrades</p> <p>RAM Compatibility: - Max: 2TB (8\u00d7 256GB LRDIMMs) - Upgrade to 512GB: Use 8\u00d7 64GB RDIMMs - Must be DDR4 ECC RDIMM or LRDIMM</p> <p>GPU Compatibility: - Any PCIe GPU will work - Consider future RTX 6000 series - Professional GPUs (A6000, H100) also supported</p>"},{"location":"guide/step1-hardware/#additional-resources","title":"Additional Resources","text":""},{"location":"guide/step1-hardware/#useful-links","title":"Useful Links","text":"<p>Motherboard: - ASRock ROMED8-2T Product Page - ROMED8-2T Manual - Latest BIOS Downloads</p> <p>CPU: - AMD EPYC 7443P Specifications - EPYC Overclocking Guide</p> <p>GPU: - NVIDIA RTX 3090 Specs - NVIDIA RTX 5090 Specs - vLLM Supported GPUs</p> <p>Communities: - r/homelab - Home server builds - ServeTheHome Forums - Enterprise hardware - r/LocalLLaMA - Local LLM running - Level1Techs Forum - High-end builds</p> <p>Guides: - EPYC Server Build Guide - Multi-GPU Deep Learning Setup</p>"},{"location":"guide/step1-hardware/#final-checklist","title":"Final Checklist","text":""},{"location":"guide/step1-hardware/#pre-purchase","title":"Pre-Purchase","text":"<ul> <li>[ ] Budget approved (~$8,000)</li> <li>[ ] eBay account created</li> <li>[ ] Workspace prepared</li> <li>[ ] Tools acquired</li> </ul>"},{"location":"guide/step1-hardware/#purchasing","title":"Purchasing","text":"<ul> <li>[ ] ASRock ROMED8-2T ordered</li> <li>[ ] AMD EPYC 7443P ordered</li> <li>[ ] SP3 CPU cooler ordered</li> <li>[ ] 8\u00d7 32GB DDR4 ECC ordered</li> <li>[ ] 4\u00d7 RTX 3090 ordered</li> <li>[ ] 1\u00d7 RTX 5090 ordered</li> <li>[ ] 4TB NVMe ordered</li> <li>[ ] 2\u00d7 1600W PSU ordered</li> <li>[ ] 5\u00d7 PCIe risers ordered</li> <li>[ ] Mining frame ordered</li> <li>[ ] Monitor, keyboard, mouse ordered</li> <li>[ ] Accessories ordered (paste, cables, fans)</li> </ul>"},{"location":"guide/step1-hardware/#assembly","title":"Assembly","text":"<ul> <li>[ ] Frame assembled</li> <li>[ ] Motherboard installed</li> <li>[ ] CPU and cooler installed</li> <li>[ ] RAM installed (all 8 sticks)</li> <li>[ ] NVMe installed</li> <li>[ ] GPUs installed (all 5)</li> <li>[ ] Power connected correctly</li> <li>[ ] Fans installed and connected</li> <li>[ ] Cables managed</li> <li>[ ] Pre-power-on checklist complete</li> </ul>"},{"location":"guide/step1-hardware/#testing","title":"Testing","text":"<ul> <li>[ ] System POSTs successfully</li> <li>[ ] BIOS configured</li> <li>[ ] All 5 GPUs detected</li> <li>[ ] Memory test passed</li> <li>[ ] CPU stress test passed</li> <li>[ ] GPU stress test passed</li> <li>[ ] Temperatures acceptable</li> <li>[ ] OS installed (RHEL 10.1)</li> </ul>"},{"location":"guide/step1-hardware/#software-next-steps","title":"Software (Next Steps)","text":"<ul> <li>[ ] NVIDIA drivers installed</li> <li>[ ] Docker installed</li> <li>[ ] vLLM configured</li> <li>[ ] Open WebUI running</li> <li>[ ] First model downloaded</li> <li>[ ] System producing inference</li> </ul> <p>Build Complete!</p> <p>You now have a professional-grade, multi-GPU LLM inference workstation capable of running the largest open-source language models.</p> <p>Total GPU Memory: 128GB (96GB RTX 3090 + 32GB RTX 5090) Total System Memory: 256GB DDR4 Total Compute: 24C/48T CPU + 74,240 CUDA cores Total Cost: ~$8,000 (60-70% savings vs new)</p> <p>Ready for: Llama 3.1 70B, Mixtral 8x22B, Qwen 72B, and more!</p> <p>Last Updated: February 2026 Target Budget: $7,000 - $9,000 (used components) Build Difficulty: Advanced (Estimated 6-8 hours)</p>"},{"location":"guide/step2-rhel/","title":"Red Hat Enterprise Linux 10.1 Installation Guide","text":"<p>Complete step-by-step guide for installing Red Hat Enterprise Linux 10.1 on your LLM inference workstation, including account creation, ISO preparation, installation with custom partitioning for Docker workloads, and Active Directory domain integration.</p>"},{"location":"guide/step2-rhel/#overview","title":"Overview","text":"<p>This guide covers the complete installation process for Red Hat Enterprise Linux 10.1 on a multi-GPU LLM inference workstation. The installation includes:</p> <ul> <li>Developer Subscription: Free for individual developers</li> <li>Custom Partitioning: Optimized for Docker and LLM workloads</li> <li>4TB NVMe Storage: Proper allocation for containers and models</li> <li>Active Directory Integration: Enterprise authentication with domain.org</li> </ul> <p>Target System: - 4TB NVMe drive - Multi-GPU configuration (5 GPUs) - 256GB RAM - AMD EPYC 7443P processor</p> <p>Time Required: 2-3 hours (including downloads)</p>"},{"location":"guide/step2-rhel/#prerequisites","title":"Prerequisites","text":""},{"location":"guide/step2-rhel/#hardware-requirements","title":"Hardware Requirements","text":"<ul> <li>\u2705 Computer assembled and hardware tested</li> <li>\u2705 4TB NVMe drive installed</li> <li>\u2705 Working monitor, keyboard, and mouse</li> <li>\u2705 Network connectivity (Ethernet recommended)</li> <li>\u2705 USB drive (16GB minimum) for installation media</li> </ul>"},{"location":"guide/step2-rhel/#software-requirements","title":"Software Requirements","text":"<ul> <li>\u2705 Windows, macOS, or Linux computer for preparation</li> <li>\u2705 Balena Etcher (for creating bootable USB)</li> <li>\u2705 Stable internet connection (minimum 10 Mbps for ISO download)</li> </ul>"},{"location":"guide/step2-rhel/#information-needed","title":"Information Needed","text":"<ul> <li>\u2705 Email address for Red Hat account</li> <li>\u2705 Desired hostname for the system</li> <li>\u2705 Network configuration (static IP or DHCP)</li> <li>\u2705 Active Directory domain credentials (if integrating)</li> <li>\u2705 Active Directory domain: domain.org</li> </ul>"},{"location":"guide/step2-rhel/#part-1-red-hat-account-and-subscription","title":"Part 1: Red Hat Account and Subscription","text":""},{"location":"guide/step2-rhel/#step-11-create-red-hat-account","title":"Step 1.1: Create Red Hat Account","text":"<p>Red Hat provides a free Developer Subscription that includes access to RHEL for individual use.</p> <p>Navigate to Red Hat Developer Portal:</p> <ol> <li>Open your web browser</li> <li>Go to: <code>https://developers.redhat.com/register</code></li> </ol> <p>Complete Registration Form:</p> <pre><code>Required Information:\n- Email address (will be your login)\n- First name\n- Last name\n- Company (can use \"Individual\" or \"Self\")\n- Country\n- Password (must be strong: 8+ characters, uppercase, lowercase, numbers)\n\nOptional:\n- Job role\n- Phone number\n</code></pre> <ol> <li>Click \"Create my account\"</li> <li>Check your email for verification link</li> <li>Click verification link to activate account</li> </ol> <p>Expected Time: 5 minutes</p>"},{"location":"guide/step2-rhel/#step-12-accept-terms-and-conditions","title":"Step 1.2: Accept Terms and Conditions","text":"<p>After verifying your email:</p> <ol> <li>Log in to <code>https://developers.redhat.com</code></li> <li>Navigate to \"Products\" \u2192 \"Red Hat Enterprise Linux\"</li> <li>Accept the Terms and Conditions for Developer Subscription</li> <li>Subscription is automatically attached to your account</li> </ol> <p>What You Get: - 16 system entitlements - Access to all RHEL versions - Developer support resources - No cost for non-production use</p>"},{"location":"guide/step2-rhel/#step-13-verify-subscription-status","title":"Step 1.3: Verify Subscription Status","text":"<ol> <li>Log in to: <code>https://access.redhat.com</code></li> <li>Click \"Subscriptions\" in top navigation</li> <li>You should see: \"Red Hat Developer Subscription for Individuals\"</li> <li>Status: Active</li> </ol>"},{"location":"guide/step2-rhel/#part-2-download-rhel-101-iso","title":"Part 2: Download RHEL 10.1 ISO","text":""},{"location":"guide/step2-rhel/#step-21-access-download-portal","title":"Step 2.1: Access Download Portal","text":"<ol> <li>Navigate to: <code>https://access.redhat.com/downloads</code></li> <li>Log in with your Red Hat account credentials</li> <li>Click on \"Product Downloads\"</li> </ol>"},{"location":"guide/step2-rhel/#step-22-select-rhel-version","title":"Step 2.2: Select RHEL Version","text":"<ol> <li>In the Products list, click \"Red Hat Enterprise Linux\"</li> <li>Click \"All Red Hat Enterprise Linux Downloads\" at bottom of page</li> <li>Select \"Red Hat Enterprise Linux 10.1\"</li> </ol> <p>Available ISO Options:</p> ISO Type Size Description Use Case DVD ISO ~9.5 GB Full installation Recommended - Offline install Boot ISO ~900 MB Network install Requires internet during install KVM Guest Image ~1 GB Pre-configured VM Not for bare metal"},{"location":"guide/step2-rhel/#step-23-download-dvd-iso","title":"Step 2.3: Download DVD ISO","text":"<p>Select the DVD ISO:</p> <ol> <li>Click on \"Red Hat Enterprise Linux 10.1 Binary DVD\"</li> <li>Architecture: x86_64</li> <li>Click \"Download Now\"</li> </ol> <p>Download Details: - File: <code>rhel-10.1-x86_64-dvd.iso</code> - Size: Approximately 9.5 GB - Checksum: Provided on download page (save for verification)</p> <p>Recommended Download Location: - Windows: <code>C:\\Users\\[Username]\\Downloads</code> - macOS: <code>~/Downloads</code> - Linux: <code>~/Downloads</code></p> <p>Download Time Estimates: - 100 Mbps: ~15 minutes - 50 Mbps: ~30 minutes - 25 Mbps: ~60 minutes</p>"},{"location":"guide/step2-rhel/#step-24-verify-iso-integrity-optional-but-recommended","title":"Step 2.4: Verify ISO Integrity (Optional but Recommended)","text":"<p>Download SHA256 Checksum:</p> <ol> <li>On download page, copy the SHA256 checksum value</li> <li>Save to text file: <code>rhel-10.1-sha256.txt</code></li> </ol> <p>Verify on Windows (PowerShell):</p> <pre><code>cd Downloads\nCertUtil -hashfile rhel-10.1-x86_64-dvd.iso SHA256\n</code></pre> <p>Verify on macOS/Linux:</p> <pre><code>cd ~/Downloads\nshasum -a 256 rhel-10.1-x86_64-dvd.iso\n</code></pre> <p>Compare output with checksum from Red Hat website. They must match exactly.</p>"},{"location":"guide/step2-rhel/#part-3-create-bootable-usb-with-balena-etcher","title":"Part 3: Create Bootable USB with Balena Etcher","text":""},{"location":"guide/step2-rhel/#step-31-download-balena-etcher","title":"Step 3.1: Download Balena Etcher","text":"<p>Navigate to Balena Etcher website:</p> <ol> <li>Go to: <code>https://etcher.balena.io</code></li> <li>Download version for your operating system:</li> <li>Windows: <code>.exe</code> installer</li> <li>macOS: <code>.dmg</code> file</li> <li>Linux: <code>.AppImage</code> file</li> </ol> <p>Install Balena Etcher:</p> <ul> <li>Windows: Run <code>.exe</code> and follow installer</li> <li>macOS: Open <code>.dmg</code> and drag to Applications</li> <li>Linux: Make AppImage executable:   <pre><code>chmod +x balenaEtcher*.AppImage\n</code></pre></li> </ul>"},{"location":"guide/step2-rhel/#step-32-prepare-usb-drive","title":"Step 3.2: Prepare USB Drive","text":"<p>\u26a0\ufe0f WARNING: All data on USB drive will be erased!</p> <p>Requirements: - USB drive: 16GB minimum (32GB recommended) - USB 3.0 or higher (for faster installation) - Empty or backed up (all data will be lost)</p> <p>Insert USB Drive:</p> <ol> <li>Insert USB drive into your computer</li> <li>Back up any important data from USB drive</li> <li>Note drive letter/device name:</li> <li>Windows: Typically <code>D:</code>, <code>E:</code>, or <code>F:</code></li> <li>macOS: <code>/Volumes/[USB_NAME]</code></li> <li>Linux: <code>/dev/sdX</code> (use <code>lsblk</code> to identify)</li> </ol>"},{"location":"guide/step2-rhel/#step-33-flash-iso-to-usb-with-balena-etcher","title":"Step 3.3: Flash ISO to USB with Balena Etcher","text":"<p>Launch Balena Etcher:</p> <ol> <li>Open Balena Etcher application</li> </ol> <p>Step 1: Select Image</p> <ol> <li>Click \"Flash from file\"</li> <li>Navigate to downloads folder</li> <li>Select: <code>rhel-10.1-x86_64-dvd.iso</code></li> <li>Click \"Open\"</li> </ol> <p>Step 2: Select Target</p> <ol> <li>Click \"Select target\"</li> <li>Choose your USB drive from list</li> <li>Verify you selected correct drive!</li> <li>Wrong selection will erase wrong drive</li> <li>Click \"Select (1)\" to confirm</li> </ol> <p>Step 3: Flash</p> <ol> <li>Click \"Flash!\"</li> <li>Enter administrator password when prompted</li> <li>Wait for flashing process (5-10 minutes)</li> </ol> <p>Progress Indicators: <pre><code>Flashing...    [\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 45%\nValidating...  [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591] 85%\n</code></pre></p> <ol> <li>When complete, you'll see: \"Flash Complete!\"</li> <li>Click \"OK\"</li> <li>Safely eject USB drive</li> </ol> <p>Expected Time: 10-15 minutes</p>"},{"location":"guide/step2-rhel/#part-4-biosuefi-configuration","title":"Part 4: BIOS/UEFI Configuration","text":""},{"location":"guide/step2-rhel/#step-41-access-biosuefi","title":"Step 4.1: Access BIOS/UEFI","text":"<ol> <li>Insert bootable USB into target computer</li> <li>Power on the system</li> <li>Press BIOS key during POST:</li> <li>ASRock motherboards: F2 or DEL</li> <li>Common alternatives: F1, F10, F12, ESC</li> </ol> <p>If you miss the key press: - Restart and try again - Look for \"Press X to enter Setup\" message</p>"},{"location":"guide/step2-rhel/#step-42-configure-boot-order","title":"Step 4.2: Configure Boot Order","text":"<p>Navigate to Boot Menu:</p> <ol> <li>Use arrow keys to navigate BIOS</li> <li>Find \"Boot\" tab or \"Boot Priority\" section</li> </ol> <p>Set Boot Order:</p> <ol> <li>Move USB device to first position</li> <li>Typical order:    <pre><code>1st Boot Device: USB Hard Disk (or UEFI: USB_DEVICE_NAME)\n2nd Boot Device: NVMe Drive\n3rd Boot Device: Network Boot\n</code></pre></li> </ol> <p>Configure UEFI Settings (if applicable):</p> <ol> <li>Secure Boot: Disabled (recommended for RHEL 10.1 with custom drivers)</li> <li>Boot Mode: UEFI (not Legacy/CSM)</li> <li>Fast Boot: Disabled</li> </ol>"},{"location":"guide/step2-rhel/#step-43-save-and-reboot","title":"Step 4.3: Save and Reboot","text":"<ol> <li>Press F10 (or navigate to \"Save &amp; Exit\")</li> <li>Select \"Save Changes and Reset\"</li> <li>Press Enter to confirm</li> </ol> <p>System will reboot and boot from USB</p>"},{"location":"guide/step2-rhel/#part-5-rhel-101-installation","title":"Part 5: RHEL 10.1 Installation","text":""},{"location":"guide/step2-rhel/#step-51-boot-from-installation-media","title":"Step 5.1: Boot from Installation Media","text":"<p>RHEL Boot Menu:</p> <p>After reboot, you'll see the Red Hat installer boot menu:</p> <pre><code>Install Red Hat Enterprise Linux 10.1\nTest this media &amp; install Red Hat Enterprise Linux 10.1\nTroubleshooting --&gt;\n</code></pre> <ol> <li>Select \"Install Red Hat Enterprise Linux 10.1\"</li> <li>Press Enter</li> </ol> <p>Initial boot takes 30-60 seconds</p>"},{"location":"guide/step2-rhel/#step-52-language-and-keyboard-selection","title":"Step 5.2: Language and Keyboard Selection","text":"<p>Welcome Screen:</p> <ol> <li>Select Language: English (United States)</li> <li>Click \"Continue\"</li> </ol> <p>Time Required: 1 minute</p>"},{"location":"guide/step2-rhel/#step-53-installation-summary-screen","title":"Step 5.3: Installation Summary Screen","text":"<p>You'll see the main installation dashboard with multiple configuration sections:</p> <pre><code>INSTALLATION SUMMARY\n\nLOCALIZATION\n  [!] Keyboard: English (US)\n  [!] Language Support: English (United States)\n  [!] Time &amp; Date: America/New_York\n\nSOFTWARE\n  [!] Installation Source: Local media\n  [!] Software Selection: Server with GUI\n\nSYSTEM\n  [!] Installation Destination: No disks selected\n  [!] Network &amp; Host Name: Not configured\n  [!] Root Password: Not set\n  [!] User Creation: No user created\n</code></pre> <p>Items with [!] require configuration</p>"},{"location":"guide/step2-rhel/#step-54-time-date-configuration","title":"Step 5.4: Time &amp; Date Configuration","text":"<ol> <li>Click \"Time &amp; Date\"</li> <li>Select your region and city</li> <li>Example: America/New_York</li> <li>Network Time: Toggle ON (recommended)</li> <li>Automatically syncs with NTP servers</li> <li>Click \"Done\"</li> </ol>"},{"location":"guide/step2-rhel/#step-55-software-selection","title":"Step 5.5: Software Selection","text":"<ol> <li>Click \"Software Selection\"</li> <li>Base Environment: Select \"Server with GUI\"</li> <li>Provides desktop environment for easier management</li> <li>Essential for monitoring GPUs visually</li> </ol> <p>Add-Ons for Selected Environment (select these): - [x] Debugging Tools - [x] Development Tools (already selected for NVIDIA drivers) - [x] System Tools - [x] Network Servers (optional)</p> <ol> <li>Click \"Done\"</li> </ol> <p>Note: Additional software will be installed post-installation.</p>"},{"location":"guide/step2-rhel/#step-56-installation-destination-critical-custom-partitioning","title":"Step 5.6: Installation Destination (Critical - Custom Partitioning)","text":"<p>This section is critical for Docker and LLM workloads.</p> <p>\u26a0\ufe0f IMPORTANT: Custom partition sizing for Docker containers and large models</p> <ol> <li>Click \"Installation Destination\"</li> <li>Select your 4TB NVMe drive (should show as 3.7 TB)</li> <li>Storage Configuration: Select \"Custom\"</li> <li>Click \"Done\"</li> </ol> <p>Manual Partitioning Screen Opens</p>"},{"location":"guide/step2-rhel/#step-57-create-partition-scheme","title":"Step 5.7: Create Partition Scheme","text":"<p>Select Partitioning Scheme:</p> <ol> <li>New RHEL Installation: Click dropdown</li> <li>Select: \"Standard Partition\" or \"LVM\" (LVM recommended)</li> <li>Click \"Click here to create them automatically\"</li> </ol> <p>Auto-created partitions appear - now we customize them</p>"},{"location":"guide/step2-rhel/#step-58-customize-partitions-for-llmdocker-workload","title":"Step 5.8: Customize Partitions for LLM/Docker Workload","text":"<p>Delete and recreate with proper sizes for 4TB drive:</p>"},{"location":"guide/step2-rhel/#partition-1-boot-efi-system","title":"Partition 1: /boot (EFI System)","text":"<p>Already created - leave as is: - Mount Point: <code>/boot/efi</code> - Size: 600 MB - File System: EFI System Partition</p>"},{"location":"guide/step2-rhel/#partition-2-boot","title":"Partition 2: /boot","text":"<p>Already created - leave as is: - Mount Point: <code>/boot</code> - Size: 1 GB (1024 MB) - File System: xfs</p>"},{"location":"guide/step2-rhel/#partition-3-swap-critical-large-for-llm-workloads","title":"Partition 3: swap (Critical - Large for LLM workloads)","text":"<p>Modify existing swap:</p> <ol> <li>Select <code>swap</code> partition</li> <li>Desired Capacity: <code>256 GB</code> (256000 MB)</li> <li>Large swap for memory-intensive LLM operations</li> <li>Allows safe handling of out-of-memory scenarios</li> <li>Click \"Update Settings\"</li> </ol> <p>Why 256GB swap: - System has 256GB RAM - Swap = 1\u00d7 RAM for heavy workloads - Allows emergency memory overflow - Supports hibernation (optional)</p>"},{"location":"guide/step2-rhel/#partition-4-root","title":"Partition 4: / (Root)","text":"<p>Modify existing root:</p> <ol> <li>Select <code>/</code> partition</li> <li>Desired Capacity: <code>2.5 TB</code> (2500 GB = 2,560,000 MB)</li> <li>OS and applications</li> <li>User home directories</li> <li>System files</li> <li>File System: <code>xfs</code> (recommended for RHEL)</li> <li>Click \"Update Settings\"</li> </ol>"},{"location":"guide/step2-rhel/#partition-5-var-critical-docker-and-containers","title":"Partition 5: /var (Critical - Docker and containers)","text":"<p>Create new /var partition:</p> <ol> <li>Click \"+\" button to add new partition</li> <li>Mount Point: <code>/var</code></li> <li>Desired Capacity: <code>500 GB</code> (512,000 MB)</li> <li>Docker images: 100-200 GB</li> <li>Container volumes: 100-200 GB</li> <li>Logs and temporary files: 100 GB</li> <li>File System: <code>xfs</code></li> <li>Click \"Add mount point\"</li> </ol> <p>Why separate /var with 500GB: - Docker stores images/containers in <code>/var/lib/docker</code> - Container data can grow very large - Prevents container storage from filling root partition - Isolates logs and variable data - Critical for production Docker workloads</p>"},{"location":"guide/step2-rhel/#partition-6-home-user-data-and-models","title":"Partition 6: /home (User data and models)","text":"<p>Create new /home partition:</p> <ol> <li>Click \"+\" to add partition</li> <li>Mount Point: <code>/home</code></li> <li>Desired Capacity: Fill remaining space (~650 GB)</li> <li>User directories</li> <li>Downloaded models</li> <li>Development projects</li> <li>Datasets</li> <li>File System: <code>xfs</code></li> <li>Click \"Add mount point\"</li> </ol>"},{"location":"guide/step2-rhel/#step-59-review-final-partition-layout","title":"Step 5.9: Review Final Partition Layout","text":"<p>Verify your partition scheme:</p> <pre><code>Device                 Mount Point    Size        Type\n/dev/nvme0n1p1        /boot/efi      600 MB      vfat\n/dev/nvme0n1p2        /boot          1 GB        xfs\n/dev/nvme0n1p3        swap           256 GB      swap\n/dev/nvme0n1p4        /              2.5 TB      xfs\n/dev/nvme0n1p5        /var           500 GB      xfs\n/dev/nvme0n1p6        /home          ~650 GB     xfs\n-----------------------------------------------------------\nTotal:                               ~3.9 TB     (4TB drive)\n</code></pre> <p>Partition Summary: - Total drive: 4TB (3.7 TB usable) - OS and apps (/): 2.5 TB - Docker and containers (/var): 500 GB - Swap: 256 GB - User data and models (/home): ~650 GB - Boot partitions: ~1.6 GB</p>"},{"location":"guide/step2-rhel/#step-510-accept-changes","title":"Step 5.10: Accept Changes","text":"<ol> <li>Click \"Done\" (top left)</li> <li>Summary of Changes dialog appears</li> <li>Review changes carefully</li> <li>Click \"Accept Changes\"</li> </ol> <p>\u26a0\ufe0f WARNING: This will format the drive. All data will be lost.</p>"},{"location":"guide/step2-rhel/#step-511-network-host-name","title":"Step 5.11: Network &amp; Host Name","text":"<p>Configure networking:</p> <ol> <li>Click \"Network &amp; Host Name\"</li> <li>Host name: Enter your desired hostname</li> <li>Example: <code>llm-inference-01.domain.org</code></li> <li>Format: <code>hostname.domain.org</code></li> <li>Click \"Apply\"</li> </ol> <p>Configure Network Interface:</p> <ol> <li>In left panel, select Ethernet connection</li> <li>Toggle switch to ON (should turn green)</li> </ol> <p>For Static IP (recommended for servers):</p> <ol> <li>Click \"Configure...\"</li> <li>Go to \"IPv4 Settings\" tab</li> <li>Method: Select \"Manual\"</li> <li>Click \"Add\" and enter:</li> <li>Address: <code>192.168.1.100</code> (example - use your network)</li> <li>Netmask: <code>255.255.255.0</code></li> <li>Gateway: <code>192.168.1.1</code> (your router)</li> <li>DNS servers: <code>192.168.1.10,192.168.1.11</code> (your AD DNS servers)</li> <li>Click \"Save\"</li> </ol> <p>For DHCP (automatic):</p> <ol> <li>Leave as DHCP (default)</li> <li> <p>Still configure DNS to point to AD servers</p> </li> <li> <p>Click \"Done\"</p> </li> </ol> <p>Important for Active Directory: - DNS must point to Active Directory domain controllers - Example: <code>192.168.1.10</code> and <code>192.168.1.11</code> - Do NOT use public DNS (8.8.8.8) if joining AD</p>"},{"location":"guide/step2-rhel/#step-512-root-password","title":"Step 5.12: Root Password","text":"<p>Set root password:</p> <ol> <li>Click \"Root Password\"</li> <li>Enter a strong password:</li> <li>Minimum 8 characters</li> <li>Mix of uppercase, lowercase, numbers, symbols</li> <li>Don't use dictionary words</li> <li>Confirm password (re-enter)</li> <li>If weak password: Click \"Done\" twice to override</li> </ol> <p>Password Requirements: <pre><code>Weak:     admin123\nModerate: Admin@2026\nStrong:   xK9#mP2!vL5@wN8q\n</code></pre></p> <ol> <li>Click \"Done\"</li> </ol> <p>\u26a0\ufe0f IMPORTANT: Save this password securely!</p>"},{"location":"guide/step2-rhel/#step-513-user-creation","title":"Step 5.13: User Creation","text":"<p>Create administrative user:</p> <ol> <li>Click \"User Creation\"</li> <li>Full name: <code>Administrator</code> (or your name)</li> <li>User name: <code>admin</code> (or your preference)</li> <li>Password: Enter strong password</li> <li>Confirm password: Re-enter</li> <li>Make this user administrator: \u2713 Check this box</li> <li>Grants sudo access</li> <li> <p>Require a password to use this account: \u2713 Keep checked</p> </li> <li> <p>Click \"Done\"</p> </li> </ol>"},{"location":"guide/step2-rhel/#step-514-begin-installation","title":"Step 5.14: Begin Installation","text":"<p>Verify all items configured:</p> <pre><code>\u2713 Keyboard: Configured\n\u2713 Language Support: Configured\n\u2713 Time &amp; Date: Configured\n\u2713 Installation Source: Configured\n\u2713 Software Selection: Server with GUI\n\u2713 Installation Destination: Custom partitions configured\n\u2713 Network &amp; Host Name: Configured\n\u2713 Root Password: Set\n\u2713 User Creation: User created\n</code></pre> <ol> <li>Click \"Begin Installation\" (blue button, bottom right)</li> </ol> <p>Installation Progress:</p> <pre><code>Installing Red Hat Enterprise Linux 10.1\n\nInstalling software packages...\n[\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 45%\n\nTime remaining: 15 minutes (varies by hardware)\n</code></pre> <p>Installation time: - Typical: 20-30 minutes - NVMe SSD: 15-20 minutes - SATA SSD: 30-45 minutes</p> <p>During installation: - Progress bar shows package installation - You can't interact with installer - Do not power off system</p>"},{"location":"guide/step2-rhel/#step-515-installation-complete","title":"Step 5.15: Installation Complete","text":"<p>When finished, you'll see:</p> <pre><code>Complete!\nRed Hat Enterprise Linux is now successfully installed.\n\n[ Reboot System ]\n</code></pre> <ol> <li>Remove USB installation drive</li> <li>Click \"Reboot System\"</li> </ol> <p>System will reboot into installed RHEL 10.1</p>"},{"location":"guide/step2-rhel/#part-6-post-installation-configuration","title":"Part 6: Post-Installation Configuration","text":""},{"location":"guide/step2-rhel/#step-61-initial-boot-and-license-agreement","title":"Step 6.1: Initial Boot and License Agreement","text":"<p>First boot after installation:</p> <ol> <li>System boots to RHEL</li> <li>Initial Setup screen appears</li> <li>License Information: Click to open</li> <li>Accept license agreement: \u2713 Check box</li> <li>Click \"Done\"</li> <li>Click \"Finish Configuration\"</li> </ol>"},{"location":"guide/step2-rhel/#step-62-first-login","title":"Step 6.2: First Login","text":"<p>Login Screen:</p> <ol> <li>Click on your username</li> <li>Enter password</li> <li>Press Enter</li> </ol> <p>GNOME Desktop loads</p>"},{"location":"guide/step2-rhel/#step-63-initial-gnome-setup-optional","title":"Step 6.3: Initial GNOME Setup (Optional)","text":"<p>Welcome to RHEL wizard:</p> <ol> <li>Privacy: Configure location services (optional)</li> <li>Online Accounts: Skip (click \"Skip\")</li> <li>Ready to Go: Click \"Start Using Red Hat Enterprise Linux\"</li> </ol> <p>Desktop environment is now ready</p>"},{"location":"guide/step2-rhel/#part-7-red-hat-subscription-attachment","title":"Part 7: Red Hat Subscription Attachment","text":""},{"location":"guide/step2-rhel/#step-71-register-system-with-red-hat","title":"Step 7.1: Register System with Red Hat","text":"<p>Open Terminal:</p> <ul> <li>Click \"Activities\" \u2192 Search for \"Terminal\"</li> <li>Or press Ctrl+Alt+T</li> </ul> <p>Register system:</p> <pre><code>sudo subscription-manager register --username YOUR_REDHAT_EMAIL\n</code></pre> <p>Enter: 1. Your Red Hat account password when prompted 2. Your user password for <code>sudo</code></p> <p>Expected output: <pre><code>The system has been registered with ID: xxxxxxxxxx\nThe registered system name is: llm-inference-01.domain.org\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-72-attach-subscription","title":"Step 7.2: Attach Subscription","text":"<p>Auto-attach subscription:</p> <pre><code>sudo subscription-manager attach --auto\n</code></pre> <p>Expected output: <pre><code>Installed Product Current Status:\nProduct Name: Red Hat Enterprise Linux for x86_64\nStatus:       Subscribed\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-73-verify-subscription","title":"Step 7.3: Verify Subscription","text":"<p>Check subscription status:</p> <pre><code>sudo subscription-manager status\n</code></pre> <p>Expected output: <pre><code>+-------------------------------------------+\n   System Status Details\n+-------------------------------------------+\nOverall Status: Current\n\nSystem Purpose Status: Matched\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-74-enable-required-repositories","title":"Step 7.4: Enable Required Repositories","text":"<p>Enable base repositories:</p> <pre><code># Enable BaseOS repository\nsudo subscription-manager repos --enable=rhel-10-for-x86_64-baseos-rpms\n\n# Enable AppStream repository\nsudo subscription-manager repos --enable=rhel-10-for-x86_64-appstream-rpms\n\n# Enable CodeReady Builder (for development)\nsudo subscription-manager repos --enable=codeready-builder-for-rhel-10-x86_64-rpms\n</code></pre> <p>Verify repositories:</p> <pre><code>sudo dnf repolist\n</code></pre> <p>Expected output: <pre><code>repo id                                     repo name\nrhel-10-for-x86_64-baseos-rpms             Red Hat Enterprise Linux 10 for x86_64 - BaseOS\nrhel-10-for-x86_64-appstream-rpms          Red Hat Enterprise Linux 10 for x86_64 - AppStream\ncodeready-builder-for-rhel-10-x86_64-rpms  CodeReady Linux Builder for RHEL 10\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-75-update-system","title":"Step 7.5: Update System","text":"<p>Perform initial system update:</p> <pre><code># Update all packages\nsudo dnf update -y\n</code></pre> <p>This may take 10-20 minutes depending on connection speed</p> <p>Reboot after update (recommended):</p> <pre><code>sudo systemctl reboot\n</code></pre>"},{"location":"guide/step2-rhel/#part-8-active-directory-integration","title":"Part 8: Active Directory Integration","text":""},{"location":"guide/step2-rhel/#step-81-prerequisites-for-ad-integration","title":"Step 8.1: Prerequisites for AD Integration","text":"<p>Network Requirements:</p> <ol> <li>DNS Configuration: System must use AD DNS servers</li> <li>Network Connectivity: Verify connection to domain controllers</li> <li>Time Synchronization: System time must match AD</li> </ol> <p>Verify DNS points to AD:</p> <pre><code>cat /etc/resolv.conf\n</code></pre> <p>Should show: <pre><code>nameserver 192.168.1.10  # AD Domain Controller 1\nnameserver 192.168.1.11  # AD Domain Controller 2\nsearch domain.org\n</code></pre></p> <p>If not correct, edit:</p> <pre><code>sudo nmcli connection modify \"System eth0\" ipv4.dns \"192.168.1.10 192.168.1.11\"\nsudo nmcli connection modify \"System eth0\" ipv4.dns-search \"domain.org\"\nsudo nmcli connection up \"System eth0\"\n</code></pre>"},{"location":"guide/step2-rhel/#step-82-install-required-packages","title":"Step 8.2: Install Required Packages","text":"<p>Install AD integration packages:</p> <pre><code>sudo dnf install -y \\\n    realmd \\\n    sssd \\\n    oddjob \\\n    oddjob-mkhomedir \\\n    adcli \\\n    samba-common-tools \\\n    krb5-workstation \\\n    openldap-clients \\\n    policycoreutils-python-utils\n</code></pre> <p>Package descriptions: - <code>realmd</code>: Domain discovery and join utility - <code>sssd</code>: System Security Services Daemon - <code>oddjob-mkhomedir</code>: Auto-create home directories - <code>adcli</code>: Active Directory command-line tool - <code>krb5-workstation</code>: Kerberos client tools - <code>samba-common-tools</code>: Samba utilities - <code>openldap-clients</code>: LDAP client utilities</p>"},{"location":"guide/step2-rhel/#step-83-configure-system-hostname","title":"Step 8.3: Configure System Hostname","text":"<p>Set fully qualified hostname:</p> <pre><code># Set hostname\nsudo hostnamectl set-hostname llm-inference-01.domain.org\n\n# Verify\nhostnamectl\n</code></pre> <p>Expected output: <pre><code>   Static hostname: llm-inference-01.domain.org\n         Icon name: computer-desktop\n           Chassis: desktop\n  Operating System: Red Hat Enterprise Linux 10.1\n</code></pre></p> <p>Update /etc/hosts:</p> <pre><code>sudo nano /etc/hosts\n</code></pre> <p>Add/modify: <pre><code>127.0.0.1   localhost localhost.localdomain\n192.168.1.100   llm-inference-01.domain.org llm-inference-01\n\n# Remove any 127.0.1.1 entries for hostname\n</code></pre></p> <p>Save: Ctrl+O, Enter, Ctrl+X</p>"},{"location":"guide/step2-rhel/#step-84-verify-time-synchronization","title":"Step 8.4: Verify Time Synchronization","text":"<p>AD requires synchronized time (critical for Kerberos):</p> <pre><code># Check current time\ntimedatectl\n\n# Enable NTP synchronization\nsudo timedatectl set-ntp true\n\n# Verify synchronization\nsudo systemctl status chronyd\n</code></pre> <p>Time difference must be less than 5 minutes from AD</p>"},{"location":"guide/step2-rhel/#step-85-test-dns-resolution-to-ad","title":"Step 8.5: Test DNS Resolution to AD","text":"<p>Verify DNS records:</p> <pre><code># Test domain\nnslookup domain.org\n\n# Test domain controllers\nnslookup dc1.domain.org\nnslookup dc2.domain.org\n\n# Test SRV records (critical for AD)\ndig -t SRV _ldap._tcp.domain.org\ndig -t SRV _kerberos._tcp.domain.org\n</code></pre> <p>SRV records should return domain controller addresses</p>"},{"location":"guide/step2-rhel/#step-86-discover-active-directory-domain","title":"Step 8.6: Discover Active Directory Domain","text":"<p>Use realmd to discover domain:</p> <pre><code>sudo realm discover domain.org\n</code></pre> <p>Expected output: <pre><code>domain.org\n  type: kerberos\n  realm-name: DOMAIN.ORG\n  domain-name: domain.org\n  configured: no\n  server-software: active-directory\n  client-software: sssd\n  required-package: oddjob\n  required-package: oddjob-mkhomedir\n  required-package: sssd\n  required-package: adcli\n  required-package: samba-common-tools\n</code></pre></p> <p>If discovery fails: - Verify DNS configuration - Check network connectivity to domain controllers - Verify firewall rules (ports 88, 389, 636, 464, 3268)</p>"},{"location":"guide/step2-rhel/#step-87-join-system-to-active-directory-domain","title":"Step 8.7: Join System to Active Directory Domain","text":"<p>Join the domain:</p> <pre><code>sudo realm join -U administrator domain.org\n</code></pre> <p>You'll be prompted: <pre><code>Password for administrator:\n</code></pre></p> <p>Enter your AD administrator password</p> <p>Successful join output: <pre><code> * Resolving: _ldap._tcp.domain.org\n * Performing LDAP DSE lookup on: 192.168.1.10\n * Successfully enrolled machine in realm\n</code></pre></p> <p>Alternative - join with specific OU:</p> <pre><code># Join to specific organizational unit\nsudo realm join -U administrator \\\n    --computer-ou=\"OU=Linux Servers,OU=Servers,DC=domain,DC=org\" \\\n    domain.org\n</code></pre>"},{"location":"guide/step2-rhel/#step-88-verify-domain-join","title":"Step 8.8: Verify Domain Join","text":"<p>Check realm status:</p> <pre><code>sudo realm list\n</code></pre> <p>Expected output: <pre><code>domain.org\n  type: kerberos\n  realm-name: DOMAIN.ORG\n  domain-name: domain.org\n  configured: kerberos-member\n  server-software: active-directory\n  client-software: sssd\n  required-package: oddjob\n  required-package: oddjob-mkhomedir\n  required-package: sssd\n  required-package: adcli\n  required-package: samba-common-tools\n  login-formats: %U@domain.org\n  login-policy: allow-realm-logins\n</code></pre></p> <p>Key indicator: <code>configured: kerberos-member</code></p>"},{"location":"guide/step2-rhel/#step-89-configure-sssd-for-optimal-performance","title":"Step 8.9: Configure SSSD for Optimal Performance","text":"<p>Edit SSSD configuration:</p> <pre><code>sudo nano /etc/sssd/sssd.conf\n</code></pre> <p>Optimize configuration:</p> <pre><code>[sssd]\ndomains = domain.org\nconfig_file_version = 2\nservices = nss, pam, ssh\n\n[domain/domain.org]\n# Domain configuration\nad_domain = domain.org\nkrb5_realm = DOMAIN.ORG\nrealmd_tags = manages-system joined-with-adcli\ncache_credentials = True\nid_provider = ad\nkrb5_store_password_if_offline = True\ndefault_shell = /bin/bash\nldap_id_mapping = True\n\n# Allow simple usernames (no domain required)\nuse_fully_qualified_names = False\n\n# Home directory configuration\nfallback_homedir = /home/%u\noverride_homedir = /home/%u\n\n# Performance tuning\nldap_referrals = false\nldap_id_mapping = True\n\n# Enumerate users (useful for small domains)\nenumerate = False\n\n# Access control - limit to specific groups\n# access_provider = simple\n# simple_allow_groups = linux-admins, llm-users\n</code></pre> <p>Save: Ctrl+O, Enter, Ctrl+X</p> <p>Set proper permissions:</p> <pre><code>sudo chmod 600 /etc/sssd/sssd.conf\nsudo chown root:root /etc/sssd/sssd.conf\n</code></pre>"},{"location":"guide/step2-rhel/#step-810-configure-pam-for-home-directory-creation","title":"Step 8.10: Configure PAM for Home Directory Creation","text":"<p>Ensure home directories are auto-created:</p> <pre><code>sudo authselect select sssd with-mkhomedir --force\n</code></pre> <p>Or manually enable:</p> <pre><code>sudo systemctl enable --now oddjobd\n</code></pre>"},{"location":"guide/step2-rhel/#step-811-restart-sssd-service","title":"Step 8.11: Restart SSSD Service","text":"<p>Restart SSSD to apply changes:</p> <pre><code># Restart SSSD\nsudo systemctl restart sssd\n\n# Enable SSSD at boot\nsudo systemctl enable sssd\n\n# Check status\nsudo systemctl status sssd\n</code></pre> <p>Expected status: <pre><code>\u25cf sssd.service - System Security Services Daemon\n   Loaded: loaded (/usr/lib/systemd/system/sssd.service; enabled)\n   Active: active (running) since ...\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-812-test-ad-user-authentication","title":"Step 8.12: Test AD User Authentication","text":"<p>Verify AD user lookup:</p> <pre><code># Look up AD user (replace with actual AD username)\nid username\n\n# Look up AD user with domain\nid username@domain.org\n\n# Get user information\ngetent passwd username\n</code></pre> <p>Expected output: <pre><code>uid=1234567890(username) gid=1234567890(domain users) groups=1234567890(domain users),1234567891(linux-admins)\n</code></pre></p> <p>Test AD group lookup:</p> <pre><code>getent group \"domain users\"\ngetent group \"linux-admins\"\n</code></pre>"},{"location":"guide/step2-rhel/#step-813-test-ssh-login-with-ad-credentials","title":"Step 8.13: Test SSH Login with AD Credentials","text":"<p>From another machine, test SSH:</p> <pre><code>ssh username@192.168.1.100\n</code></pre> <p>Or test locally:</p> <pre><code>su - username\n</code></pre> <p>Enter AD password when prompted</p> <p>Successful login creates home directory automatically: <pre><code>Creating home directory for username.\nusername@llm-inference-01:~$\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-814-configure-sudo-access-for-ad-groups","title":"Step 8.14: Configure Sudo Access for AD Groups","text":"<p>Grant sudo access to AD group:</p> <pre><code>sudo visudo -f /etc/sudoers.d/ad-admins\n</code></pre> <p>Add: <pre><code># Allow AD linux-admins group full sudo access\n%linux-admins ALL=(ALL) ALL\n\n# Or without password (use with caution)\n# %linux-admins ALL=(ALL) NOPASSWD: ALL\n</code></pre></p> <p>Save: Ctrl+X, Y, Enter</p> <p>Test sudo access:</p> <pre><code># As AD user\nsudo whoami\n</code></pre> <p>Should output: <code>root</code></p>"},{"location":"guide/step2-rhel/#part-9-verification-and-testing","title":"Part 9: Verification and Testing","text":""},{"location":"guide/step2-rhel/#step-91-system-verification","title":"Step 9.1: System Verification","text":"<p>Verify all core components:</p> <pre><code># Check RHEL version\ncat /etc/redhat-release\n\n# Check subscription\nsudo subscription-manager status\n\n# Check hostname\nhostnamectl\n\n# Check network\nip addr show\nping -c 4 google.com\n\n# Check DNS\nnslookup domain.org\n\n# Check AD membership\nsudo realm list\n</code></pre>"},{"location":"guide/step2-rhel/#step-92-partition-verification","title":"Step 9.2: Partition Verification","text":"<p>Verify partition layout:</p> <pre><code># Show disk usage\ndf -h\n\n# Show partition table\nsudo fdisk -l /dev/nvme0n1\n\n# Verify swap\nsudo swapon --show\nfree -h\n</code></pre> <p>Expected output: <pre><code>Filesystem      Size  Used Avail Use% Mounted on\n/dev/nvme0n1p4  2.5T  8.2G  2.5T   1% /\n/dev/nvme0n1p5  500G  1.5G  499G   1% /var\n/dev/nvme0n1p6  650G  2.1G  648G   1% /home\n/dev/nvme0n1p2  1.0G  250M  750M  25% /boot\n/dev/nvme0n1p1  600M  12M   588M   2% /boot/efi\n</code></pre></p> <p>Verify swap: <pre><code>NAME           TYPE  SIZE USED PRIO\n/dev/nvme0n1p3 partition 256G   0B   -2\n</code></pre></p>"},{"location":"guide/step2-rhel/#step-93-ad-integration-verification","title":"Step 9.3: AD Integration Verification","text":"<p>Complete AD test:</p> <pre><code># Test Kerberos\nkinit administrator@DOMAIN.ORG\nklist\n\n# Test LDAP search\nldapsearch -x -H ldap://dc1.domain.org -b \"DC=domain,DC=org\" \"(sAMAccountName=username)\"\n\n# Test group membership\ngroups username\n\n# Test SSH key from AD (if configured)\ngetent sshkey username\n</code></pre>"},{"location":"guide/step2-rhel/#step-94-security-verification","title":"Step 9.4: Security Verification","text":"<p>Check firewall status:</p> <pre><code>sudo firewall-cmd --state\nsudo firewall-cmd --list-all\n</code></pre> <p>Check SELinux:</p> <pre><code>getenforce\n# Should show: Enforcing\n</code></pre>"},{"location":"guide/step2-rhel/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/step2-rhel/#issue-cannot-join-ad-domain","title":"Issue: Cannot Join AD Domain","text":"<p>Symptoms: - <code>realm join</code> fails with authentication error - \"Couldn't authenticate to active directory\" message</p> <p>Solutions:</p> <p>1. Verify DNS: <pre><code># DNS must resolve AD domain\nnslookup domain.org\ndig -t SRV _ldap._tcp.domain.org\n</code></pre></p> <p>2. Check time sync: <pre><code># Time must be within 5 minutes of AD\ntimedatectl\nsudo chronyd -q 'server dc1.domain.org iburst'\n</code></pre></p> <p>3. Verify network connectivity: <pre><code># Test LDAP port\ntelnet dc1.domain.org 389\n\n# Test Kerberos port\ntelnet dc1.domain.org 88\n</code></pre></p> <p>4. Check AD permissions: - Verify user has rights to join computers to domain - Check computer account quota in AD</p> <p>5. Try manual Kerberos test: <pre><code>kinit administrator@DOMAIN.ORG\nklist\n</code></pre></p>"},{"location":"guide/step2-rhel/#issue-ad-user-login-fails","title":"Issue: AD User Login Fails","text":"<p>Symptoms: - Can't SSH or login with AD credentials - \"Authentication failure\" message</p> <p>Solutions:</p> <p>1. Verify user lookup: <pre><code>id username\ngetent passwd username\n</code></pre></p> <p>2. Check SSSD status: <pre><code>sudo systemctl status sssd\nsudo journalctl -u sssd -f\n</code></pre></p> <p>3. Clear SSSD cache: <pre><code>sudo systemctl stop sssd\nsudo rm -rf /var/lib/sss/db/*\nsudo systemctl start sssd\n</code></pre></p> <p>4. Verify PAM configuration: <pre><code>authselect current\nsudo authselect select sssd with-mkhomedir --force\n</code></pre></p>"},{"location":"guide/step2-rhel/#issue-home-directory-not-created","title":"Issue: Home Directory Not Created","text":"<p>Symptoms: - AD user logs in but no home directory exists - \"Could not chdir to home directory\" error</p> <p>Solutions:</p> <pre><code># Verify oddjobd is running\nsudo systemctl status oddjobd\nsudo systemctl enable --now oddjobd\n\n# Manually create home directory\nsudo mkhomedir_helper username\n\n# Check PAM configuration\ngrep mkhomedir /etc/pam.d/system-auth\n# Should contain: session optional pam_oddjob_mkhomedir.so\n</code></pre>"},{"location":"guide/step2-rhel/#issue-slow-login-with-ad","title":"Issue: Slow Login with AD","text":"<p>Symptoms: - Login takes 30+ seconds - Slow response for <code>id</code> command</p> <p>Solutions:</p> <p>1. Disable enumeration: <pre><code>sudo nano /etc/sssd/sssd.conf\n# Set: enumerate = False\nsudo systemctl restart sssd\n</code></pre></p> <p>2. Reduce DNS timeout: <pre><code>sudo nano /etc/sssd/sssd.conf\n# Add under [domain/domain.org]:\ndns_resolver_timeout = 5\nldap_network_timeout = 3\nsudo systemctl restart sssd\n</code></pre></p> <p>3. Configure SSSD caching: <pre><code>sudo nano /etc/sssd/sssd.conf\n# Add:\nentry_cache_timeout = 300\nsudo systemctl restart sssd\n</code></pre></p>"},{"location":"guide/step2-rhel/#issue-partition-not-mounted","title":"Issue: Partition Not Mounted","text":"<p>Symptoms: - <code>/var</code> or <code>/home</code> shows wrong size - \"No space left on device\" on root</p> <p>Solutions:</p> <pre><code># Check mounts\nmount | grep nvme\n\n# Check /etc/fstab\ncat /etc/fstab\n\n# Manually mount if missing\nsudo mount -a\n\n# Regenerate fstab if corrupted\nsudo blkid\n# Add missing entries to /etc/fstab\n</code></pre>"},{"location":"guide/step2-rhel/#additional-resources","title":"Additional Resources","text":""},{"location":"guide/step2-rhel/#red-hat-documentation","title":"Red Hat Documentation","text":"<ul> <li>RHEL 10.1 Installation Guide</li> <li>Integrating RHEL with Active Directory</li> <li>Storage Administration Guide</li> <li>Security Hardening Guide</li> </ul>"},{"location":"guide/step2-rhel/#active-directory-integration","title":"Active Directory Integration","text":"<ul> <li>SSSD Configuration</li> <li>Realmd Documentation</li> <li>Kerberos Configuration</li> </ul>"},{"location":"guide/step2-rhel/#community-resources","title":"Community Resources","text":"<ul> <li>Red Hat Customer Portal</li> <li>Red Hat Developer Forums</li> <li>RHEL Subreddit</li> </ul>"},{"location":"guide/step2-rhel/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"guide/step2-rhel/#subscription-management","title":"Subscription Management","text":"<pre><code># Register system\nsudo subscription-manager register --username EMAIL\n\n# Attach subscription\nsudo subscription-manager attach --auto\n\n# Check status\nsudo subscription-manager status\n\n# List repositories\nsudo dnf repolist\n\n# Enable repository\nsudo subscription-manager repos --enable=REPO_ID\n</code></pre>"},{"location":"guide/step2-rhel/#active-directory","title":"Active Directory","text":"<pre><code># Discover domain\nsudo realm discover domain.org\n\n# Join domain\nsudo realm join -U administrator domain.org\n\n# Leave domain\nsudo realm leave domain.org\n\n# List domains\nsudo realm list\n\n# Test user lookup\nid username\ngetent passwd username\n\n# Check SSSD status\nsudo systemctl status sssd\n\n# Clear SSSD cache\nsudo sss_cache -E\n</code></pre>"},{"location":"guide/step2-rhel/#system-management","title":"System Management","text":"<pre><code># Check partitions\ndf -h\nsudo fdisk -l\n\n# Check swap\nfree -h\nsudo swapon --show\n\n# Update system\nsudo dnf update\n\n# Check services\nsudo systemctl status SERVICE_NAME\n\n# View logs\nsudo journalctl -u SERVICE_NAME -f\n</code></pre> <p>Installation Complete! \ud83c\udf89</p> <p>Your RHEL 10.1 system is now: - \u2705 Installed with optimized partitioning for Docker/LLM workloads - \u2705 Registered with Red Hat subscription - \u2705 Integrated with Active Directory domain (domain.org) - \u2705 Ready for NVIDIA driver installation - \u2705 Ready for Docker and vLLM deployment</p> <p>Next Steps: 1. Install NVIDIA drivers (see: NVIDIA-driver-installation.md) 2. Run step2.sh script for LLM software stack 3. Deploy Docker containers with Open WebUI and vLLM</p> <p>Last Updated: February 2026 RHEL Version: 10.1 Domain: domain.org Storage: 4TB NVMe with Docker-optimized partitioning</p>"},{"location":"guide/step3-nvidia/","title":"NVIDIA Driver Installation Guide for RHEL 10.1","text":"<p>Complete guide for installing NVIDIA drivers and CUDA Toolkit on Red Hat Enterprise Linux 10.1 for multi-GPU configurations (RTX 3090, RTX 5090, and other modern NVIDIA GPUs).</p>"},{"location":"guide/step3-nvidia/#prerequisites","title":"Prerequisites","text":"<ul> <li>Fresh installation of Red Hat Enterprise Linux 10.1</li> <li>Active Red Hat subscription (required)</li> <li>Root or sudo access</li> <li>Internet connectivity</li> <li>Multiple NVIDIA GPUs (e.g., RTX 3090, RTX 5090)</li> <li>Secure Boot disabled (recommended)</li> </ul>"},{"location":"guide/step3-nvidia/#important-notes","title":"Important Notes","text":"<p>\u26a0\ufe0f RHEL 10.1+ Simplified Installation Available</p> <p>If you're running RHEL 10.1 or later, Red Hat now provides a simplified installation method using the <code>rhel-drivers</code> tool. This is the recommended approach as it: - Uses drivers built and signed by Red Hat - Works with Secure Boot enabled - Automatically handles dependencies - Provides a one-command installation</p> <p>See the \"Alternative: RHEL 10.1+ Simplified Method\" section below for details.</p> <p>\u26a0\ufe0f RHEL 10.0 GPG Key Issue</p> <p>RHEL 10.0 has a known GPG key issue that must be resolved before proceeding with driver installation. This guide includes the fix as the first step.</p> <p>\u26a0\ufe0f Open vs Proprietary Driver</p> <p>This guide uses the NVIDIA Open Kernel Driver (<code>nvidia-open</code>), which is recommended for modern GPUs including RTX 3090 and RTX 5090. Note: - Open drivers are supported on Turing architecture and newer (RTX 2000 series+) - For older GPUs (Maxwell, Pascal, Volta), use proprietary drivers instead</p> <p>\u26a0\ufe0f Secure Boot Considerations</p> <p>The method in this guide uses locally downloaded drivers that are not Red Hat signed: - Secure Boot must be disabled for this method - For Secure Boot support, use the RHEL 10.1+ simplified method or precompiled signed drivers</p>"},{"location":"guide/step3-nvidia/#installation-steps","title":"Installation Steps","text":""},{"location":"guide/step3-nvidia/#1-fix-rhel-10-gpg-key-issue","title":"1. Fix RHEL 10 GPG Key Issue","text":"<p>Important: This step must be completed before proceeding with driver installation.</p> <p>RHEL 10 has a known bug where DNF transactions fail with GPG key errors. This must be resolved first.</p> <p>Reference: Red Hat Article - DNF transaction fails with GPG key errors</p> <pre><code># Attempt initial upgrade (may fail with GPG errors)\nsudo dnf upgrade\n\n# Clean DNF cache\nsudo dnf clean all\n\n# Check for the specific advisory\nsudo dnf updateinfo list RHBA-2025:21017\n\n# Locate the redhat-release package\nsudo dnf repoquery --location redhat-release\n\n# Update with the advisory, bypassing GPG check\nsudo sudo dnf update --advisory=RHBA-2025:21017 --nogpgcheck\n\n# Run upgrade again to ensure system is up to date\nsudo dnf upgrade\n</code></pre> <p>After this fix, DNF operations should work normally without GPG key errors.</p>"},{"location":"guide/step3-nvidia/#2-enable-required-repositories","title":"2. Enable Required Repositories","text":"<p>Enable the necessary Red Hat repositories for kernel development and additional packages.</p> <pre><code># Enable AppStream repository (will take a 5 minutes to respond)\nsudo subscription-manager repos --enable=rhel-10-for-x86_64-appstream-rpms\n\n# Enable BaseOS repository (will take a 5 minutes to respond)\nsudo subscription-manager repos --enable=rhel-10-for-x86_64-baseos-rpms\n\n# Enable CodeReady Builder repository (for development packages) (will take a 5 minutes to respond)\nsudo subscription-manager repos --enable=codeready-builder-for-rhel-10-x86_64-rpms\n</code></pre> <p>Verify repositories are enabled:</p> <pre><code>dnf repolist\n</code></pre>"},{"location":"guide/step3-nvidia/#3-install-kernel-development-packages","title":"3. Install Kernel Development Packages","text":"<p>Install the kernel headers and development packages that match your running kernel.</p> <pre><code>sudo dnf install kernel-devel-matched kernel-headers\n</code></pre> <p>Note: The <code>kernel-devel-matched</code> package ensures compatibility with your current running kernel. If you encounter issues, you can install the specific version:</p> <pre><code># Check your current kernel version\nsudo uname -r\n\n# Install specific kernel development packages\nsudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r)\n</code></pre> <p>This ensures the kernel modules can be built properly for your current kernel version.</p>"},{"location":"guide/step3-nvidia/#4-install-epel-repository","title":"4. Install EPEL Repository","text":"<p>EPEL (Extra Packages for Enterprise Linux) provides additional packages not included in RHEL.</p> <pre><code>sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n</code></pre>"},{"location":"guide/step3-nvidia/#5-download-and-install-nvidia-driver-repository","title":"5. Download and Install NVIDIA Driver Repository","text":"<p>Download the NVIDIA driver local repository RPM and install it.</p> <p>Download the driver repository:</p> <pre><code># Driver version 590.48.01 (adjust version as needed)\nsudo wget https://developer.download.nvidia.com/compute/nvidia-driver/590.48.01/local_installers/nvidia-driver-local-repo-rhel10-590.48.01-1.0-1.x86_64.rpm\n</code></pre> <p>Install the repository:</p> <pre><code>sudo rpm -i nvidia-driver-local-repo-rhel10-590.48.01-1.0-1.x86_64.rpm\n</code></pre> <p>Clean DNF cache:</p> <pre><code>sudo dnf clean all\n</code></pre>"},{"location":"guide/step3-nvidia/#6-install-nvidia-open-kernel-driver","title":"6. Install NVIDIA Open Kernel Driver","text":"<p>Install the NVIDIA open kernel driver, which provides better compatibility with modern RHEL systems.</p> <pre><code>dnf -y install nvidia-open-590\n</code></pre> <p>This will install: - NVIDIA open kernel modules - NVIDIA driver libraries - Required dependencies</p> <p>The installation may take several minutes to complete.</p>"},{"location":"guide/step3-nvidia/#7-download-and-install-cuda-toolkit","title":"7. Download and Install CUDA Toolkit","text":"<p>Download and install the CUDA Toolkit (version 13.1.1 in this example).</p> <p>Download CUDA repository:</p> <pre><code>sudo wget https://developer.download.nvidia.com/compute/cuda/13.1.1/local_installers/cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\n</code></pre> <p>Install CUDA repository:</p> <pre><code>sudo rpm -i cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\n</code></pre> <p>Clean DNF cache:</p> <pre><code>sudo dnf clean all\n</code></pre> <p>Install CUDA Toolkit:</p> <pre><code>sudo dnf -y install cuda-toolkit-13-1\n</code></pre> <p>This installs: - CUDA compiler (nvcc) - CUDA libraries - CUDA samples and documentation - Development tools</p>"},{"location":"guide/step3-nvidia/#8-configure-dracut-for-nvidia-modules","title":"8. Configure Dracut for NVIDIA Modules","text":"<p>Configure dracut to include NVIDIA kernel modules in the initial RAM filesystem (initramfs). This ensures the drivers load early in the boot process.</p> <p>First, blacklist the Nouveau driver (conflicts with NVIDIA):</p> <pre><code>sudo bash -c 'cat &gt; /etc/modprobe.d/blacklist-nouveau.conf &lt;&lt; EOF\nblacklist nouveau\noptions nouveau modeset=0\nEOF'\n</code></pre> <p>Create dracut configuration file:</p> <pre><code>sudo nano /usr/lib/dracut/dracut.conf.d/99-nvidia.conf\n</code></pre> <p>Add the following content:</p> <pre><code>add_drivers+=\" nvidia nvidia-drm nvidia-modeset nvidia-uvm \"\n</code></pre> <p>Note: Only include the <code>add_drivers</code> line. Do not add an <code>omit_drivers</code> line.</p> <p>Save and exit (Ctrl+X, then Y, then Enter)</p> <p>Rebuild the initramfs:</p> <pre><code>sudo dracut -fv --add-drivers \"nvidia nvidia-drm nvidia-modeset nvidia-uvm\"\n</code></pre> <p>This command: - <code>-f</code> forces a rebuild - <code>-v</code> provides verbose output - <code>--add-drivers</code> explicitly includes the NVIDIA modules</p>"},{"location":"guide/step3-nvidia/#9-reboot-system","title":"9. Reboot System","text":"<pre><code>sudo systemctl reboot\n</code></pre>"},{"location":"guide/step3-nvidia/#10-post-installation-verification","title":"10. Post-Installation Verification","text":"<p>After reboot, verify the NVIDIA driver and CUDA Toolkit are properly installed and functional.</p> <p>Check loaded kernel modules:</p> <pre><code>lsmod | grep nvidia\n</code></pre> <p>Expected output: <pre><code>nvidia_uvm           1523712  0\nnvidia_drm             73728  0\nnvidia_modeset       1306624  1 nvidia_drm\nnvidia              56426496  2 nvidia_uvm,nvidia_modeset\ndrm_kms_helper        176128  4 qxl,nvidia_drm\ndrm                   565248  7 drm_kms_helper,qxl,nvidia,drm_ttm_helper,nvidia_drm,ttm\n</code></pre></p> <p>Verify NVIDIA driver with nvidia-smi:</p> <pre><code>sudo nvidia-smi\n</code></pre> <p>Expected output (example with multiple GPUs): <pre><code>+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 590.48.01      Driver Version: 590.48.01      CUDA Version: 13.1          |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n| 30%   35C    P8              25W / 350W |      0MiB / 24576MiB |      0%      Default |\n+-----------------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce RTX 5090        Off | 00000000:02:00.0 Off |                  N/A |\n| 30%   33C    P8              28W / 450W |      0MiB / 32768MiB |      0%      Default |\n+-----------------------------------------+----------------------+----------------------+\n</code></pre></p>"},{"location":"guide/step3-nvidia/#11-set-cuda-environment-variables","title":"11. Set CUDA Environment Variables","text":"<p>Important: This configuration is required for <code>nvcc</code> to work properly.</p> <p>Add to <code>~/.bashrc</code>:</p> <pre><code>export PATH=/usr/local/cuda-13.1/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-13.1/lib64:$LD_LIBRARY_PATH\n</code></pre> <p>Then reload:</p> <pre><code>source ~/.bashrc\n</code></pre> <p>Verify CUDA compiler installation:</p> <pre><code>nvcc --version\n</code></pre> <p>Expected output: <pre><code>nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2024 NVIDIA Corporation\nBuilt on Wed_Oct_30_01:18:48_PDT_2024\nCuda compilation tools, release 13.1, V13.1.1\nBuild cuda_13.1.r13.1/compiler.34431801_0\n</code></pre></p> <p>Check driver module information:</p> <pre><code>modinfo nvidia\n</code></pre> <p>Test CUDA with a simple deviceQuery (if CUDA samples installed):</p> <pre><code>cd /usr/local/cuda-13.1/extras/demo_suite\n./deviceQuery\n</code></pre> <p>Configure CUDA environment variables (important!):</p> <p>Add CUDA to your PATH and LD_LIBRARY_PATH:</p> <pre><code>echo 'export PATH=/usr/local/cuda-13.1/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=/usr/local/cuda-13.1/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>For system-wide configuration:</p> <pre><code>sudo bash -c 'cat &gt; /etc/profile.d/cuda.sh &lt;&lt; EOF\nexport PATH=/usr/local/cuda-13.1/bin:\\$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-13.1/lib64:\\$LD_LIBRARY_PATH\nEOF'\n</code></pre>"},{"location":"guide/step3-nvidia/#enable-persistence-mode","title":"Enable Persistence Mode","text":"<p>Persistence mode keeps the NVIDIA driver loaded, reducing initialization time for subsequent GPU operations.</p>"},{"location":"guide/step3-nvidia/#install-nvidia-persistenced","title":"Install nvidia-persistenced","text":"<pre><code>sudo dnf install nvidia-persistenced\n</code></pre>"},{"location":"guide/step3-nvidia/#enable-and-start-the-service","title":"Enable and Start the Service","text":"<pre><code>sudo systemctl enable nvidia-persistenced\nsudo systemctl start nvidia-persistenced\n</code></pre>"},{"location":"guide/step3-nvidia/#verify-persistence-mode","title":"Verify Persistence Mode","text":"<pre><code>sudo systemctl status nvidia-persistenced\nsudo nvidia-smi\n</code></pre> <p>You should see <code>Persistence-M: On</code> for all NVIDIA GPUs in the nvidia-smi output.</p>"},{"location":"guide/step3-nvidia/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/step3-nvidia/#gpg-key-errors-persist","title":"GPG Key Errors Persist","text":"<p>If you continue to see GPG key errors after following Step 1:</p> <pre><code># Force clean all DNF metadata\nsudo dnf clean all\nsudo rm -rf /var/cache/dnf\n\n# Try update again\nsudo dnf update --nogpgcheck\n</code></pre>"},{"location":"guide/step3-nvidia/#nvidia-driver-not-loading","title":"NVIDIA Driver Not Loading","text":"<p>Check kernel messages:</p> <pre><code>dmesg | grep -i nvidia\n</code></pre> <p>Check systemd journal:</p> <pre><code>journalctl -b | grep -i nvidia\n</code></pre> <p>Verify dracut configuration was applied:</p> <pre><code>lsinitrd | grep nvidia\n</code></pre> <p>You should see the NVIDIA modules listed in the initramfs.</p>"},{"location":"guide/step3-nvidia/#multiple-gpu-issues","title":"Multiple GPU Issues","text":"<p>Verify all GPUs are detected:</p> <pre><code>nvidia-smi -L\n</code></pre> <p>Check PCIe bus configuration:</p> <pre><code>lspci | grep -i nvidia\n</code></pre> <p>Monitor GPU topology:</p> <pre><code>nvidia-smi topo -m\n</code></pre>"},{"location":"guide/step3-nvidia/#cuda-toolkit-not-found","title":"CUDA Toolkit Not Found","text":"<p>Set CUDA environment variables:</p> <p>Add to <code>~/.bashrc</code>:</p> <pre><code>export PATH=/usr/local/cuda-13.1/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-13.1/lib64:$LD_LIBRARY_PATH\n</code></pre> <p>Then reload:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"guide/step3-nvidia/#nouveau-driver-conflicts","title":"Nouveau Driver Conflicts","text":"<p>If the system still loads the Nouveau driver:</p> <pre><code># Verify Nouveau is disabled\nlsmod | grep nouveau\n\n# If Nouveau is loaded, ensure blacklist is correct\ncat /etc/modprobe.d/blacklist-nouveau.conf\n\n# Rebuild initramfs again\nsudo dracut -fv\nsudo reboot\n</code></pre>"},{"location":"guide/step3-nvidia/#selinux-considerations","title":"SELinux Considerations","text":"<p>SELinux may interfere with NVIDIA driver loading. Check status:</p> <pre><code>getenforce\n</code></pre> <p>If experiencing issues, you can temporarily set to permissive mode for testing:</p> <pre><code>sudo setenforce 0\n</code></pre> <p>To make it permanent (not recommended for production):</p> <pre><code>sudo sed -i 's/SELINUX=enforcing/SELINUX=permissive/' /etc/selinux/config\n</code></pre> <p>Note: It's better to create proper SELinux policies than disable it entirely.</p>"},{"location":"guide/step3-nvidia/#rebuild-initramfs","title":"Rebuild Initramfs","text":"<p>If drivers are not loading at boot:</p> <pre><code># Rebuild initramfs for current kernel\nsudo dracut -fv\n\n# Or rebuild for specific kernel\nsudo dracut -fv /boot/initramfs-$(uname -r).img $(uname -r)\n</code></pre>"},{"location":"guide/step3-nvidia/#driver-version-conflicts","title":"Driver Version Conflicts","text":"<p>If you need to switch driver versions:</p> <pre><code># Remove current driver\ndnf remove nvidia-open-*\n\n# Clean cache\ndnf clean all\n\n# Install different version\ndnf install nvidia-open-&lt;version&gt;\n</code></pre>"},{"location":"guide/step3-nvidia/#known-issues","title":"Known Issues","text":""},{"location":"guide/step3-nvidia/#rhel-10-specific-issues","title":"RHEL 10 Specific Issues","text":"<ul> <li>GPG Key Bug: Fixed in RHBA-2025:21017 advisory (addressed in Step 1)</li> <li>Kernel Updates: After kernel updates, you may need to rebuild initramfs:   <pre><code>sudo dracut -fv\nsudo systemctl reboot\n</code></pre></li> </ul>"},{"location":"guide/step3-nvidia/#multi-gpu-considerations","title":"Multi-GPU Considerations","text":"<ul> <li>Power Requirements: Ensure adequate PSU capacity</li> <li>RTX 3090: ~350W per card</li> <li>RTX 5090: ~450W per card</li> <li> <p>Recommended: 1200W+ PSU for dual GPU setup</p> </li> <li> <p>PCIe Bandwidth: Check motherboard specifications</p> </li> <li>Both GPUs should run at PCIe 4.0 x16 or x8 minimum</li> <li> <p>Some boards reduce lanes when multiple slots are populated</p> </li> <li> <p>Cooling: Multi-GPU configurations generate significant heat</p> </li> <li>Ensure proper case ventilation</li> <li>Monitor temperatures with <code>nvidia-smi dmon</code></li> </ul>"},{"location":"guide/step3-nvidia/#driver-updates","title":"Driver Updates","text":"<p>When updating NVIDIA drivers:</p> <pre><code># Update driver\ndnf update nvidia-open-*\n\n# Rebuild initramfs\nsudo dracut -fv\n\n# Reboot\nsudo systemctl reboot\n</code></pre>"},{"location":"guide/step3-nvidia/#alternative-rhel-101-simplified-installation-method","title":"Alternative: RHEL 10.1+ Simplified Installation Method","text":"<p>For RHEL 10.1 and later, Red Hat provides a much simpler installation method using <code>rhel-drivers</code>.</p>"},{"location":"guide/step3-nvidia/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>RHEL 10.1 or later</li> <li>Active Red Hat subscription</li> <li>Compatible NVIDIA GPU (Turing architecture or newer for open drivers)</li> </ul>"},{"location":"guide/step3-nvidia/#installation-steps_1","title":"Installation Steps","text":"<p>1. Install the rhel-drivers package:</p> <pre><code>sudo dnf install rhel-drivers\n</code></pre> <p>2. Install NVIDIA drivers with one command:</p> <pre><code>sudo rhel-drivers install nvidia\nsudo reboot\n</code></pre> <p>3. Verify installation:</p> <pre><code>nvidia-smi\n</code></pre>"},{"location":"guide/step3-nvidia/#advantages-of-this-method","title":"Advantages of this Method","text":"<ul> <li>\u2705 Drivers are built and signed by Red Hat</li> <li>\u2705 Works with Secure Boot enabled</li> <li>\u2705 Automatic dependency handling</li> <li>\u2705 No manual repository configuration needed</li> <li>\u2705 No EPEL required</li> <li>\u2705 Tested and validated driver/kernel combinations</li> <li>\u2705 Prevents kernel updates that break the driver</li> </ul>"},{"location":"guide/step3-nvidia/#installing-specific-driver-versions","title":"Installing Specific Driver Versions","text":"<p>If you need a specific driver version instead of the latest:</p> <p>Enable the supplementary repository:</p> <pre><code>sudo subscription-manager repos --enable=rhel-10-for-x86_64-supplementary-rpms\nsudo subscription-manager repos --enable=rhel-10-for-x86_64-extensions-rpms\n</code></pre> <p>Install specific version:</p> <pre><code>sudo dnf install kmod-nvidia-&lt;version&gt; nvidia-driver-&lt;version&gt;\nsudo reboot\n</code></pre>"},{"location":"guide/step3-nvidia/#cuda-toolkit-installation-rhel-101","title":"CUDA Toolkit Installation (RHEL 10.1+)","text":"<p>After installing the driver with <code>rhel-drivers</code>, install CUDA Toolkit:</p> <p>Enable EPEL for dependencies:</p> <pre><code>sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n</code></pre> <p>Download and install CUDA repository:</p> <pre><code>wget https://developer.download.nvidia.com/compute/cuda/13.1.1/local_installers/cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\nsudo rpm -i cuda-repo-rhel10-13-1-local-13.1.1_590.48.01-1.x86_64.rpm\nsudo dnf clean all\nsudo dnf install cuda-toolkit-13-1\n</code></pre> <p>Set environment variables:</p> <pre><code>echo 'export PATH=/usr/local/cuda-13.1/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=/usr/local/cuda-13.1/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"guide/step3-nvidia/#additional-resources","title":"Additional Resources","text":"<ul> <li>NVIDIA Driver Documentation</li> <li>NVIDIA Open GPU Kernel Modules</li> <li>Red Hat GPG Key Issue Solution</li> <li>Red Hat AI Accelerator Driver Guide</li> <li>NVIDIA Open GPU Drivers Signed by Red Hat</li> <li>CUDA Toolkit Documentation</li> <li>RHEL 10 Release Notes</li> </ul>"},{"location":"guide/step3-nvidia/#version-specific-downloads","title":"Version-Specific Downloads","text":"<ul> <li>NVIDIA Driver Downloads</li> <li>CUDA Toolkit Archive</li> </ul>"},{"location":"guide/step3-nvidia/#quick-reference-commands","title":"Quick Reference Commands","text":"<pre><code># Check driver status\nnvidia-smi\n\n# Monitor GPU usage\nwatch -n 1 nvidia-smi\n\n# Check loaded modules\nlsmod | grep nvidia\n\n# View GPU details\nnvidia-smi -q\n\n# Check CUDA version\nnvcc --version\n\n# Monitor temperatures and power\nnvidia-smi dmon\n\n# GPU topology (multi-GPU)\nnvidia-smi topo -m\n</code></pre>"},{"location":"guide/step3-nvidia/#license","title":"License","text":"<p>This guide is provided as-is for educational and informational purposes. Written by Greg Blake.</p>"},{"location":"guide/step3-nvidia/#contributing","title":"Contributing","text":"<p>Contributions, corrections, and improvements are welcome. Please submit a pull request or open an issue.</p> <p>Last Updated: February 2026 RHEL Version: 10 Driver Version: 590.48.01 CUDA Version: 13.1.1 Tested GPUs: RTX 3090, RTX 5090 Installation Method: NVIDIA Open Kernel Driver</p>"},{"location":"guide/step4-apps/","title":"Install App Stack","text":"<p>Complete post-NVIDIA driver installation guide for setting up a production-ready LLM inference system on Red Hat Enterprise Linux 10.1.</p>"},{"location":"guide/step4-apps/#overview","title":"Overview","text":"<p>This guide configures a RHEL 10.1 system for production LLM inference workloads. After completing these steps, your system will be ready to:</p> <ul> <li>Serve large language models with vLLM</li> <li>Run containerized AI workloads with GPU acceleration</li> <li>Monitor system and GPU performance in real-time</li> <li>Download and manage models from Hugging Face</li> <li>Handle multi-GPU inference efficiently</li> </ul> <p>Estimated Time: 45-60 minutes Difficulty: Intermediate</p>"},{"location":"guide/step4-apps/#prerequisites","title":"Prerequisites","text":"<p>\u2705 NVIDIA drivers successfully installed (from previous guide) \u2705 CUDA Toolkit installed and configured \u2705 Active Red Hat subscription \u2705 Root or sudo access \u2705 Internet connectivity \u2705 Minimum 100GB free disk space (for models and caches)</p> <p>Verify NVIDIA installation:</p> <pre><code>nvidia-smi\nnvcc --version\n</code></pre> <p>Both commands should execute successfully before proceeding.</p>"},{"location":"guide/step4-apps/#installation-roadmap","title":"Installation Roadmap","text":"<p>The installation follows this specific order to ensure dependencies are met:</p> <ol> <li>System Utilities \u2192 Basic command-line tools</li> <li>Git \u2192 Version control for repositories</li> <li>UV \u2192 Modern Python package manager</li> <li>Python 3.13 \u2192 Latest stable Python runtime</li> <li>Docker \u2192 Container platform</li> <li>NVIDIA Container Toolkit \u2192 GPU access for containers</li> <li>Monitoring Tools \u2192 System and GPU monitoring</li> <li>Hugging Face \u2192 Model management</li> </ol>"},{"location":"guide/step4-apps/#step-1-system-utilities-and-tools","title":"Step 1: System Utilities and Tools","text":"<p>Install essential command-line utilities for system management and editing.</p>"},{"location":"guide/step4-apps/#install-core-utilities","title":"Install Core Utilities","text":"<pre><code># Update system first\nsudo dnf update -y\n\n# Install essential utilities\nsudo dnf install -y \\\n    wget \\\n    curl \\\n    vim \\\n    nano \\\n    htop \\\n    git \\\n    gcc \\\n    gcc-c++ \\\n    make \\\n    cmake \\\n    automake \\\n    autoconf \\\n    libtool \\\n    python3-devel \\\n    openssl-devel \\\n    bzip2-devel \\\n    libffi-devel \\\n    zlib-devel \\\n    readline-devel \\\n    sqlite-devel \\\n    ncurses-devel\n</code></pre>"},{"location":"guide/step4-apps/#verify-installation","title":"Verify Installation","text":"<pre><code># Check each utility\nwget --version\ncurl --version\nvim --version\nnano --version\nhtop --version\n</code></pre>"},{"location":"guide/step4-apps/#step-2-version-control-with-git","title":"Step 2: Version Control with Git","text":"<p>Git is essential for cloning repositories and managing code.</p>"},{"location":"guide/step4-apps/#configure-git","title":"Configure Git","text":"<pre><code># Set up global git configuration\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"[email protected]\"\n\n# Verify configuration\ngit config --list\n</code></pre>"},{"location":"guide/step4-apps/#test-git","title":"Test Git","text":"<pre><code># Clone a test repository\ngit clone https://github.com/vllm-project/vllm.git /tmp/vllm-test\nrm -rf /tmp/vllm-test\n</code></pre>"},{"location":"guide/step4-apps/#step-3-python-environment-manager-uv","title":"Step 3: Python Environment Manager (UV)","text":"<p>UV is a blazing-fast Python package manager written in Rust, 10-100x faster than pip.</p>"},{"location":"guide/step4-apps/#install-uv","title":"Install UV","text":"<pre><code># Install UV using the standalone installer\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"guide/step4-apps/#configure-uv","title":"Configure UV","text":"<pre><code># Add UV to PATH (automatically done by installer)\n# Reload shell configuration\nsource ~/.bashrc\n\n# Verify installation\nuv --version\n</code></pre> <p>Expected output: <pre><code>uv 0.5.x (or later)\n</code></pre></p>"},{"location":"guide/step4-apps/#configure-uv-for-system-wide-use","title":"Configure UV for System-Wide Use","text":"<pre><code># Enable shell completion for UV\necho 'eval \"$(uv generate-shell-completion bash)\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"guide/step4-apps/#uv-quick-reference","title":"UV Quick Reference","text":"<pre><code># Create virtual environment\nuv venv myenv\n\n# Activate environment\nsource myenv/bin/activate\n\n# Install package\nuv pip install package-name\n\n# Install from requirements.txt\nuv pip install -r requirements.txt\n\n# List installed packages\nuv pip list\n</code></pre>"},{"location":"guide/step4-apps/#step-4-python-313-installation","title":"Step 4: Python 3.13 Installation","text":"<p>Python 3.13 provides performance improvements and is recommended for vLLM.</p>"},{"location":"guide/step4-apps/#install-python-313-with-uv","title":"Install Python 3.13 with UV","text":"<pre><code># Install Python 3.13\nuv python install 3.13\n\n# Verify installation\nuv python list\n\n# Set Python 3.13 as default for projects\nuv python pin 3.13\n</code></pre>"},{"location":"guide/step4-apps/#verify-python-installation","title":"Verify Python Installation","text":"<pre><code># Check Python version\npython3.13 --version\n\n# Check pip\npython3.13 -m pip --version\n</code></pre> <p>Expected output: <pre><code>Python 3.13.x\npip 24.x from /path/to/python3.13/site-packages/pip (python 3.13)\n</code></pre></p>"},{"location":"guide/step4-apps/#create-system-wide-python-313-alias","title":"Create System-Wide Python 3.13 Alias","text":"<pre><code># Add alias to bashrc\necho 'alias python=python3.13' &gt;&gt; ~/.bashrc\necho 'alias python3=python3.13' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Verify\npython --version\n</code></pre>"},{"location":"guide/step4-apps/#step-5-docker-installation","title":"Step 5: Docker Installation","text":"<p>Docker is required for containerized LLM deployments and provides isolation for different models.</p>"},{"location":"guide/step4-apps/#add-docker-repository","title":"Add Docker Repository","text":"<pre><code># Add Docker CE repository\nsudo dnf config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo\n</code></pre>"},{"location":"guide/step4-apps/#install-docker","title":"Install Docker","text":"<pre><code># Install Docker CE and related packages\nsudo dnf install -y \\\n    docker-ce \\\n    docker-ce-cli \\\n    containerd.io \\\n    docker-buildx-plugin \\\n    docker-compose-plugin\n</code></pre>"},{"location":"guide/step4-apps/#configure-docker-service","title":"Configure Docker Service","text":"<pre><code># Start Docker service\nsudo systemctl start docker\n\n# Enable Docker to start on boot\nsudo systemctl enable docker\n\n# Verify Docker is running\nsudo systemctl status docker\n</code></pre>"},{"location":"guide/step4-apps/#docker-firewall-troubleshooting","title":"Docker Firewall Troubleshooting","text":"<p>If Docker fails to start properly, check the firewall configuration:</p> <p>Check docker0 zone assignment:</p> <pre><code>sudo firewall-cmd --get-zone-of-interface=docker0\n</code></pre> <p>Remove docker0 from trusted zone (if needed):</p> <pre><code>sudo firewall-cmd --permanent --zone=trusted --remove-interface=docker0\n</code></pre> <p>Reload firewalld and restart Docker:</p> <pre><code>sudo firewall-cmd --reload\nsudo systemctl restart docker\nsudo systemctl status docker\n</code></pre>"},{"location":"guide/step4-apps/#add-user-to-docker-group","title":"Add User to Docker Group","text":"<p>Important: This allows running Docker without sudo.</p> <pre><code># Add current user to docker group\nsudo usermod -aG docker $USER\n\n# Apply group changes (requires logout/login or use newgrp)\nnewgrp docker\n\n# Verify\ngroups\n</code></pre> <p>You should see <code>docker</code> in the list of groups.</p>"},{"location":"guide/step4-apps/#test-docker-installation","title":"Test Docker Installation","text":"<pre><code># Run hello-world container\ndocker run hello-world\n\n# Check Docker version\ndocker --version\ndocker compose version\n</code></pre> <p>Expected output: <pre><code>Docker version 29.2.1, build xxxxxxx\nDocker Compose version v5.0.2 - or something laters\n</code></pre></p>"},{"location":"guide/step4-apps/#configure-docker-for-production","title":"Configure Docker for Production","text":"<p>Create daemon configuration for optimal performance:</p> <pre><code>sudo nano /etc/docker/daemon.json\n</code></pre> <p>Add the following configuration:</p> <pre><code>{\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"storage-driver\": \"overlay2\",\n  \"default-runtime\": \"nvidia\"\n}\n</code></pre> <p>Restart Docker:</p> <pre><code>sudo systemctl restart docker\n</code></pre>"},{"location":"guide/step4-apps/#step-6-nvidia-container-toolkit","title":"Step 6: NVIDIA Container Toolkit","text":"<p>The NVIDIA Container Toolkit enables Docker containers to access GPUs.</p>"},{"location":"guide/step4-apps/#add-nvidia-container-toolkit-repository","title":"Add NVIDIA Container Toolkit Repository","text":"<pre><code># Configure the repository\ncurl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \\\nsudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo\n</code></pre>"},{"location":"guide/step4-apps/#install-nvidia-container-toolkit","title":"Install NVIDIA Container Toolkit","text":"<pre><code># Clean DNF cache\nsudo dnf clean all\n\n# Install the toolkit\nsudo dnf install -y nvidia-container-toolkit\n</code></pre>"},{"location":"guide/step4-apps/#configure-docker-to-use-nvidia-runtime","title":"Configure Docker to Use NVIDIA Runtime","text":"<pre><code># Configure the container runtime\nsudo nvidia-ctk runtime configure --runtime=docker\n\n# Restart Docker to apply changes\nsudo systemctl restart docker\n</code></pre>"},{"location":"guide/step4-apps/#verify-nvidia-docker-integration","title":"Verify NVIDIA Docker Integration","text":"<pre><code># Test GPU access in container\ndocker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n</code></pre> <p>Expected output: You should see the nvidia-smi output from within the container showing your GPUs.</p>"},{"location":"guide/step4-apps/#advanced-gpu-configuration","title":"Advanced GPU Configuration","text":"<p>Specify specific GPUs:</p> <pre><code># Use GPU 0 only\ndocker run --rm --gpus '\"device=0\"' nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n\n# Use GPUs 0 and 1\ndocker run --rm --gpus '\"device=0,1\"' nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n</code></pre>"},{"location":"guide/step4-apps/#step-7-system-monitoring-tools","title":"Step 7: System Monitoring Tools","text":"<p>Install advanced monitoring tools for system and GPU performance tracking.</p>"},{"location":"guide/step4-apps/#install-nvitop-nvidia-gpu-monitor","title":"Install nvitop (NVIDIA GPU Monitor)","text":"<pre><code># Create virtual environment for monitoring tools\nuv venv ~/.venv/monitoring\nsource ~/.venv/monitoring/bin/activate\n\n# Install nvitop\nuv pip install nvitop\n\n# Deactivate and create wrapper\ndeactivate\n\n# Create system-wide nvitop command\nsudo bash -c 'cat &gt; /usr/local/bin/nvitop &lt;&lt; \"EOF\"\n#!/bin/bash\nsource ~/.venv/monitoring/bin/activate\nnvitop \"$@\"\ndeactivate\nEOF'\n\nsudo chmod +x /usr/local/bin/nvitop\n</code></pre> <p>Test nvitop:</p> <pre><code>nvitop\n</code></pre> <p>Press <code>q</code> to exit.</p>"},{"location":"guide/step4-apps/#install-btop-advanced-system-monitor","title":"Install btop (Advanced System Monitor)","text":"<pre><code># Install btop from EPEL or build from source\n# For RHEL 10, compile from source for latest version\n\n# Install build dependencies\nsudo dnf install -y coreutils sed git\n\n# Clone btop repository\ncd /tmp\ngit clone https://github.com/aristocratos/btop.git\ncd btop\n\n# Build and install\nmake\nsudo make install\n\n# Verify\nbtop --version\n</code></pre> <p>Test btop:</p> <pre><code>btop\n</code></pre> <p>Press <code>q</code> to exit.</p>"},{"location":"guide/step4-apps/#configure-htop","title":"Configure htop","text":"<p>htop should already be installed from Step 1. Configure it for better display:</p> <pre><code># Run htop\nhtop\n</code></pre> <p>Press <code>F2</code> for setup, customize as needed, then <code>F10</code> to save and exit.</p>"},{"location":"guide/step4-apps/#create-monitoring-aliases","title":"Create Monitoring Aliases","text":"<pre><code># Add useful aliases to bashrc\ncat &gt;&gt; ~/.bashrc &lt;&lt; 'EOF'\n\n# Monitoring aliases\nalias gpu='watch -n 1 nvidia-smi'\nalias gpumon='nvitop'\nalias sysmon='btop'\nalias temp='nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader'\nalias gpumem='nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader'\nalias gpuutil='nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader'\nEOF\n\nsource ~/.bashrc\n</code></pre>"},{"location":"guide/step4-apps/#step-8-hugging-face-cli-and-authentication","title":"Step 8: Hugging Face CLI and Authentication","text":"<p>Hugging Face Hub hosts thousands of pre-trained models. Authentication is required for gated models.</p>"},{"location":"guide/step4-apps/#install-hugging-face-hub","title":"Install Hugging Face Hub","text":"<pre><code># Activate vLLM environment (or use UV directly)\nsource ~/.venv/vllm/bin/activate\n\n# Install huggingface-hub CLI\nuv pip install -U \"huggingface_hub[cli]\"\n</code></pre>"},{"location":"guide/step4-apps/#authenticate-with-hugging-face","title":"Authenticate with Hugging Face","text":"<p>Option 1: Interactive Login please paste your hugging face login token to login. go to huggingface.co and register and create a token for your computer.</p> <pre><code>hf auth login\n</code></pre> <p>You'll be prompted to enter your Hugging Face token. Get your token from: https://huggingface.co/settings/tokens</p> <p>Option 2: Environment Variable</p> <pre><code># Add to ~/.bashrc for persistence\necho 'export HF_TOKEN=\"your_token_here\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Option 3: Token File</p> <pre><code># Create token file\nmkdir -p ~/.cache/huggingface\necho \"your_token_here\" &gt; ~/.cache/huggingface/token\nchmod 600 ~/.cache/huggingface/token\n</code></pre>"},{"location":"guide/step4-apps/#verify-authentication","title":"Verify Authentication","text":"<pre><code>huggingface-cli whoami\n</code></pre> <p>Expected output: <pre><code>username: your-username\norgs: []\n</code></pre></p>"},{"location":"guide/step4-apps/#download-models-with-hugging-face-cli","title":"Download Models with Hugging Face CLI","text":"<pre><code># Download a model\nhuggingface-cli download meta-llama/Llama-3.2-1B\n\n# Download to specific directory\nhuggingface-cli download meta-llama/Llama-3.2-1B --local-dir ./models/llama-3.2-1b\n\n# List downloaded models\nls -lh ~/.cache/huggingface/hub/\n</code></pre>"},{"location":"guide/step4-apps/#hugging-face-cache-management","title":"Hugging Face Cache Management","text":"<pre><code># Check cache size\nhuggingface-cli scan-cache\n\n# Delete unused models\nhuggingface-cli delete-cache\n\n# Set custom cache directory\nexport HF_HOME=/data/huggingface_cache\n</code></pre> <p>Add to <code>~/.bashrc</code> for persistence:</p> <pre><code>echo 'export HF_HOME=/data/huggingface_cache' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"guide/step4-apps/#configure-firewall","title":"Configure Firewall","text":"<pre><code># Allow vLLM API port\nsudo firewall-cmd --permanent --add-port=8000/tcp\nsudo firewall-cmd --reload\n\n# Verify\nsudo firewall-cmd --list-ports\n</code></pre>"},{"location":"guide/step4-apps/#additional-resources","title":"Additional Resources","text":""},{"location":"guide/step4-apps/#official-documentation","title":"Official Documentation","text":"<ul> <li>vLLM Documentation</li> <li>Hugging Face Hub Documentation</li> <li>NVIDIA Container Toolkit Documentation</li> <li>UV Documentation</li> <li>Docker Documentation</li> </ul>"},{"location":"guide/step4-apps/#community-resources","title":"Community Resources","text":"<ul> <li>vLLM GitHub</li> <li>vLLM Discord</li> <li>Hugging Face Forums</li> </ul>"},{"location":"guide/step4-apps/#performance-benchmarks","title":"Performance Benchmarks","text":"<ul> <li>vLLM Performance Benchmarks</li> <li>Multi-GPU Scaling Guide</li> </ul>"},{"location":"guide/step4-apps/#model-resources","title":"Model Resources","text":"<ul> <li>Hugging Face Model Hub</li> <li>vLLM Supported Models</li> <li>LLM Leaderboard</li> </ul>"},{"location":"guide/step4-apps/#quick-command-reference","title":"Quick Command Reference","text":"<pre><code># Monitoring\ngpu                    # Watch nvidia-smi\ngpumon                # nvitop\nsysmon                # btop\ntemp                  # GPU temperatures\ngpumem                # GPU memory usage\n\n# vLLM\nsource ~/.venv/vllm/bin/activate          # Activate vLLM environment\nvllm serve model-name                     # Start vLLM server\nsystemctl status vllm                     # Check vLLM service\n\n# Hugging Face\nhuggingface-cli whoami                    # Check auth status\nhuggingface-cli download model-id         # Download model\nhuggingface-cli scan-cache                # Check cache\ndownload-model model-id                   # Custom download script\n\n# Docker\ndocker ps                                 # List running containers\ndocker images                             # List images\ndocker run --gpus all ...                 # Run with GPU\ndocker logs container-name                # View logs\n\n# UV\nuv venv env-name                          # Create environment\nuv pip install package                    # Install package\nuv pip list                               # List packages\nuv python list                            # List Python versions\n</code></pre> <p>Configuration Complete!</p> <p>Your RHEL 10.1 system is now fully configured for production LLM inference workloads.</p> <p>Next recommended steps: 1. Download your production models using <code>download-model</code> 2. Configure the vLLM service with your preferred model 3. Set up monitoring dashboards 4. Test performance with your expected workload 5. Configure backup and model versioning</p> <p>Last Updated: February 2026 System: RHEL 10.1 Target Use Case: LLM Inference with Multi-GPU Support</p>"},{"location":"guide/step5-webui/","title":"Step 3: Docker Deployment - Open WebUI with vLLM","text":"<p>Complete guide for deploying Open WebUI and vLLM in containerized environments using Docker Compose. This setup provides a ChatGPT-like web interface powered by your local GPU-accelerated LLM inference engine.</p>"},{"location":"guide/step5-webui/#overview","title":"Overview","text":"<p>This deployment combines two powerful components:</p> <ul> <li>vLLM: High-performance LLM inference engine with OpenAI-compatible API</li> <li>Open WebUI: Modern, ChatGPT-like web interface for interacting with language models</li> </ul>"},{"location":"guide/step5-webui/#key-benefits","title":"Key Benefits","text":"<ul> <li>GPU-accelerated inference with vLLM</li> <li>User-friendly ChatGPT-like interface</li> <li>Completely private and self-hosted</li> <li>Containerized for easy deployment and portability</li> <li>Support for multiple models and users</li> <li>Persistent storage for conversations and settings</li> </ul>"},{"location":"guide/step5-webui/#use-cases","title":"Use Cases","text":"<ul> <li>Development and testing of LLM applications</li> <li>Private AI assistant for teams</li> <li>Research and experimentation with open-source models</li> <li>Production LLM serving with web UI</li> </ul>"},{"location":"guide/step5-webui/#architecture","title":"Architecture","text":"<pre><code>+-----------------------------------------------------+\n|                    User Browser                     |\n|               http://localhost:3000                 |\n+-------------------------+---------------------------+\n                          |\n                          | Port 3000\n                          |\n+-------------------------v---------------------------+\n|               Open WebUI Container                  |\n|          (ghcr.io/open-webui/open-webui)            |\n|                                                     |\n|    - Web Interface                                  |\n|    - User Management                                |\n|    - Conversation History                           |\n|    - Document Upload &amp; RAG                          |\n+-------------------------+---------------------------+\n                          |\n                          | Internal Network\n                          | http://vllm:8000/v1\n                          |\n+-------------------------v---------------------------+\n|                  vLLM Container                     |\n|               (vllm/vllm-openai)                    |\n|                                                     |\n|    - LLM Inference Engine                           |\n|    - OpenAI-Compatible API                          |\n|    - GPU Acceleration                               |\n|    - Model Loading &amp; Caching                        |\n+-------------------------+---------------------------+\n                          |\n                          | GPU Access\n                          |\n+-------------------------v---------------------------+\n|                   NVIDIA GPU(s)                     |\n|            (RTX 3090, RTX 5090, etc.)               |\n+-----------------------------------------------------+\n</code></pre>"},{"location":"guide/step5-webui/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have completed:</p> <p>\u2705 Step 1: NVIDIA drivers and CUDA toolkit installed \u2705 Step 2: Docker, NVIDIA Container Toolkit, and supporting tools installed \u2705 Minimum 16GB RAM (32GB+ recommended) \u2705 Sufficient disk space (100GB+ for models and data) \u2705 At least one NVIDIA GPU with 12GB+ VRAM</p> <p>Verify prerequisites:</p> <pre><code># Check Docker\ndocker --version\ndocker compose version\n\n# Check NVIDIA Docker support\ndocker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n\n# Check available disk space\ndf -h /var/lib/docker\n</code></pre>"},{"location":"guide/step5-webui/#directory-structure","title":"Directory Structure","text":"<p>Create a dedicated project directory for your deployment:</p> <pre><code>mkdir -p ~/llm-stack\ncd ~/llm-stack\n</code></pre> <p>Recommended structure:</p> <pre><code>llm-stack/\n\u251c\u2500\u2500 docker-compose.yml          # Main compose file\n\u251c\u2500\u2500 .env                        # Environment variables\n\u251c\u2500\u2500 models/                     # Hugging Face model cache\n\u2502   \u2514\u2500\u2500 models--meta-llama--Llama-3.2-1B/\n\u251c\u2500\u2500 openwebui-data/            # Open WebUI persistent data\n\u2502   \u251c\u2500\u2500 uploads/\n\u2502   \u251c\u2500\u2500 cache/\n\u2502   \u2514\u2500\u2500 vector_db/\n\u251c\u2500\u2500 nginx/                      # NGINX config (optional)\n\u2502   \u251c\u2500\u2500 nginx.conf\n\u2502   \u2514\u2500\u2500 certs/\n\u2502       \u251c\u2500\u2500 server.crt\n\u2502       \u2514\u2500\u2500 server.key\n\u2514\u2500\u2500 logs/                       # Application logs\n    \u251c\u2500\u2500 vllm.log\n    \u2514\u2500\u2500 openwebui.log\n</code></pre> <p>Create directories:</p> <pre><code>cd ~/llm-stack\nmkdir -p models openwebui-data nginx/certs logs\n</code></pre>"},{"location":"guide/step5-webui/#configuration-files","title":"Configuration Files","text":""},{"location":"guide/step5-webui/#docker-compose-file","title":"Docker Compose File","text":"<p>Create the main <code>docker-compose.yml</code> file:</p> <pre><code>nano docker-compose.yml\n</code></pre> <p>Basic Configuration (Single GPU):</p> <pre><code>version: '3.8'\n\nservices:\n  # vLLM Inference Engine\n  vllm:\n    image: vllm/vllm-openai:latest\n    container_name: vllm-server\n    runtime: nvidia\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n      - HF_HOME=/models\n      - HF_TOKEN=${HF_TOKEN}\n    volumes:\n      - ./models:/models:rw\n      - ./logs:/logs:rw\n    ports:\n      - \"8000:8000\"\n    command:\n      - --model\n      - meta-llama/Llama-3.2-1B-Instruct\n      - --host\n      - \"0.0.0.0\"\n      - --port\n      - \"8000\"\n      - --gpu-memory-utilization\n      - \"0.9\"\n      - --max-model-len\n      - \"4096\"\n      - --dtype\n      - auto\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n      start_period: 300s\n    restart: unless-stopped\n    networks:\n      - llm-network\n\n  # Open WebUI Frontend\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    container_name: open-webui\n    depends_on:\n      vllm:\n        condition: service_healthy\n    environment:\n      - OPENAI_API_BASE_URL=http://vllm:8000/v1\n      - OPENAI_API_KEY=sk-dummy-key\n      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}\n      - WEBUI_NAME=LLM Inference Platform\n      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}\n      - DEFAULT_USER_ROLE=user\n      - ENABLE_OLLAMA_API=false\n      - ENABLE_OPENAI_API=true\n    volumes:\n      - ./openwebui-data:/app/backend/data:rw\n    ports:\n      - \"3000:8080\"\n    restart: unless-stopped\n    networks:\n      - llm-network\n\nnetworks:\n  llm-network:\n    driver: bridge\n\nvolumes:\n  models:\n  openwebui-data:\n</code></pre>"},{"location":"guide/step5-webui/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file for sensitive configuration:</p> <pre><code>nano .env\n</code></pre> <p>Add the following content:</p> <pre><code># Hugging Face Token (required for gated models like Llama)\n# Get your token from https://huggingface.co/settings/tokens\nHF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n# Open WebUI Secret Key (generate with: openssl rand -hex 32)\nWEBUI_SECRET_KEY=your-secret-key-here-generate-with-openssl\n\n# User Registration\nENABLE_SIGNUP=true\n\n# Optional: OpenAI API Key (if using external models)\nOPENAI_API_KEY=\n\n# Optional: Custom model path\nMODEL_NAME=meta-llama/Llama-3.2-1B-Instruct\n\n# GPU Configuration\nCUDA_VISIBLE_DEVICES=0,1\n</code></pre> <p>Generate a secure secret key:</p> <pre><code>openssl rand -hex 32 &gt;&gt; .env\n</code></pre> <p>Secure the .env file:</p> <pre><code>chmod 600 .env\n</code></pre>"},{"location":"guide/step5-webui/#deployment-options","title":"Deployment Options","text":""},{"location":"guide/step5-webui/#option-1-basic-deployment","title":"Option 1: Basic Deployment","text":"<p>Best for: Single GPU systems, development, testing</p> <p>Features: - Single vLLM instance - One model loaded at a time - Simple configuration</p> <p>docker-compose.yml (see Basic Configuration above)</p> <p>Deploy:</p> <pre><code>cd ~/llm-stack\ndocker compose up -d\n</code></pre>"},{"location":"guide/step5-webui/#option-2-multi-gpu-deployment","title":"Option 2: Multi-GPU Deployment","text":"<p>Best for: Systems with multiple GPUs, higher throughput requirements</p> <p>Features: - Tensor parallelism across GPUs - Higher throughput - Larger model support</p> <p>docker-compose-multi-gpu.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  vllm:\n    image: vllm/vllm-openai:latest\n    container_name: vllm-server\n    runtime: nvidia\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=0,1  # Use GPU 0 and 1\n      - HF_HOME=/models\n      - HF_TOKEN=${HF_TOKEN}\n    volumes:\n      - ./models:/models:rw\n      - ./logs:/logs:rw\n    ports:\n      - \"8000:8000\"\n    command:\n      - --model\n      - meta-llama/Llama-3.2-3B-Instruct\n      - --host\n      - \"0.0.0.0\"\n      - --port\n      - \"8000\"\n      - --tensor-parallel-size\n      - \"2\"  # Use 2 GPUs\n      - --gpu-memory-utilization\n      - \"0.95\"\n      - --max-model-len\n      - \"8192\"\n      - --dtype\n      - auto\n      - --enforce-eager  # Disable CUDA graphs for stability\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              device_ids: ['0', '1']\n              capabilities: [gpu]\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n      start_period: 600s  # Longer startup for larger models\n    restart: unless-stopped\n    networks:\n      - llm-network\n\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    container_name: open-webui\n    depends_on:\n      vllm:\n        condition: service_healthy\n    environment:\n      - OPENAI_API_BASE_URL=http://vllm:8000/v1\n      - OPENAI_API_KEY=sk-dummy-key\n      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}\n      - WEBUI_NAME=Multi-GPU LLM Platform\n      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-false}\n      - DEFAULT_USER_ROLE=user\n      - ENABLE_OLLAMA_API=false\n      - ENABLE_OPENAI_API=true\n    volumes:\n      - ./openwebui-data:/app/backend/data:rw\n    ports:\n      - \"3000:8080\"\n    restart: unless-stopped\n    networks:\n      - llm-network\n\nnetworks:\n  llm-network:\n    driver: bridge\n</code></pre> <p>Deploy:</p> <pre><code>docker compose -f docker-compose-multi-gpu.yml up -d\n</code></pre>"},{"location":"guide/step5-webui/#option-3-production-deployment-with-nginx","title":"Option 3: Production Deployment with NGINX","text":"<p>Best for: Production environments, SSL/TLS requirements, multiple domains</p> <p>Features: - NGINX reverse proxy - SSL/TLS termination - Load balancing ready - Enhanced security</p> <p>Create NGINX configuration:</p> <pre><code>nano nginx/nginx.conf\n</code></pre> <p>Add content:</p> <pre><code>events {\n    worker_connections 1024;\n}\n\nhttp {\n    upstream open-webui {\n        server open-webui:8080;\n    }\n\n    upstream vllm-api {\n        server vllm:8000;\n    }\n\n    # HTTP to HTTPS redirect\n    server {\n        listen 80;\n        server_name your-domain.com;\n        return 301 https://$server_name$request_uri;\n    }\n\n    # HTTPS server for Open WebUI\n    server {\n        listen 443 ssl http2;\n        server_name your-domain.com;\n\n        ssl_certificate /etc/nginx/certs/server.crt;\n        ssl_certificate_key /etc/nginx/certs/server.key;\n        ssl_protocols TLSv1.2 TLSv1.3;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n\n        client_max_body_size 100M;\n\n        location / {\n            proxy_pass http://open-webui;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # WebSocket support\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n        }\n\n        # Optional: Direct API access\n        location /api/ {\n            proxy_pass http://vllm-api/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n    }\n}\n</code></pre> <p>Generate self-signed SSL certificate (for testing):</p> <pre><code>openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n  -keyout nginx/certs/server.key \\\n  -out nginx/certs/server.crt \\\n  -subj \"/C=US/ST=State/L=City/O=Organization/CN=localhost\"\n</code></pre> <p>docker-compose-nginx.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  vllm:\n    image: vllm/vllm-openai:latest\n    container_name: vllm-server\n    runtime: nvidia\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n      - HF_HOME=/models\n      - HF_TOKEN=${HF_TOKEN}\n    volumes:\n      - ./models:/models:rw\n    # No port exposure - accessed through NGINX\n    command:\n      - --model\n      - meta-llama/Llama-3.2-1B-Instruct\n      - --host\n      - \"0.0.0.0\"\n      - --port\n      - \"8000\"\n      - --gpu-memory-utilization\n      - \"0.9\"\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n      start_period: 300s\n    restart: unless-stopped\n    networks:\n      - llm-network\n\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    container_name: open-webui\n    depends_on:\n      vllm:\n        condition: service_healthy\n    environment:\n      - OPENAI_API_BASE_URL=http://vllm:8000/v1\n      - OPENAI_API_KEY=sk-dummy-key\n      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}\n      - WEBUI_NAME=Production LLM Platform\n      - ENABLE_SIGNUP=false\n      - DEFAULT_USER_ROLE=pending\n    volumes:\n      - ./openwebui-data:/app/backend/data:rw\n    # No port exposure - accessed through NGINX\n    restart: unless-stopped\n    networks:\n      - llm-network\n\n  nginx:\n    image: nginx:alpine\n    container_name: nginx-proxy\n    depends_on:\n      - open-webui\n      - vllm\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/certs:/etc/nginx/certs:ro\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    restart: unless-stopped\n    networks:\n      - llm-network\n\nnetworks:\n  llm-network:\n    driver: bridge\n</code></pre> <p>Deploy:</p> <pre><code>docker compose -f docker-compose-nginx.yml up -d\n</code></pre>"},{"location":"guide/step5-webui/#step-by-step-deployment","title":"Step-by-Step Deployment","text":""},{"location":"guide/step5-webui/#step-1-prepare-environment","title":"Step 1: Prepare Environment","text":"<pre><code># Navigate to project directory\ncd ~/llm-stack\n\n# Ensure Docker is running\nsudo systemctl status docker\n\n# Verify GPU access\nnvidia-smi\n\n# Check Docker GPU support\ndocker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi\n</code></pre>"},{"location":"guide/step5-webui/#step-2-download-model-optional-but-recommended","title":"Step 2: Download Model (Optional but Recommended)","text":"<p>Pre-downloading models prevents long startup times and provides better visibility.</p> <pre><code># Activate your vLLM environment (if using local installation)\nsource ~/.venv/vllm/bin/activate\n\n# Download model to local cache\nhuggingface-cli download meta-llama/Llama-3.2-1B-Instruct --local-dir ./models/llama-3.2-1b\n\n# Or let Docker handle it automatically on first start\n</code></pre>"},{"location":"guide/step5-webui/#step-3-configure-environment","title":"Step 3: Configure Environment","text":"<pre><code># Create .env file\nnano .env\n\n# Add your HF token and generate secret key\n# See Environment Variables section above\n</code></pre>"},{"location":"guide/step5-webui/#step-4-create-docker-compose-file","title":"Step 4: Create Docker Compose File","text":"<pre><code># Create docker-compose.yml\nnano docker-compose.yml\n\n# Copy the appropriate configuration from above\n</code></pre>"},{"location":"guide/step5-webui/#step-5-start-services","title":"Step 5: Start Services","text":"<pre><code># Pull images (optional, will happen automatically)\ndocker compose pull\n\n# Start services in background\ndocker compose up -d\n\n# Watch logs\ndocker compose logs -f\n</code></pre> <p>Expected startup sequence:</p> <ol> <li>vLLM container starts and loads the model (2-5 minutes)</li> <li>Health check passes once model is loaded</li> <li>Open WebUI starts and connects to vLLM</li> <li>Services are ready for use</li> </ol>"},{"location":"guide/step5-webui/#step-6-verify-deployment","title":"Step 6: Verify Deployment","text":"<pre><code># Check container status\ndocker compose ps\n\n# Should show:\n# NAME                IMAGE                              STATUS\n# vllm-server         vllm/vllm-openai:latest           Up (healthy)\n# open-webui          ghcr.io/open-webui/open-webui     Up\n\n# Test vLLM API directly\ncurl http://localhost:8000/v1/models\n\n# Check Open WebUI\ncurl http://localhost:3000\n</code></pre>"},{"location":"guide/step5-webui/#step-7-create-first-user","title":"Step 7: Create First User","text":"<ol> <li>Open browser and navigate to <code>http://localhost:3000</code></li> <li>Click \"Sign Up\" (if <code>ENABLE_SIGNUP=true</code>)</li> <li>Enter email and password</li> <li>First user becomes admin automatically</li> </ol>"},{"location":"guide/step5-webui/#model-management","title":"Model Management","text":""},{"location":"guide/step5-webui/#changing-models","title":"Changing Models","text":"<p>Option 1: Edit docker-compose.yml</p> <pre><code># Stop services\ndocker compose down\n\n# Edit docker-compose.yml\nnano docker-compose.yml\n\n# Change the --model parameter under vllm service\n# Example: meta-llama/Llama-3.2-3B-Instruct\n\n# Restart services\ndocker compose up -d\n</code></pre> <p>Option 2: Environment Variable</p> <pre><code># In .env file\nMODEL_NAME=meta-llama/Llama-3.2-3B-Instruct\n\n# In docker-compose.yml, use:\ncommand:\n  - --model\n  - ${MODEL_NAME}\n</code></pre>"},{"location":"guide/step5-webui/#loading-multiple-models","title":"Loading Multiple Models","text":"<p>To serve multiple models simultaneously, create multiple vLLM containers:</p> <pre><code>services:\n  vllm-small:\n    image: vllm/vllm-openai:latest\n    container_name: vllm-small\n    environment:\n      - CUDA_VISIBLE_DEVICES=0\n    command:\n      - --model\n      - meta-llama/Llama-3.2-1B-Instruct\n      - --port\n      - \"8000\"\n    ports:\n      - \"8000:8000\"\n\n  vllm-large:\n    image: vllm/vllm-openai:latest\n    container_name: vllm-large\n    environment:\n      - CUDA_VISIBLE_DEVICES=1\n    command:\n      - --model\n      - meta-llama/Llama-3.2-3B-Instruct\n      - --port\n      - \"8001\"\n    ports:\n      - \"8001:8001\"\n</code></pre> <p>Configure Open WebUI to use multiple endpoints in Admin Panel &gt; Settings &gt; Connections.</p>"},{"location":"guide/step5-webui/#supported-models","title":"Supported Models","text":"<p>vLLM supports many model architectures. Popular choices:</p> <p>Small Models (&lt; 8GB VRAM): - meta-llama/Llama-3.2-1B-Instruct - meta-llama/Llama-3.2-3B-Instruct - Qwen/Qwen2.5-3B-Instruct - microsoft/phi-3-mini-4k-instruct</p> <p>Medium Models (12-24GB VRAM): - meta-llama/Llama-3.1-8B-Instruct - mistralai/Mistral-7B-Instruct-v0.3 - Qwen/Qwen2.5-7B-Instruct</p> <p>Large Models (24GB+ VRAM or Multi-GPU): - meta-llama/Llama-3.1-70B-Instruct (requires multi-GPU) - mistralai/Mixtral-8x7B-Instruct-v0.1</p> <p>Check vLLM supported models for full list.</p>"},{"location":"guide/step5-webui/#accessing-the-interface","title":"Accessing the Interface","text":""},{"location":"guide/step5-webui/#web-interface","title":"Web Interface","text":"<p>URL: <code>http://localhost:3000</code></p> <p>First Login: 1. Navigate to <code>http://localhost:3000</code> 2. Sign up with email and password (first user is admin) 3. Select model from dropdown (should auto-detect vLLM model) 4. Start chatting!</p>"},{"location":"guide/step5-webui/#api-access","title":"API Access","text":"<p>OpenAI-Compatible API:</p> <pre><code># List models\ncurl http://localhost:8000/v1/models\n\n# Chat completion\ncurl http://localhost:8000/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"meta-llama/Llama-3.2-1B-Instruct\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n    ],\n    \"max_tokens\": 100\n  }'\n</code></pre> <p>Python Example:</p> <pre><code>import openai\n\nclient = openai.OpenAI(\n    base_url=\"http://localhost:8000/v1\",\n    api_key=\"dummy-key\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"meta-llama/Llama-3.2-1B-Instruct\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Explain quantum computing\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"guide/step5-webui/#configuration-and-customization","title":"Configuration and Customization","text":""},{"location":"guide/step5-webui/#open-webui-settings","title":"Open WebUI Settings","text":"<p>Access via: Admin Panel (top right) &gt; Settings</p> <p>Key Settings:</p> <ol> <li>General</li> <li>Interface language</li> <li>Default model</li> <li> <p>Message retention</p> </li> <li> <p>Connections</p> </li> <li>Add/remove API endpoints</li> <li>Configure API keys</li> <li> <p>Test connections</p> </li> <li> <p>Users</p> </li> <li>User management</li> <li>Role assignments</li> <li> <p>Access control</p> </li> <li> <p>Models</p> </li> <li>Model selection</li> <li>Default parameters</li> <li>Temperature, top_p, etc.</li> </ol>"},{"location":"guide/step5-webui/#vllm-performance-tuning","title":"vLLM Performance Tuning","text":"<p>Memory Optimization:</p> <pre><code>command:\n  - --model\n  - your-model\n  - --gpu-memory-utilization\n  - \"0.95\"  # Use up to 95% of GPU memory\n  - --swap-space\n  - \"4\"     # 4GB CPU swap space\n</code></pre> <p>Throughput Optimization:</p> <pre><code>command:\n  - --model\n  - your-model\n  - --max-num-batched-tokens\n  - \"8192\"   # Larger batch processing\n  - --max-num-seqs\n  - \"256\"    # More concurrent sequences\n</code></pre> <p>Latency Optimization:</p> <pre><code>command:\n  - --model\n  - your-model\n  - --disable-log-requests  # Reduce logging overhead\n  - --enforce-eager         # Disable CUDA graphs for lower latency\n</code></pre>"},{"location":"guide/step5-webui/#advanced-open-webui-configuration","title":"Advanced Open WebUI Configuration","text":"<p>Environment Variables:</p> <pre><code>environment:\n  # Authentication\n  - ENABLE_SIGNUP=false\n  - DEFAULT_USER_ROLE=pending\n  - WEBUI_AUTH=true\n\n  # Features\n  - ENABLE_RAG_WEB_SEARCH=true\n  - ENABLE_IMAGE_GENERATION=false\n  - ENABLE_COMMUNITY_SHARING=false\n\n  # Uploads\n  - UPLOAD_ENABLED=true\n  - FILE_SIZE_LIMIT=100\n\n  # Database\n  - DATABASE_URL=sqlite:////app/backend/data/webui.db\n</code></pre>"},{"location":"guide/step5-webui/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"guide/step5-webui/#view-logs","title":"View Logs","text":"<pre><code># All services\ndocker compose logs -f\n\n# Specific service\ndocker compose logs -f vllm\ndocker compose logs -f open-webui\n\n# Last 100 lines\ndocker compose logs --tail=100 vllm\n</code></pre>"},{"location":"guide/step5-webui/#monitor-gpu-usage","title":"Monitor GPU Usage","text":"<pre><code># Real-time GPU monitoring\nwatch -n 1 nvidia-smi\n\n# Or use nvitop (if installed)\nnvitop\n</code></pre>"},{"location":"guide/step5-webui/#container-resource-usage","title":"Container Resource Usage","text":"<pre><code># View resource usage\ndocker stats\n\n# Specific container\ndocker stats vllm-server open-webui\n</code></pre>"},{"location":"guide/step5-webui/#health-checks","title":"Health Checks","text":"<pre><code># Check vLLM health\ncurl http://localhost:8000/health\n\n# Check Open WebUI\ncurl http://localhost:3000/api/health\n\n# Check container health status\ndocker inspect vllm-server | grep -A 10 Health\n</code></pre>"},{"location":"guide/step5-webui/#update-containers","title":"Update Containers","text":"<pre><code># Pull latest images\ndocker compose pull\n\n# Recreate containers with new images\ndocker compose up -d --force-recreate\n\n# Or do it in one step\ndocker compose pull &amp;&amp; docker compose up -d --force-recreate\n</code></pre>"},{"location":"guide/step5-webui/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/step5-webui/#issue-vllm-container-fails-to-start","title":"Issue: vLLM Container Fails to Start","text":"<p>Symptoms: - Container exits immediately - \"CUDA out of memory\" errors - Model loading failures</p> <p>Solutions:</p> <pre><code># Check logs\ndocker compose logs vllm\n\n# Reduce GPU memory utilization\n# In docker-compose.yml:\ncommand:\n  - --gpu-memory-utilization\n  - \"0.8\"  # Reduce from 0.9\n\n# Try smaller model\ncommand:\n  - --model\n  - meta-llama/Llama-3.2-1B-Instruct  # Instead of larger model\n\n# Clear cache and restart\ndocker compose down\nrm -rf models/*\ndocker compose up -d\n</code></pre>"},{"location":"guide/step5-webui/#issue-open-webui-cannot-connect-to-vllm","title":"Issue: Open WebUI Cannot Connect to vLLM","text":"<p>Symptoms: - \"Connection refused\" errors - No models shown in Open WebUI - API calls fail</p> <p>Solutions:</p> <pre><code># Check if vLLM is healthy\ndocker compose ps\n\n# Verify network connectivity\ndocker exec -it open-webui curl http://vllm:8000/health\n\n# Check environment variable\ndocker exec -it open-webui env | grep OPENAI_API_BASE_URL\n\n# Should be: http://vllm:8000/v1 (not http://localhost:8000/v1)\n\n# Restart services\ndocker compose restart\n</code></pre>"},{"location":"guide/step5-webui/#issue-slow-model-loading","title":"Issue: Slow Model Loading","text":"<p>Symptoms: - vLLM takes 10+ minutes to start - Health check times out</p> <p>Solutions:</p> <pre><code># Pre-download models\nhuggingface-cli download meta-llama/Llama-3.2-1B-Instruct --local-dir ./models/llama-3.2-1b\n\n# Increase health check start period\n# In docker-compose.yml:\nhealthcheck:\n  start_period: 600s  # 10 minutes instead of 5\n\n# Use faster storage for model cache\n# Mount SSD instead of HDD for ./models\n</code></pre>"},{"location":"guide/step5-webui/#issue-permission-denied-errors","title":"Issue: Permission Denied Errors","text":"<p>Symptoms: - \"Permission denied\" when writing to volumes - Container cannot create files</p> <p>Solutions:</p> <pre><code># Fix ownership\nsudo chown -R $USER:$USER ./models ./openwebui-data\n\n# Or run containers with user\n# In docker-compose.yml:\nservices:\n  vllm:\n    user: \"${UID}:${GID}\"\n\n# Set UID and GID in .env:\nUID=1000\nGID=1000\n</code></pre>"},{"location":"guide/step5-webui/#issue-out-of-disk-space","title":"Issue: Out of Disk Space","text":"<p>Symptoms: - \"No space left on device\" - Model downloads fail</p> <p>Solutions:</p> <pre><code># Check disk usage\ndf -h\ndocker system df\n\n# Clean up unused Docker resources\ndocker system prune -a --volumes\n\n# Remove old model files\nrm -rf models/models--old-model-name\n\n# Move models to larger disk\nsudo systemctl stop docker\nsudo mv /var/lib/docker /data/docker\nsudo ln -s /data/docker /var/lib/docker\nsudo systemctl start docker\n</code></pre>"},{"location":"guide/step5-webui/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guide/step5-webui/#gpu-optimization","title":"GPU Optimization","text":"<p>Enable Persistence Mode:</p> <pre><code>sudo nvidia-smi -pm 1\n</code></pre> <p>Set Power Limit (optional):</p> <pre><code># Set to maximum performance\nsudo nvidia-smi -pl 350  # Adjust based on your GPU\n</code></pre>"},{"location":"guide/step5-webui/#vllm-optimization","title":"vLLM Optimization","text":"<p>For Maximum Throughput:</p> <pre><code>command:\n  - --model\n  - your-model\n  - --tensor-parallel-size\n  - \"2\"  # Multi-GPU\n  - --gpu-memory-utilization\n  - \"0.95\"\n  - --max-num-batched-tokens\n  - \"16384\"\n  - --max-num-seqs\n  - \"512\"\n</code></pre> <p>For Minimum Latency:</p> <pre><code>command:\n  - --model\n  - your-model\n  - --gpu-memory-utilization\n  - \"0.8\"\n  - --max-num-batched-tokens\n  - \"2048\"\n  - --max-num-seqs\n  - \"64\"\n  - --enforce-eager\n</code></pre>"},{"location":"guide/step5-webui/#docker-optimization","title":"Docker Optimization","text":"<p>Increase shared memory:</p> <pre><code>services:\n  vllm:\n    shm_size: '8gb'  # Or use ipc: host\n</code></pre> <p>Resource limits:</p> <pre><code>services:\n  vllm:\n    deploy:\n      resources:\n        limits:\n          memory: 32g\n        reservations:\n          memory: 16g\n</code></pre>"},{"location":"guide/step5-webui/#security-considerations","title":"Security Considerations","text":""},{"location":"guide/step5-webui/#network-security","title":"Network Security","text":"<p>1. Restrict Public Access:</p> <pre><code># Bind only to localhost\nports:\n  - \"127.0.0.1:3000:8080\"  # Not accessible from network\n</code></pre> <p>2. Use NGINX with Authentication:</p> <pre><code>location / {\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/.htpasswd;\n    proxy_pass http://open-webui;\n}\n</code></pre> <p>3. Enable Firewall:</p> <pre><code># Allow only from specific IP\nsudo firewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" port protocol=\"tcp\" port=\"3000\" accept'\nsudo firewall-cmd --reload\n</code></pre>"},{"location":"guide/step5-webui/#application-security","title":"Application Security","text":"<p>1. Disable Public Signup:</p> <pre><code>environment:\n  - ENABLE_SIGNUP=false\n</code></pre> <p>2. Use Strong Secret Key:</p> <pre><code># Generate strong key\nopenssl rand -hex 32\n</code></pre> <p>3. Set Default User Role to Pending:</p> <pre><code>environment:\n  - DEFAULT_USER_ROLE=pending\n</code></pre> <p>4. Regular Updates:</p> <pre><code># Update monthly\ndocker compose pull\ndocker compose up -d --force-recreate\n</code></pre>"},{"location":"guide/step5-webui/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"guide/step5-webui/#backup-procedure","title":"Backup Procedure","text":"<p>1. Backup Open WebUI Data:</p> <pre><code># Stop services\ndocker compose down\n\n# Backup data directory\ntar -czf openwebui-backup-$(date +%Y%m%d).tar.gz openwebui-data/\n\n# Backup .env\ncp .env .env.backup\n\n# Restart services\ndocker compose up -d\n</code></pre> <p>2. Backup Models (Optional):</p> <pre><code># Models are cached and can be re-downloaded\n# But for air-gapped systems:\ntar -czf models-backup-$(date +%Y%m%d).tar.gz models/\n</code></pre> <p>3. Automated Backup Script:</p> <pre><code>#!/bin/bash\n# backup.sh\n\nBACKUP_DIR=\"/backup/llm-stack\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p $BACKUP_DIR\n\ncd ~/llm-stack\ndocker compose down\n\ntar -czf $BACKUP_DIR/openwebui-$DATE.tar.gz openwebui-data/\ntar -czf $BACKUP_DIR/config-$DATE.tar.gz docker-compose.yml .env\n\ndocker compose up -d\n\n# Keep only last 7 backups\nfind $BACKUP_DIR -name \"openwebui-*.tar.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"guide/step5-webui/#recovery-procedure","title":"Recovery Procedure","text":"<p>1. Restore from Backup:</p> <pre><code># Stop services\ndocker compose down\n\n# Restore data\ntar -xzf openwebui-backup-20260214.tar.gz\n\n# Restore configuration\ntar -xzf config-backup-20260214.tar.gz\n\n# Restart services\ndocker compose up -d\n</code></pre> <p>2. Disaster Recovery:</p> <pre><code># Fresh start with backed up data\ncd ~/llm-stack-new\ncp /backup/.env .\ncp /backup/docker-compose.yml .\ntar -xzf /backup/openwebui-backup-latest.tar.gz\ndocker compose up -d\n</code></pre>"},{"location":"guide/step5-webui/#additional-resources","title":"Additional Resources","text":""},{"location":"guide/step5-webui/#official-documentation","title":"Official Documentation","text":"<ul> <li>vLLM Documentation</li> <li>Open WebUI Documentation</li> <li>Docker Compose Documentation</li> <li>NVIDIA Container Toolkit</li> </ul>"},{"location":"guide/step5-webui/#community-resources","title":"Community Resources","text":"<ul> <li>vLLM GitHub</li> <li>Open WebUI GitHub</li> <li>vLLM Discord</li> <li>Open WebUI Discord</li> </ul>"},{"location":"guide/step5-webui/#example-configurations","title":"Example Configurations","text":"<ul> <li>vLLM + Open WebUI Examples</li> <li>Production Docker Compose</li> </ul>"},{"location":"guide/step5-webui/#model-resources","title":"Model Resources","text":"<ul> <li>Hugging Face Model Hub</li> <li>vLLM Supported Models</li> <li>LLM Leaderboard</li> </ul>"},{"location":"guide/step5-webui/#quick-command-reference","title":"Quick Command Reference","text":"<pre><code># Deployment\ndocker compose up -d                    # Start services\ndocker compose down                     # Stop services\ndocker compose restart                  # Restart services\ndocker compose pull                     # Update images\n\n# Monitoring\ndocker compose logs -f                  # View logs\ndocker compose ps                       # Service status\ndocker stats                           # Resource usage\nnvidia-smi                             # GPU status\n\n# Maintenance\ndocker compose exec vllm bash          # Enter vLLM container\ndocker compose exec open-webui sh      # Enter Open WebUI container\ndocker system prune -a                 # Clean up Docker\n\n# Troubleshooting\ndocker compose logs vllm --tail=100    # Last 100 vLLM logs\ncurl http://localhost:8000/health      # Check vLLM health\ncurl http://localhost:3000             # Check Open WebUI\n</code></pre> <p>Deployment Complete!</p> <p>Your containerized LLM inference platform is now ready. Access Open WebUI at <code>http://localhost:3000</code> and start chatting with your local AI models.</p> <p>Next Steps: 1. Create your first user account 2. Download additional models 3. Configure user preferences 4. Set up backups 5. Explore RAG features and document uploads</p> <p>Last Updated: February 19 2026 System: RHEL 10.1 Components: vLLM + Open WebUI + Docker Compose</p>"},{"location":"guide/step6-ad/","title":"Red Hat Enterprise Linux 10.1 Active Directory Integration Guide","text":""},{"location":"guide/step6-ad/#server-information","title":"Server Information","text":"<ul> <li>Hostname: bert</li> <li>Operating System: Red Hat Enterprise Linux 10.1</li> <li>Target Domain: mycompany.org (placeholder for your company)</li> <li>Domain Account: henryf</li> <li>Domain Password: password123 (placeholder for documentation)</li> </ul>"},{"location":"guide/step6-ad/#network-configuration-change","title":"Network Configuration Change","text":"<ul> <li>Current IP: 198.186.1.1</li> <li>New IP: 10.0.13.35</li> <li>Gateway: 10.0.13.1</li> <li>Subnet Mask: 255.255.255.0 (assumed - adjust as needed)</li> </ul>"},{"location":"guide/step6-ad/#prerequisites","title":"Prerequisites","text":"<p>Before beginning, ensure you have: - Root or sudo access to the server - Network connectivity to the Active Directory domain controllers - DNS servers that can resolve the mycompany.org domain - Active Directory domain administrator credentials or delegated permissions</p>"},{"location":"guide/step6-ad/#part-1-network-configuration-change","title":"Part 1: Network Configuration Change","text":""},{"location":"guide/step6-ad/#step-1-identify-current-network-interface","title":"Step 1: Identify Current Network Interface","text":"<pre><code># List network interfaces\nnmcli device status\n\n# Or use ip command\nip addr show\n</code></pre> <p>Note the interface name (e.g., <code>ens160</code>, <code>eth0</code>, <code>enpXsY</code>).</p>"},{"location":"guide/step6-ad/#step-2-backup-current-network-configuration","title":"Step 2: Backup Current Network Configuration","text":"<pre><code># Create backup directory\nsudo mkdir -p /root/network-backup\n\n# Export current network configuration\nsudo nmcli connection show &gt; /root/network-backup/connections-backup.txt\nsudo ip addr show &gt; /root/network-backup/ip-config-backup.txt\nsudo ip route show &gt; /root/network-backup/routes-backup.txt\n</code></pre>"},{"location":"guide/step6-ad/#step-3-configure-new-ip-address","title":"Step 3: Configure New IP Address","text":"<p>Replace <code>&lt;interface-name&gt;</code> with your actual interface name (e.g., <code>ens160</code>).</p> <pre><code># Identify the connection name\nsudo nmcli connection show\n\n# Modify the connection with new IP settings\nsudo nmcli connection modify &lt;interface-name&gt; \\\n  ipv4.addresses 10.0.13.35/24 \\\n  ipv4.gateway 10.0.13.1 \\\n  ipv4.method manual\n\n# Set DNS servers (use your Active Directory DNS servers)\n# Replace with actual DNS server IPs\nsudo nmcli connection modify &lt;interface-name&gt; \\\n  ipv4.dns \"10.0.13.10 10.0.13.11\"\n\n# Set DNS search domain\nsudo nmcli connection modify &lt;interface-name&gt; \\\n  ipv4.dns-search mycompany.org\n\n# Bring down and up the connection to apply changes\nsudo nmcli connection down &lt;interface-name&gt;\nsudo nmcli connection up &lt;interface-name&gt;\n</code></pre>"},{"location":"guide/step6-ad/#step-4-verify-network-configuration","title":"Step 4: Verify Network Configuration","text":"<pre><code># Check IP address\nip addr show\n\n# Check routing table\nip route show\n\n# Test gateway connectivity\nping -c 4 10.0.13.1\n\n# Test DNS resolution\nnslookup mycompany.org\n\n# Test internet connectivity\nping -c 4 8.8.8.8\n</code></pre>"},{"location":"guide/step6-ad/#step-5-verify-dns-resolution-for-active-directory","title":"Step 5: Verify DNS Resolution for Active Directory","text":"<pre><code># Check domain controller discovery\nnslookup mycompany.org\n\n# Check for SRV records (essential for AD integration)\nnslookup -type=SRV _ldap._tcp.mycompany.org\n\n# Check Kerberos SRV records\nnslookup -type=SRV _kerberos._tcp.mycompany.org\n</code></pre> <p>Important: If DNS queries fail, verify your DNS server settings and ensure they point to Active Directory domain controllers.</p>"},{"location":"guide/step6-ad/#part-2-active-directory-integration","title":"Part 2: Active Directory Integration","text":""},{"location":"guide/step6-ad/#step-6-install-required-packages","title":"Step 6: Install Required Packages","text":"<pre><code># Update system packages\nsudo dnf update -y\n\n# Install required packages for AD integration\nsudo dnf install -y \\\n  realmd \\\n  sssd \\\n  sssd-tools \\\n  sssd-ad \\\n  adcli \\\n  samba-common-tools \\\n  oddjob \\\n  oddjob-mkhomedir \\\n  krb5-workstation\n</code></pre>"},{"location":"guide/step6-ad/#step-7-discover-the-active-directory-domain","title":"Step 7: Discover the Active Directory Domain","text":"<pre><code># Discover the domain\nsudo realm discover mycompany.org\n</code></pre> <p>Expected Output: <pre><code>mycompany.org\n  type: kerberos\n  realm-name: MYCOMPANY.ORG\n  domain-name: mycompany.org\n  configured: no\n  server-software: active-directory\n  client-software: sssd\n  required-package: sssd-tools\n  required-package: sssd\n  required-package: adcli\n  required-package: samba-common-tools\n</code></pre></p> <p>If the discovery fails, verify: - DNS configuration points to AD DNS servers - Firewall allows necessary traffic - Network connectivity to domain controllers</p>"},{"location":"guide/step6-ad/#step-8-configure-time-synchronization","title":"Step 8: Configure Time Synchronization","text":"<p>Active Directory requires time synchronization (within 5 minutes tolerance).</p> <pre><code># Install chrony if not already installed\nsudo dnf install -y chrony\n\n# Configure chrony to sync with domain controller or NTP server\nsudo vi /etc/chrony.conf\n\n# Add or modify to include your domain controller or time server\n# Example:\n# server 10.0.13.10 iburst\n\n# Restart chronyd service\nsudo systemctl restart chronyd\n\n# Enable chronyd to start at boot\nsudo systemctl enable chronyd\n\n# Verify time synchronization\nsudo chronyc sources -v\nsudo timedatectl status\n</code></pre>"},{"location":"guide/step6-ad/#step-9-join-the-active-directory-domain","title":"Step 9: Join the Active Directory Domain","text":"<pre><code># Join the domain using the provided credentials\nsudo realm join --user=henryf mycompany.org\n</code></pre> <p>When prompted, enter the password: <code>password123</code></p> <p>Alternative method with explicit parameters:</p> <pre><code>sudo realm join --user=henryf \\\n  --computer-ou=\"OU=Servers,DC=mycompany,DC=org\" \\\n  --verbose \\\n  mycompany.org\n</code></pre> <p>Note: Replace the <code>--computer-ou</code> parameter with the appropriate Organizational Unit path if needed, or omit it to use the default Computers container.</p>"},{"location":"guide/step6-ad/#step-10-verify-domain-join","title":"Step 10: Verify Domain Join","text":"<pre><code># Check realm status\nsudo realm list\n\n# Verify SSSD configuration\nsudo cat /etc/sssd/sssd.conf\n\n# Test domain connectivity\nsudo sssctl domain-status mycompany.org\n\n# Verify Kerberos ticket\nsudo kinit henryf@MYCOMPANY.ORG\nsudo klist\n</code></pre>"},{"location":"guide/step6-ad/#step-11-configure-sssd-optional-enhancements","title":"Step 11: Configure SSSD (Optional Enhancements)","text":"<p>Edit the SSSD configuration for enhanced functionality:</p> <pre><code>sudo vi /etc/sssd/sssd.conf\n</code></pre> <p>Add or modify these settings:</p> <pre><code>[sssd]\ndomains = mycompany.org\nconfig_file_version = 2\nservices = nss, pam\n\n[domain/mycompany.org]\ndefault_shell = /bin/bash\nkrb5_store_password_if_offline = True\ncache_credentials = True\nkrb5_realm = mycompany.org\nrealmd_tags = manages-system joined-with-adcli\nid_provider = ad\nfallback_homedir = /home/%u@%d\nad_domain = mycompany.org\nuse_fully_qualified_names = False\nldap_id_mapping = True\naccess_provider = ad\n</code></pre> <p>Key Configuration Options: - <code>use_fully_qualified_names = False</code> - Allows login with just username instead of username@domain - <code>fallback_homedir = /home/%u@%d</code> - Sets home directory location - <code>cache_credentials = True</code> - Allows offline authentication</p> <p>After editing, restart SSSD:</p> <pre><code>sudo systemctl restart sssd\nsudo systemctl enable sssd\n</code></pre>"},{"location":"guide/step6-ad/#step-12-configure-automatic-home-directory-creation","title":"Step 12: Configure Automatic Home Directory Creation","text":"<pre><code># Enable and start oddjobd service\nsudo systemctl enable oddjobd\nsudo systemctl start oddjobd\n\n# Verify PAM configuration includes mkhomedir\nsudo authselect current\n\n# If needed, enable with-mkhomedir\nsudo authselect select sssd with-mkhomedir --force\n</code></pre>"},{"location":"guide/step6-ad/#step-13-test-domain-user-authentication","title":"Step 13: Test Domain User Authentication","text":"<pre><code># Test user information retrieval\nid henryf\ngetent passwd henryf\n\n# Test domain group information\ngetent group \"domain users\"\n\n# Test SSH or local login (if SSH is configured)\n# From another terminal or system:\nssh henryf@10.0.13.35\n</code></pre>"},{"location":"guide/step6-ad/#step-14-configure-sudo-access-for-domain-users-optional","title":"Step 14: Configure Sudo Access for Domain Users (Optional)","text":"<p>To grant sudo privileges to domain users or groups:</p> <pre><code># Edit sudoers file\nsudo visudo\n\n# Add domain users or groups\n# For individual user:\nhenryf ALL=(ALL) ALL\n\n# For a domain group (use %):\n%domain\\ admins ALL=(ALL) ALL\n</code></pre> <p>Or create a separate sudoers file:</p> <pre><code>sudo vi /etc/sudoers.d/domain_admins\n\n# Add content:\n%domain\\ admins ALL=(ALL) ALL\n\n# Set proper permissions\nsudo chmod 0440 /etc/sudoers.d/domain_admins\n</code></pre>"},{"location":"guide/step6-ad/#step-15-configure-firewall-if-applicable","title":"Step 15: Configure Firewall (If Applicable)","text":"<p>Ensure the firewall allows necessary AD traffic:</p> <pre><code># Check firewall status\nsudo firewall-cmd --state\n\n# Allow required services\nsudo firewall-cmd --permanent --add-service=kerberos\nsudo firewall-cmd --permanent --add-service=ldap\nsudo firewall-cmd --permanent --add-service=ldaps\nsudo firewall-cmd --permanent --add-service=dns\n\n# Reload firewall\nsudo firewall-cmd --reload\n\n# Verify rules\nsudo firewall-cmd --list-all\n</code></pre>"},{"location":"guide/step6-ad/#step-16-verify-complete-integration","title":"Step 16: Verify Complete Integration","text":"<pre><code># Check system authentication\nsudo systemctl status sssd\n\n# Verify domain membership\nsudo realm list\n\n# Test user lookup\nid henryf\ngetent passwd henryf\n\n# Check Kerberos ticket\nsudo kinit henryf@MYCOMPANY.ORG\nsudo klist\n\n# Test password authentication\nsu - henryf\n</code></pre>"},{"location":"guide/step6-ad/#part-3-post-configuration-tasks","title":"Part 3: Post-Configuration Tasks","text":""},{"location":"guide/step6-ad/#step-17-set-hostname-resolution","title":"Step 17: Set Hostname Resolution","text":"<p>Ensure the server's hostname is properly configured:</p> <pre><code># Set hostname\nsudo hostnamectl set-hostname bert.mycompany.org\n\n# Verify hostname\nhostnamectl\n\n# Update /etc/hosts\nsudo vi /etc/hosts\n\n# Add entry:\n10.0.13.35    bert.mycompany.org    bert\n</code></pre>"},{"location":"guide/step6-ad/#step-18-configure-selinux-if-enabled","title":"Step 18: Configure SELinux (If Enabled)","text":"<pre><code># Check SELinux status\ngetenforce\n\n# If SELinux is enforcing, ensure proper contexts\nsudo setsebool -P allow_polyinstantiation on\nsudo restorecon -Rv /home\n</code></pre>"},{"location":"guide/step6-ad/#step-19-enable-services-at-boot","title":"Step 19: Enable Services at Boot","text":"<pre><code># Ensure all required services start at boot\nsudo systemctl enable sssd\nsudo systemctl enable chronyd\nsudo systemctl enable oddjobd\n</code></pre>"},{"location":"guide/step6-ad/#step-20-document-and-backup-configuration","title":"Step 20: Document and Backup Configuration","text":"<pre><code># Create configuration backup\nsudo mkdir -p /root/ad-integration-backup\nsudo cp /etc/sssd/sssd.conf /root/ad-integration-backup/\nsudo cp /etc/krb5.conf /root/ad-integration-backup/\nsudo cp /etc/resolv.conf /root/ad-integration-backup/\nsudo nmcli connection show &gt; /root/ad-integration-backup/network-config.txt\n\n# Create documentation of current state\nsudo realm list &gt; /root/ad-integration-backup/realm-status.txt\nsudo systemctl list-unit-files | grep enabled &gt; /root/ad-integration-backup/enabled-services.txt\n</code></pre>"},{"location":"guide/step6-ad/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/step6-ad/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"guide/step6-ad/#issue-domain-discovery-fails","title":"Issue: Domain Discovery Fails","text":"<p>Solution: <pre><code># Verify DNS servers\ncat /etc/resolv.conf\n\n# Test DNS resolution\nnslookup mycompany.org\nnslookup -type=SRV _ldap._tcp.mycompany.org\n\n# Manually set DNS servers if needed\nsudo nmcli connection modify &lt;interface-name&gt; ipv4.dns \"AD_DNS_SERVER_IP\"\nsudo nmcli connection down &lt;interface-name&gt;\nsudo nmcli connection up &lt;interface-name&gt;\n</code></pre></p>"},{"location":"guide/step6-ad/#issue-join-operation-fails","title":"Issue: Join Operation Fails","text":"<p>Solution: <pre><code># Check time synchronization\ntimedatectl status\n\n# Verify connectivity to domain controller\nping &lt;DC_IP&gt;\n\n# Check for existing computer account in AD and remove if necessary\n# Attempt join with verbose output\nsudo realm join --user=henryf --verbose mycompany.org\n</code></pre></p>"},{"location":"guide/step6-ad/#issue-user-login-fails","title":"Issue: User Login Fails","text":"<p>Solution: <pre><code># Clear SSSD cache\nsudo sss_cache -E\n\n# Restart SSSD\nsudo systemctl restart sssd\n\n# Check SSSD logs\nsudo tail -f /var/log/sssd/*.log\n\n# Test user lookup\ngetent passwd henryf\nid henryf\n</code></pre></p>"},{"location":"guide/step6-ad/#issue-home-directory-not-created","title":"Issue: Home Directory Not Created","text":"<p>Solution: <pre><code># Verify oddjobd is running\nsudo systemctl status oddjobd\n\n# Check authselect configuration\nsudo authselect current\n\n# Re-enable mkhomedir\nsudo authselect select sssd with-mkhomedir --force\nsudo systemctl restart sssd\n</code></pre></p>"},{"location":"guide/step6-ad/#issue-permission-denied-on-login","title":"Issue: Permission Denied on Login","text":"<p>Solution: <pre><code># Check access_provider setting in sssd.conf\nsudo grep access_provider /etc/sssd/sssd.conf\n\n# Verify SELinux is not blocking\nsudo ausearch -m avc -ts recent\n\n# Check PAM configuration\nsudo ls -la /etc/pam.d/\n</code></pre></p>"},{"location":"guide/step6-ad/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Network IP address changed to 10.0.13.35</li> <li>[ ] Gateway configured as 10.0.13.1</li> <li>[ ] DNS resolves mycompany.org domain</li> <li>[ ] Time synchronized with domain</li> <li>[ ] Server joined to mycompany.org domain</li> <li>[ ] <code>realm list</code> shows domain configuration</li> <li>[ ] Domain user <code>henryf</code> can be resolved with <code>id</code> command</li> <li>[ ] SSSD service is running and enabled</li> <li>[ ] Home directories are created automatically on first login</li> <li>[ ] Domain users can authenticate</li> <li>[ ] Firewall configured appropriately</li> <li>[ ] Configuration backed up</li> </ul>"},{"location":"guide/step6-ad/#important-security-notes","title":"Important Security Notes","text":"<ol> <li>Change the default password for the <code>henryf</code> account immediately after testing</li> <li>Use strong passwords for all domain accounts</li> <li>Implement least privilege - only grant necessary permissions</li> <li>Enable firewall and restrict access to required ports only</li> <li>Keep system updated with security patches:    <pre><code>sudo dnf update -y\n</code></pre></li> <li>Monitor logs regularly for suspicious activity:    <pre><code>sudo journalctl -u sssd -f\n</code></pre></li> <li>Implement SSH key authentication for remote access instead of password-only</li> </ol>"},{"location":"guide/step6-ad/#additional-resources","title":"Additional Resources","text":"<ul> <li>Red Hat Enterprise Linux Documentation: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/10</li> <li>SSSD Documentation: https://sssd.io/</li> <li>Active Directory Integration Guide: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/10/html/configuring_authentication_and_authorization_in_rhel/</li> </ul>"},{"location":"guide/step6-ad/#support-contact-information","title":"Support Contact Information","text":"<p>For issues or questions, contact: - IT Support: [Your IT Support Contact] - Domain Administrator: [Domain Admin Contact] - Red Hat Support: https://access.redhat.com/support</p> <p>Document Version: 1.0 Last Updated: February 16, 2026 Author: System Administrator Server: bert.mycompany.org</p>"}]}